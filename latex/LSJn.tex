\input{preamble}



\begin{document}
\renewcommand{\labelitemi}{$\diamond$}
\vspace{2cm}~~\\

\input{bussproofs}

\tableofcontents

\pagebreak






\section{Logique intuitionniste propositionnelle : approche par le calcul de séquents \LJ}




Il existe de nombreuses approches de la logique intuitionniste : on choisit ici celle par le calcul de séquents \LJ\ introduit par Gentzen. 
Elle fournit une définition de la prouvabilité d'une formule en logique intuitionniste qui n'est pas la plus courante ni la plus rapide à exposer ; mais elle permet de présenter un premier calcul de séquents avec de nombreuses définitions qui seront utiles par la suite.
%Cela permet de se familiariser avec les calculs de séquents, avant de discuter




%Il existe de nombreuses approches de la logique intuitionniste : on choisit ici celle par un calcul de séquents.

\

On s'intéresse à la partie propositionnelle de la logique intuitionniste : les formules sont construites à partir de la constante $\bot$, de variables propositionnelles et des connecteurs binaires $\land$, $\lor$, $\to$. Une formule est \emph{atomique} si elle est réduite à une variable propositionnelle ou $\bot$. La notation $\lnot A$ signifie $A\to\bot$.






%\subsection{LJ : le calcul originel de la logique intuitionniste}
%\subsection{De \LK\ à \LJ}
\subsection{Définition du calcul \LJ}


%Un calcul de séquents se caractérise en général par sa propre définition d'un séquent, ainsi qu'un ensemble de règles. Voici
%Comme la plupart des calculs de séquents, le calcul \LJ\ se caractérise par une définition de ses \emph{séquents} ainsi qu'un ensemble de \emph{règles}.
Les éléments qui caractérisent généralement un calcul de séquents sont une définition de ses \emph{séquents} et un ensemble de \emph{règles}. Présentons ceux du calcul \LJ.

\

\noindent
\textbf{Multiensembles et notations.}
On s'intéresse à des \emph{multiensembles}, c'est-à-dire des collections où le nombre d'occurrences est pris en compte, mais non l'ordre des éléments. Cela permettra de ne pas avoir besoin de règles explicites d'échange. On utilise des lettres romaines (typiquement $A$, $B$, $D$, $G$) pour désigner les formules et des lettres grecques ($\G$, $\D$) pour les multiensembles de formules. La notation ``$A,\G$'' représente le multiensemble obtenu à partir de $\G$ en ajoutant une occurrence de $A$. Lorsqu'il n'y a pas matière à confusion, on représente un multiensemble vide par un simple blanc.

%Un \textbf{séquent} de \LK\ est la donnée de deux multiensembles de formules $\G$ (les ``hypothèses'') et $\D$ (les ``conclusions'') ; on écrit $\G \To \D$.

\begin{df}
%est la donnée de
%est constitué de
Un \textbf{\emph{séquent}} de \LJ\ est consiste en un multiensemble de formules $\G$ (les ``hypothèses'') et une formule $D$ (la ``conclusion'') ; on écrit $\G \To D$.
\end{df}



Les \textbf{\emph{règles}} du calcul \LJ\ sont données dans la figure~\ref{fig:reglesLJ}.  Pour une règle \regle, $\mathcal R$ est le nom de la règle, $prem_{1}$, ... , $prem_{p}$ sont les \textbf{\emph{prémisses}}, et $concl$ la \textbf{\emph{conclusion}}. Les prémisses et la conclusion sont des séquents où $A$, $B$, $D$ sont des formules quelconques et $\G$ un multiensemble de formules quelconques. 
%La distinction entre règles \emph{logiques} et \emph{structurelles} sera expliquée plus loin.
 Les \emph{axiomes} sont les règles sans prémisse.
On distingue deux grandes familles de règles. Les \emph{règles logiques} remplacent une formule de la conclusion par une ou des formules plus simples. La formule remplacée, appelée \emph{formule principale}, doit avoir une forme donnée en fonction de la règle. Les \emph{règles structurelles} manipulent la structure du séquent en enlevant, dupliquant, dépla\c cant des formules dont on n'a pas besoin de connaître la forme. Elles dépendent du choix de structure du séquent : si on avait 
%choisi de réprésenter 
représenté
$\G$ par une liste et non un multiensemble, on aurait eu besoin d'ajouter une règle d'échange\LJechange.

%On distingue généralement deux sortes de règles. Les \emph{règles logiques} remplacent une formule de la conclusion par une ou des formules plus simples. La formule remplacée, appelée \emph{formule principale}, doit avoir une forme donnée en fonction de la règle. Les \emph{règles structurelles} manipulent la structure du séquent en enlevant, dupliquant, dépla\c cant des formules dont on n'a pas besoin de connaître la forme. Elles dépendent du choix de structure du séquent : pour le calcul \LJ, si on avait choisi de réprésenter $\G$ par une liste et non un multiensemble, on aurait eu besoin d'ajouter une règle d'échange \echange.



Cette présentation est à peu près celle donnée par Dyckhoff dans \cite{LJT}. Elle diffère de celle de Gentzen, mais elle en est suffisamment proche pour qu'on puisse quand même l'appeler le calcul \LJ. On peut d'ailleurs facilement passer d'une définition à l'autre à l'aide des règles structurelles.

{
\renewcommand{\arraystretch}{2}

\begin{figure}[h]
\centering

%$\begin{tabular}{cc|}
%	\LJbotL & \LJId \\ \hline
%	\LJetL & \LJetR \\
%	\LJouL & \quad\LJouRun \quad \LJouRdeux \\
%	\LJimpL & \LJimpR 
%%	\multicolumn{2}{c}{\impL}\\\\
%%	\multicolumn{2}{c}{\impR}
%\end{tabular}$

%\def\identite{
%\begin{tabular}{cc}
%	\emph{Identité} \qquad&\qquad \LJId
%\end{tabular}
%}
%\def\coupure{
%\begin{tabular}{cc}
%	\emph{Coupure} & \LJcut
%\end{tabular}
%}
%\def\logiques{
%$\begin{tabular}{cc}
%%	\LJbotL & \LJId \\ \hline
%%	\multicolumn{2}{c}{\emph{Règles logiques}} \\
%	\LJbotL & \emph{Règles logiques} \\
%	\LJetL & \LJetR \\
%	\LJouL & \LJouRun \LJouRdeux \\
%	\LJimpL & \LJimpR 
%\end{tabular}$
%}
%\def\structurelles{
%$\begin{tabular}{c}
%	\emph{Règles structurelles} \\
%	\LJweakening \\
%	\LJcontraction
%\end{tabular}$
%}
%
%%$\begin{tabular}{cc|}
%%%	\LJbotL & \LJId \\ \hline 
%%	\multicolumn{2}{c}{\logiques}
%%\end{tabular}$
%$\begin{tabular}{|c|c|}
%	\hline
%	\identite & \coupure \\
%	\hline 
%	{\logiques} & \structurelles \\
%	\hline
%\end{tabular}$

\resizebox{\textwidth}{!}{

$\begin{tabular}{|cc|c|}
	\hline
	\textbf{\large{Identité}} & \LJId & \textbf{\large{Coupure}} \\
	\cline{1-2}
	\LJbotL & \textbf{\large{Règles logiques}} & \LJcut \\[4pt]
	\cline{3-3}
	\LJetL & \LJetR & \textbf{\large{Règles structurelles}} \\
	\LJouL & \LJouRun \LJouRdeux & \LJweakening \\
	\LJimpL & \LJimpR & \LJcontraction \\[4pt]
	\hline
%
%	\emph{Règles structurelles} \\
%	\LJweakening \\
%	\LJcontraction
\end{tabular}$

}

\caption{Règles du calcul \LJ}
\label{fig:reglesLJ}
\end{figure}
}

%\
%
%On dispose de \textbf{règles}, données sous la forme \regle. $\mathcal R$ est le nom de la règle. $prem_{1}$, ... , $prem_{p}$ sont les 
%%(resp. première, ... , $p$-ième) 
%\textbf{prémisses}, et $concl$ la \textbf{conclusion}. Les prémisses et la conclusion sont des séquents où $A$, $B$, $D$ sont des formules quelconques et $\G$ un multiensemble de formules quelconques.
%
%Les \textbf{axiomes} sont les règles sans prémisse. Un calcul de séquents comporte en général deux sortes de règles en plus de quelques axiomes : des \emph{règles logiques} et des \emph{règles structurelles}. Pour les règles logiques, il existe une unique formule de la conclusion dont on connaît le connecteur : c'est la \textbf{formule principale}, qui disparaît généralement dans les prémisses au profit de formules plus simples. Les règles structurelles ne se préoccupent pas des connecteurs, mais, comme leur nom l'indique, de la structure du séquent. Elles dépendent fortement du choix de définition d'un séquent : les règles d'échange comme\echange\ font partie des règles structurelles lorsqu'on retient les formules de $\G$ sous la forme d'une liste ; comme nous travaillons avec un mutiensemble, nous n'en avons pas besoin.
%
%Les axiomes et règles logiques de \LJ\ sont données dans la figure~\ref{fig:reglesLJ}. Comme règle structurelle, on ne considère que\contraction\ : cela suffit pour avoir un calcul complet (voir ??). 
%%Cette présentation du calcul \LJ\ diffère un peu de celle de Gentzen, mais on peut facilement passer de l'une à l'autre à l'aide des règles structurelles de Gentzen.
%Cette présentation diffère de celle de Gentzen, mais elle en est suffisamment proche pour qu'on puisse quand même l'appeler le calcul \LJ. On peut d'ailleurs facilement passer d'une définition à l'autre à l'aide des règles structurelles, si on rajoute la règle structurelle \weakening\ qui est juste mais pas nécessaire pour la complétude de notre approche.




%\subsection{Prouvabilité}
%
%
%
%Une \textbf{\emph{instance}} d'une règle $\mathcal R$ a la même forme que la règle : \instance, mais ici les $\s_{i}$ et $\s$ sont des séquents connus explicitement ; bien entendu il faut qu'il s'agisse de séquents qui correspondent à la forme donnée par la définition de la règle. %Par exemple \etL\ devient une instance de la règle $\land L$ (qui a la même écriture que la règle) lorsqu'on connaît les formules $A$ et $B$ et toutes les formules de $\Th$, $\G$, $\D$.
%
%Une \textbf{\emph{preuve}} (ou \emph{arbre de preuve}) est un arbre dont les n\oe uds sont étiquetés par un séquent et une règle et ont la même arité que le nombre de prémisses de la règle, et tel que : pour tout n\oe ud de séquent $\s$ et de règle $\mathcal R$, si $\s_{1}$, ... , $\s_{p}$ sont les séquents associés à chacun de ses fils respectivement, alors\instance\ est une instance de $\mathcal R$. Les feuilles d'un tel arbre sont les n\oe uds auxquels est associé un axiome.
%
%\begin{df*}
%Un séquent $\s$ est \textbf{\emph{prouvable}} par le calcul \LJ\ s'il existe un arbre de preuve tel que le séquent associé à la racine est $\s$. De manière équivalente, on peut définir l'ensemble des séquents prouvables comme le plus petit ensemble vérifiant : pour toute instance \instance\ d'une règle, si pour tout $i$, $\s_{i}$ est prouvable, alors $\s$ est prouvable (en particulier pour toute instance \instanceAx\ d'un axiome $\mathcal A$, $\s$ est prouvable).
%\end{df*}
%
%Ceci nous permet de définir la prouvabilité en logique intuitionniste.
%
%\begin{df*}
%Une formule $A$ est \textbf{\emph{prouvable en logique intuitionniste}} si le séquent $\;\To A$ est prouvable par le calcul \LJ\ (on écrit $\;\To A$ pour $\emptyset \To A$).
%\end{df*}
%
%\noindent
%\textbf{Interprétation d'un séquent.}
%%Les séquents sont des structures pratiques pour le calcul de séquents où ils sont manipulés à l'aide de règles, mais ils 
%%Les séquents, en plus d'être des structures pratiques pour le calcul de séquents où ils sont manipulés à l'aide de règles, 
%Les séquents, en plus d'être des structures pratiques à manipuler à l'aide de règles, 
%ont en eux-mêmes une interprétation logique très simple grâce à la propriété suivante : un séquent $\G \To D$ est prouvable par le calcul \LJ\ si, et seulement si, la formule $\left(\bigwedge_{G\in\G}G\right)\to D$ est prouvable en logique intuitionniste.
%



\subsection{Prouvabilité d'un séquent}
\label{ProuvabiliteSequent}

Les définitions suivantes s'appliquent aux calculs de séquents en général, pas seulement \LJ.
Une \textbf{\emph{instance}} d'une règle $\mathcal R$ a la même forme que la règle : \instance, mais ici les $\s_{i}$ et $\s$ sont des séquents connus explicitement ; bien entendu il faut qu'il s'agisse de séquents qui correspondent à la forme donnée par la définition de la règle. %Par exemple \etL\ devient une instance de la règle $\land L$ (qui a la même écriture que la règle) lorsqu'on connaît les formules $A$ et $B$ et toutes les formules de $\Th$, $\G$, $\D$.
Une \textbf{\emph{preuve}} (ou \textbf{\emph{arbre de preuve}}) est un arbre dont les n\oe uds sont étiquetés par un séquent et une règle et ont la même arité que le nombre de prémisses de la règle, et tel que : pour tout n\oe ud de séquent $\s$ et de règle $\mathcal R$, si $\s_{1}$, ... , $\s_{p}$ sont les séquents associés à chacun de ses fils respectivement, alors\instance\ est une instance de $\mathcal R$. Les feuilles d'un tel arbre sont les n\oe uds auxquels est associé un axiome.

\begin{df}
Un séquent $\s$ est \textbf{\emph{prouvable}} \emph{dans} 
%(ou \emph{par}) 
%ou \emph{par}
\emph{un calcul de séquents} s'il existe un arbre de preuve tel que le séquent associé à la racine est $\s$. De manière équivalente, on peut définir l'ensemble des séquents prouvables comme le plus petit ensemble vérifiant : pour toute instance \instance\ d'une règle, si pour tout $i$, $\s_{i}$ est prouvable, alors $\s$ est prouvable (en particulier pour toute instance \instanceAx\ d'un axiome $\mathcal A$, $\s$ est prouvable).
\end{df}

\subsection{Une définition de la prouvabilité en logique intuitionniste}

On peut maintenant donner une définition de la prouvabilité d'une formule en logique intuitionniste. L'idée est qu'un séquent $\G\To D$ représente la formule $\left(\bigwedge_{G\in\G}G\right)\to D$.

\begin{df}
Une formule $A$ est \textbf{\emph{prouvable en logique intuitionniste}} si le séquent $\;\To A$ est prouvable par le calcul \LJ\ (on écrit $\;\To A$ pour $\emptyset \To A$).
\end{df}

Il existe de nombreuses autres manières d'aborder la logique intuitionniste, par exemple avec les modèles de Kripke (?).





\subsection{Comparaison avec la logique classique (calcul \LK)}
%\
%\noindent
%\emph{Remarque.}
%Le calcul \LJ\ a été dérivé d'un calcul \LK\
%La logique classique peut être définie à l'aide d'un calcul de séquents appelé \LK, très similaire à \LJ\ (en fait, c'est \LJ\ qui a été dérivé de \LK\ pour passer de la logique classique à la logique intuitionniste). 
%La logique classique peut être définie à l'aide d'un calcul de séquents appelé \LK, dont \LJ\, qui en a été dérivé pour la logique intuitionniste, est très proche.
La logique classique peut être définie à l'aide d'un calcul de séquents appelé \LK, dont \LJ\ a été dérivé pour la logique intuitionniste. Un séquent de \LK\ comporte un autre multiensemble $\D$ de ``conclusions'' au lieu d'une unique conclusion $D$ : on écrit $\G \To \D$. Un tel séquent a également une interprétation logique : 
%il est prouvable par \LK\ si, et seulement si, la formule $\left(\bigwedge_{G\in\G}G\right)\to\left(\bigvee_{D\in\D}D\right)$ est vraie en logique classique.
il représente la formule $\left(\bigwedge_{G\in\G}G\right)\to\left(\bigvee_{D\in\D}D\right)$ en logique classique.
%
Les règles %sont modifiées
diffèrent en conséquence : par exemple\LKetR\ remplace ${\LJetR\,.}$ Bien entendu, on ajoute aussi des règles structurelles agissant sur $\D$.
 Mais surtout, on n'a plus qu'une règle pour le $\lor$ à droite : ${\LKouR\,.}$ (Dans d'autres définitions, on garde deux règles distinctes, mais la règle que nous donnons ici peut être déduite de ces deux règles et de règles structurelles.)
 
\begin{floatingfigure}%[h]
	[r]{3.7cm}
\centering
\LKTiersExclu

%\caption{Preuve dans \LK\ de $A\lor\lnot A$}
\caption{Preuve de $A\lor\lnot A$ dans \LK}
\label{fig:LKTiersExclu}
\end{floatingfigure}

C'est la possibilité d'avoir plusieurs formules dans la partie droite du séquent qui permet de prouver davantage de séquents dans \LK\ que dans \LJ. On comprend ainsi la différence entre le ``ou'' classique et le ``ou'' intuitionniste. En logique classique, prouver $A\lor B$, c'est prouver le séquent $\;\To A,B$ : les deux formules sont encore présentes. Un bon exemple est la preuve du principe du tiers exclu $A\lor\lnot A$ (figure~\ref{fig:LKTiersExclu} ; on rappelle que $\lnot A$ est une notation pour $A\to\bot$) : si on peut appliquer l'axiome Id à la formule $A$ (ce qui nécessite deux occurrences distinctes de la formule, une de chaque côté), c'est bien parce qu'on a conservé les deux parties de la formule initiale. Tandis qu'en logique intuitionniste, pour prouver $A\lor B$ c'est-à-dire $\;\To A\lor B$, les seules règles applicables sont $\lor R_{1}$ et $\lor R_{2}$ : il faut donc prouver $\;\To A$ ou prouver $\;\To B$ ; une fois qu'on a choisi lequel on va prouver, on n'a plus accès à l'autre. Ainsi, on ne peut prouver $A\lor\lnot A$, car ni $\;\To A$ ni $\;\To \lnot A$ n'est prouvable.

 %on ne peut prouver le séquent $\To A$, ni le séquent $\To 
%, où on applique l'axiome Id à une occurrence de $A$ venant du $\lnot A$ 



%%%%
%
%%\section{Avantages et inconvénients de différents calculs de séquents pour la logique intuitionniste}
%\section{Application du calcul de séquents à la recherche de preuve automatisée. Comparaison des différents systèmes}
%
%Un calcul de séquents est généralement défini par sa propre définition d'un séquent ainsi qu'un ensemble de règles. Il est souvent attaché à une logique : à partir d'une formule, on peut construire un séquent qui est prouvable si et seulement si la formule est ``prouvable'' ou ``vraie'' dans la logique en question (l'appellation dépend de la logique). Il existe plusieurs calculs de séquents pour la logique intuitionniste, sans parler des nombreuses autres logiques existantes.
%
%\
%
%\noindent
%\textbf{Algorithme.}
%Un calcul de séquents suggère naturellement un algorithme de recherche de preuve : pour essayer de prouver un séquent, on choisit une règle dont il peut être la conclusion et on essaie de prouver les prémisses correspondantes. Si elles sont toutes prouvables (notamment, s'il n'y en a pas : si le séquent est la conclusion d'un axiome), alors par définition le séquent initial est aussi prouvable. Sinon, on essaie une autre règle (sauf dans certains cas où on peut conclure grâce à la notion de règle ou prémisse inversible que nous verrons plus loin). Si on a essayé toutes les règles applicables au séquent sans succès (pour chacune, au moins une prémisse est non prouvable), on conclut que le séquent initial n'est pas prouvable.
%
%Un tel algorithme est correct par construction et d'après la définition de la prouvabilité d'un séquent. En revanche, les causes possibles de non terminaison sont nombreuses. Assurer la terminaison est une des raisons qui rendent certaines propriétés sur les calculs de séquents très intéressantes.
%
%
%\
%
%\noindent
%\textbf{Classification des règles.}
%On distingue généralement deux sortes de règles. Les \emph{règles logiques} remplacent une formule de la conclusion par une ou des formules plus simples. La formule remplacée, appelée \emph{formule principale}, doit avoir une forme donnée en fonction de la règle. Les \emph{règles structurelles} manipulent la structure du séquent en enlevant, dupliquant, dépla\c cant des formules dont on n'a pas besoin de connaître la forme. Elles dépendent du choix de structure du séquent : pour le calcul \LJ, si on avait choisi de réprésenter $\G$ par une liste et non un multiensemble, on aurait eu besoin d'ajouter une règle d'échange \echange.
%
%\
%
%\noindent
%\textbf{Coupure.}
%La règle de coupure (figure~1, ``cut'') condamne l'algorithme à elle seule, puisqu'il peut y avoir une infinité de prémisses associées à une conclusion donnée. Heureusement, cette règle est souvent non nécessaire : de nombreux calculs de séquents possèdent la propriété d'élimination de la coupure, si bien qu'on peut faire comme si cette règle n'existait pas. C'est une propriété souvent difficile à démontrer, mais on ne s'y intéressera pas. Désormais, on présentera des calculs sans donner de règle de coupure.
%
%
%\
%
%\noindent
%\textbf{Règles structurelles et coupure à éviter.}
%
%
%
%
%La règle de coupure (figure~1, ``cut'') condamne l'algorithme à elle seule, puisqu'il peut y avoir une infinité de prémisses associées à une conclusion donnée. Pour commencer, on veut donc un calcul où le nombre d'instances ayant une conclusion donnée est toujours fini. Mais même ainsi, comme pour essayer de prouver un séquent, on rappelle l'algorithme sur d'autres séquents, il faut un argument soigneux de terminaison : par exemple, associer à chaque séquent une ``taille'' entière positive, telle que pour toute instance des règles, les ``tailles'' de toutes les prémisses sont strictement inférieures à celle de la conclusion. Comme on le verra, la propriété de la sous-formule est bien pratique pour ce point-là.
%
%%il n'a pas de raison de terminer a priori. 
%
%%:  si on obtient qu'un séquent est prouvable, on  a en fait trouvé un arbre de preuve correspondant par construction de l'algorithme ; si on obtient qu'il n'est pas prouvable, cela signifie qu'il n'existe aucune instance de règle dont il est la conclusion et dont les prémisses sont prouvables, donc il ne peut pas être associé à la racine d'un arbre de preuve.
%
%
%
%
%\subsection{\LJ\ : existence de cycles}
%
%
%
%
%
%
%\
%
%
%nécessité de contraction ou réécriture de $\to L$ (preuve de $\lnot\lnot(A\lor\lnot A)$)
%
%LJT


%%%%%%%%%


%\section{D'un calcul de séquents à une recherche de preuve automatisée. Avantages et inconvénients de différents calculs}
\section{Propriétés favorisant l'application d'un calcul de séquents à la recherche automatisée de preuve et exemples de calculs}


Il existe plusieurs calculs de séquents pour la logique intuitionniste, sans parler des nombreuses autres logiques existantes. Un tel calcul comporte ses propres définition d'un séquent, règles, et construction pour chaque formule d'un séquent qui est prouvable par le calcul ssi la formule est prouvable en logique intuitionniste. En dériver l'algorithme de recherche de preuve ci-après est assez naturel. Sa correction est immédiate par construction. En revanche, la terminaison pose problème. 
%Il faut parfois complexifier beaucoup l'algorithme pour l'assurer. Afin d'éviter de devoir le faire, il faut certaines propriétés sur le calcul de séquents. 
Elle n'est pas toujours assurée, et même quand elle l'est, souvent difficile à prouver.
Nous présentons %l'algorithme générique, puis 
quelques propriétés sur les calculs de séquents
qui sont intéressantes pour assurer la terminaison et améliorer la complexité de l'algorithme qui leur est associé. Enfin, nous donnons deux exemples de calculs de séquents existants pour la logique intuitionniste, antérieurs au calcul que nous utilisons pour l'implémentation.



\subsection{Algorithme de recherche de preuve}

%Un calcul de séquents suggère naturellement un algorithme de recherche de preuve : pour essayer de prouver un séquent, 
On considère un calcul de séquents. Pour déterminer si un séquent est prouvable,
on choisit une règle dont il peut être la conclusion et on 
%essaie de prouver les 
applique récursivement la recherche de preuve aux
prémisses correspondantes. Si elles sont toutes prouvables (en particulier, s'il n'y en a pas : si le séquent est la conclusion d'un axiome), alors par définition le séquent initial est aussi prouvable ; de plus, si on a calculé un arbre de preuve pour chaque prémisse, on en obtient un pour le séquent initial. Sinon, on essaie une autre règle (sauf dans certains cas où on peut conclure grâce à la notion de règle ou prémisse inversible que nous verrons plus loin). Si on a essayé toutes les règles applicables au séquent sans succès, c'est-à-dire que pour chacune, au moins une prémisse est non prouvable (en particulier, s'il n'y a aucune règle applicable : si le séquent n'est la conclusion d'aucune instance), on conclut que le séquent initial n'est pas prouvable.

Cet algorithme est correct par construction et d'après la définition de la prouvabilité d'un séquent. En revanche, 
%sans certaines conditions, il ne termine pas toujours.
il y a des causes possibles de non terminaison, qui se regroupent en deux catégories : ``largeur'' infinie, ``profondeur'' infinie. Pour éviter une ``largeur'' infinie,
il faut que pour un séquent donné, le nombre d'instances dont il est conclusion soit fini.
En ce qui concerne le problème de ``profondeur'' dû à la récursivité, on peut souvent
%associer à chaque séquent une valeur dans un ensemble bien ordonné, de sorte que pour toute instance de règle, les valeurs associées aux prémisses sont toutes strictement inférieures à celle associée à la conclusion. 
munir les séquents d'un ordre bien fondé, de sorte que pour toute instance de règle, les prémisses sont toutes strictement inférieures à la conclusion.
%Comme on le verra, la propriété de la sous-formule est bien pratique pour cela.
%La propriété de la sous-formule qu'on verra plus loin est bien pratique pour cela.
%associer à chaque séquent un entier positif, de sorte que pour toute instance de règle, les entiers associés aux prémisses sont tous strictement inférieurs à celui associé à la conclusion. Comme on le verra, la propriété de la sous-formule est bien pratique pour cela.

\

\noindent
\textit{Remarque : la règle de coupure.}
La règle de coupure, par exemple pour \LJ\ : ${\LJcut,}$ rend l'algorithme proposé inutilisable parce qu'il ne termine jamais. En effet, on explore indéfiniment en ``largeur'', car le nombre d'instances dont un séquent donné est conclusion est infini, $A$ pouvant être n'importe quelle formule. Heureusement, cette règle est souvent non nécessaire. De nombreux calculs la formulent car c'est une bonne chose que l'implication représentée par un séquent soit transitive, mais s'en passent ensuite grâce à un \emph{théorème d'élimination de la coupure} (souvent difficile à établir). Quoi qu'il en soit, on ne s'intéresse désormais qu'à des calculs dans lesquels cette règle n'est pas énoncée.

\subsection{Propriétés intéressantes des calculs de séquents}

\subsectionDescription{
%Remarque : la règle de coupure.
Absence de contraction.
Propriété de la sous-formule.
Inversibilité de certaines règles ou prémisses.
Localité des règles.
}

%Nous présentons %l'algorithme générique, puis 
%quelques propriétés sur les calculs de séquents
%qui sont intéressantes pour assurer la terminaison et améliorer la complexité de l'algorithme qui leur est associé.

Un calcul de séquents peut présenter certaines des propriétés suivantes, qui contribuent à assurer la terminaison ou améliorer la complexité de l'algorithme précédent.

\

\noindent
\textbf{Absence de contraction.}
%Les règles de duplication, par exemple 
Certaines règles, comme la contraction à gauche de \LJ\ : 
%
%\noindent
\linebreak
${\LJcontraction}$, sont problématiques pour la terminaison de l'algorithme. En effet, pour essayer de prouver $\G,A\To D$, on peut être amené à essayer de prouver $\G,A,A\To D$, puis en appliquant encore la même règle à essayer de prouver $\G,A,A,A\To D$, et ainsi de suite, sans fin. 
%On parle de duplication car au cours de notre recherche de preuve, on passe de la conclusion à la prémisse en dupliquant la formule $A$. 
Il est parfois possible d'adapter l'algorithme à une possibilité de contraction en prenant certaines précautions, comme on le verra pour le calcul \LJ.
%Il est tout de même possible d'adapter l'algorithme à une duplication dans certains cas, comme on le verra pour le calcul \LJ.

\

\noindent
\textbf{Propriété de la sous-formule.}
La formule $B$ est une \textbf{\emph{sous-formule}} de la formule $A$ si $B$ est égale à $A$ ou si $A$ est de la forme $A_{1}\diamond A_{2}$ où $\diamond$ est un connecteur et [$B$ est une sous-formule de $A_{1}$ ou $B$ est une sous-formule de $A_{2}$]. Un calcul de séquents vérifie la \textbf{\emph{propriété de la sous-formule}} si tout séquent prouvable $\s$ admet une preuve telle que toute formule apparaissant dans (un séquent de) cette preuve est une sous-formule d'une formule de $\s$. 
%En particulier, le séquent $\To A$ a une preuve dans laquelle toute formule est une sous-formule de $A$.
%
La propriété de la sous-formule est très utile pour un calcul de séquents. 
%Souvent, le calcul présente une propriété un peu plus forte, qui assure la terminaison de l'algorithme : toutes les règles sont des règles logiques où on passe de la conclusion aux prémisses en rempla\c cant une formule principale d'une forme donnée par une ou plusieurs sous-formules strictes. Dans ce cas
Souvent, elle fait partie des arguments qui permettent de montrer la terminaison. Elle fournit en effet un ordre bien fondé sur les formules, qu'il reste à étendre de fa\c con bien choisie aux séquents.
%Elle permet de montrer assez facilement la terminaison de l'algorithme dans le cas où toutes les règles sont des règles logiques : on remplace une formule d'une forme donnée dans la conclusion par des
%
%La propriété de la sous-formule
Elle est également utile lors de l'implémentation : si on veut appliquer la recherche de preuve à un séquent donné, on peut connaître à l'avance la liste exhaustive de toutes les formules susceptibles d'apparaître. On peut donc effectuer une indexation préliminaire, puis représenter les formules par des objets de taille constante, par exemple des entiers, au lieu d'arbres qui peuvent être coûteux en mémoire. Voir la sous-section ? pour un exemple détaillé d'une telle indexation.

\

\noindent
\textbf{Inversibilité de certaines règles ou prémisses.}
Dans l'algorithme proposé, il peut être assez long de montrer qu'un séquent n'est pas prouvable, puisqu'on essaie toutes les instances dont il est la conclusion. La notion d'inversibilité permet de terminer beaucoup plus rapidement dans certains cas. 
Une prémisse $prem_{i}$ d'une règle\regle(aussi appelée \emph{$i$-ème prémisse de $\mathcal R$}) est \textbf{\emph{inversible}} si on a : si $prem_{i}$ est non prouvable, alors $concl$ est non prouvable. Une règle est \textbf{\emph{inversible}} si toutes ses prémisses sont inversibles. Ainsi, si au cours de la recherche de preuve, on obtient qu'une prémisse inversible est non prouvable, on peut directement conclure que la conclusion ne l'est pas non plus, sans avoir besoin d'essayer d'autre règle.

\

\noindent
\textbf{Localité des règles.} 
L'algorithme nécessite de savoir déterminer, pour un séquent donné, toutes les instances dont il est conclusion, et en particulier calculer les prémisses de ces instances. 
Pour une instance, la \emph{formule principale} est la formule de la conclusion qui est remplacée dans les prémisses par d'autres formules (règles logiques ; la formule doit alors avoir une forme particulière, par exemple présenter un connecteur donné) ou dupliquée ou supprimée (règles structurelles).
Souvent, pour une conclusion et une règle données et un choix de formule principale autorisé par la règle, il existe une unique instance correspondante, dont on peut facilement calculer toutes les prémisses.
%
Parfois, on a aussi le sens inverse : à partir de la $k$-ième prémisse, si on connaît la règle et le numéro $k$ et la formule principale, on peut construire la conclusion. On dit qu'une règle est \textbf{\emph{locale}} si on a cette dernière propriété pour toutes les prémisses de toutes ses instances.
%
Si toutes les règles sont locales (et si on cherche juste à décider si un séquent est prouvable sans demander d'arbre de preuve le cas échéant), alors on peut ne garder qu'un seul séquent en mémoire à tout moment, plus des informations (numéro de prémisse, formule principale) qui sont moins coûteuses. %C'est donc plus efficace en terme de complexité spatiale.
Lorsque qu'on s'intéresse à une instance dont le séquent retenu est conclusion, on transforme ce séquent en une prémisse, sur laquelle on relance l'algorithme. Et inversement, on a parfois besoin de revenir à la conclusion à partir d'une prémisse et des informations supplémentaires retenues : par exemple pour ensuite calculer une autre prémisse de l'instance, ou encore pour essayer d'appliquer une autre règle à la conclusion si on a trouvé une prémisse non prouvable et non inversible.
Ainsi, si toutes les règles du calcul sont locales, on peut améliorer la complexité spatiale de l'algorithme.

%L'algorithme nécessite de savoir déterminer, pour un séquent donné, toutes les instances dont il est conclusion, et en particulier calculer les prémisses de ces instances. Pour une instance, la \emph{formule principale} est la formule de la conclusion qui joue un rôle particulier : elle est remplacée dans les prémisses par une ou plusieurs formules plus simples (règles logiques ; dans ce cas la formule doit avoir une forme particulière, par exemple présenter un connecteur donné), ou dupliquée ou supprimée (règles structurelles). Sous certaines conditions (notamment, absence de règle de coupure) souvent vérifiées, on peut facilement calculer, à partir d'une conclusion donnée et d'une règle et d'un choix de formule principale %adaptée à 
%autorisé par la règle, toutes les prémisses de la seule instance correspondante. Mais ce n'est pas tout. Lorsqu'on s'intéresse à une prémisse, on risque d'avoir à nouveau besoin plus tard de la conclusion, par exemple pour calculer une autre prémisse, ou essayer une autre instance s'il y a une prémisse non inversible non prouvable.
%%
%Une solution consiste à retenir la conclusion pendant qu'on effectue la recherche de preuve sur les différentes prémisses, mais cela peut être coûteux en mémoire. Une autre solution est possible si on sait retrouver la conclusion à partir de n'importe quelle prémisse et %d'informations moins coûteuses : le 
%du numéro de la prémisse concernée et de la formule principale. Une règle dont toutes les instances vérifient ce qui précède est dite \textbf{\emph{locale}}. Si toutes les règles sont locales, on peut ne garder qu'un seul séquent en mémoire à tout moment, plus des informations (numéro de prémisse et formule principale) qui sont moins coûteuses. C'est donc plus efficace en terme de complexité spatiale.





\subsection{Deux exemples de calculs de séquents pour la logique intuitionniste}

%\subsectionDescription{
%LJ.
%LJT.
%}
%\subsectionDescription{LJLJT}

\noindent
\textbf{\LJ.}
%Le calcul \LJ\ présenté dans la première partie %peut difficilement être appliqué à une recherche automatique de preuve tel quel.
%a besoin de quelques ajustements pour pouvoir être appliqué à la recherche automatique de preuves
Pour appliquer le calcul \LJ\ présenté dans la première partie à la recherche automatique de preuves, il faut quelques ajustements sur le calcul lui-même et sur l'algorithme proposé. Il faut notamment enlever la règle de coupure (figure~\ref{fig:reglesLJ}, \emph{cut}), ce qui est possible car le calcul reste évidemment correct, mais surtout complet. Pour la même raison, on peut aussi enlever la règle \emph{weakening}. En revanche, on ne peut pas supprimer purement et simplement la règle\LJcontraction. On ne pourrait 
%en effet 
par exemple
plus prouver la formule %bien connue 
${\lnot\lnot(A\lor\lnot A)}$%, dont une preuve est donnée en figure ?
.
%\ (voir figure~\ref{fig:LJnnTiersExclu}). 
Mais comme on l'a vu, cette règle pose un problème de terminaison de l'algorithme. Une solution consiste à remplacer les deux règles $contraction\ L$ et \LJimpL\ par une seule règle \LJimpLcontr. On n'a alors plus d'appels récursifs sur des séquents strictement croissants $\G,A\To D$ puis $\G,A,A\To D$ puis $\G,A,A,A\To D$ etc. En revanche, on peut avoir un appel récursif sur un séquent déjà rencontré, par exemple si $D=A$, une prémisse est identique à la conclusion dans \LJimpLcontrA. On ajoute alors un système de détection de cycles en retenant tous les séquents rencontrés. L'algorithme obtenu est correct et termine. On a la propriété de la sous-formule. Les règles sont toutes inversibles et locales sauf $\to L$, dont seule la deuxième prémisse est inversible. Mais la détection de cycles est très coûteuse.

%\begin{figure}[h]
%\centering
%\LJnnTiersExclu
%
%\caption{Preuve dans \LJ\ de $\lnot\lnot(A\lor\lnot A)$% : on a besoin de la règle $contraction\ L$
%. Sans la règle $contraction\ L$, le séquent surligné serait $\;\To A\lor\lnot A$ qui n'est pas prouvable.
%}
%\label{fig:LJnnTiersExclu}
%\end{figure}

\

\noindent
\textbf{\LJT.}
Le calcul \LJT\ est introduit par R. Dyckhoff dans \cite{LJT} pour pallier le problème de cycles de \LJ. Il n'y a pas de règle de contraction, et la règle $\to L$ est remplacée par quatre règles selon la structure de $A$ dans la formule principale $A\to B$ : par exemple \LJTimpLun où $A$ doit être %\emph{atomique} c'est-à-dire 
réduite à une variable, ou encore \LJTimpLdeux. On n'a pas la propriété de la sous-formule, mais on peut quand même déterminer toutes les formules susceptibles d'apparaître lorsqu'on essaie de prouver un séquent donné. Dyckhoff montre que l'algorithme termine en choisissant bien un bon ordre sur les formules puis sur les séquents. Toutes les règles sont inversibles et locales sauf une des règles qui remplacent $\imp L$, qui comporte deux prémisses dont seule la deuxième est inversible.




%%%%%


\section{Le calcul de séquents utilisé pour l'implémentation : \LSJ, légèrement modifié en \LSJn}

Le calcul de séquents utilisé pour l'implémentation est \LSJn, une variante de \LSJ. Le calcul \LSJ\ est présenté par M. Ferrari, C. Fiorentini et G. Fiorino dans \cite{LSJ}. Il présente des priopriétés très intéressantes pour l'application à la recherche de preuve. \LSJn\ est fondamentalement le même calcul, %où les séquents sont représentés
avec une représentation des séquents un peu plus riche en informations. Il a été proposé par mon maître de stage D. Larchey-Wendling. \LSJn\ hérite de toutes les bonnes propriétés de \LSJ, en ajoutant la localité des règles.

%

\subsection{Séquents et règles de \LSJ}

%L'article \cite{LSJ} définit le calcul de séquents \LSJ. Une sémantique naturelle des séquents est proposée à l'aide des modèles de Kripke, mais nous ne la présentons pas. En effet, ce qui nous intéresse est l'existence, pour toute formule, d'un séquent qui est prouvable dans le calcul \LSJ\ si, et seulement si, la formule est prouvable en logique intuitionniste. Nous renvoyons à l'article pour les démonstrations, notamment celles de la correction et de la complétude du calcul.



\begin{df}
Un \textbf{\emph{séquent}} de \LSJ\ est la donnée de trois multiensembles $\Th$, $\G$ et $\D$ de formules ; on écrit $\Th\;;\;\G\;\To\;\D$.
\end{df}


%On a vu que dans \LJ, le séquent représente ... et dans \LK,
On a vu que dans les calculs \LK\ et \LJ, le séquent $\G \To \D$ représente la formule ${\left(\bigwedge_{G\in\G}G\right)\to\left(\bigvee_{D\in\D}D\right)}$, respectivement en logique classique et en logique intuitionniste, avec $\D$ contenant exactement une formule pour \LJ. C'est une interprétation courante en calcul de séquents. Pour \LSJ, on ne sait pas représenter un séquent $\Th\,;\,\G\To\D$ par une seule formule.
%Une sémantique pour les séquents
On a cependant le résultat suivant : un séquent $\varnothing\,;\,\G\To\D$ est prouvable dans \LSJ\ si et seulement si la formule ${\left(\bigwedge_{G\in\G}G\right)\to\left(\bigvee_{D\in\D}D\right)}$ est prouvable en logique intuitionniste.
$\G$ et $\D$ ont donc une signification ordinaire.
En revanche, $\Th$ est propre à \LSJ, et difficile à interpréter. On peut dire que $\Th$ contient des formules gardées en réserve, non accessibles directement (une formule de $\Th$ ne peut pas être \emph{formule principale}), mais qui peuvent être transférées dans $\G$ et ainsi devenir accessibles. On verra que les seules règles qui agissent sur $\Th$ sont celles qui concernent le connecteur $\to$.
L'article \cite{LSJ} propose bien une interprétation du séquent $\Th\;;\;\G\;\To\;\D$ pour $\Th$ quelconque, en utilisant des modèles de Kripke. Nous ne la détaillons pas, car ce qui nous intéresse surtout est la propriété suivante qui découle du résultat énoncé sur un séquent avec $\Th$ vide.
%Une interprétation du séquent $\Th\;;\;\G\;\To\;\D$ pour $\Th$ quelconque est 


%\
%La définition d'un séquent \emph{prouvable} est celle qui a été donnée en \ref{ProuvabiliteSequent} pour le calcul \LJ.
%La définition d'un séquent \emph{prouvable} a été donnée en \ref{ProuvabiliteSequent}.

%\begin{prop}\label{propSignificationSequent}
%%Soit $\G$, $\D$ des multiensembles de formules. Le séquent $\emptyset\;;\;\G\;\To\;\D$ est \textbf{prouvable} dans \LSJ, c'est-à-dire non réfutable, si et seulement si la formule $\bigwedge_{A\in\G}A\,\to\,\bigvee_{B\in\D}B$ est valide en logique intuitionniste.
%Un séquent $\emptyset\;;\;\G\;\To\;\D$ est \textbf{réfutable} si, et seulement si, la formule $\bigwedge_{A\in\G}A\,\to\,\bigvee_{B\in\D}B$ n'est pas valide en logique intuitionniste. Un séquent est \textbf{prouvable} dans \LSJ\ si, et seulement si, il n'est pas réfutable.
%\end{prop}

\begin{prop}
Soit $A$ une formule, elle est valide en logique intuitionniste si et seulement si le séquent $\emptyset;\emptyset\To A$ est  prouvable dans \LSJ.
\end{prop}

\def\mywidth{0.6\textwidth}
\begin{floatingfigure}[r]{\mywidth}
\centering

\resizebox{\mywidth}{!}{

$\begin{array}{cc}
	\LSJfauxL & \Id \\\\
	\LSJetL & \LSJetR \\\\
	\LSJouL & \LSJouR \\\\
	\multicolumn{2}{c}{\LSJimpL}\\\\
	\multicolumn{2}{c}{\LSJimpR}
\end{array}$

}

\caption{Les règles du calcul \LSJ}
\label{fig:reglesLSJ}
\end{floatingfigure}

Les \textbf{\emph{règles}} du calcul \LSJ\ sont données dans la figure~\ref{fig:reglesLSJ}. Toutes les règles sont des \emph{axiomes} ou des \emph{règles logiques}. Il n'y a pas de \emph{règle structurelle} ni de règle de \emph{coupure}.

\

\noindent
\textbf{Propriétés de \LSJ.}
(Pour les \\démonstrations, voir \cite{LSJ}.)
Le calcul \LSJ\ est sans contraction et vérifie la propriété de la sous-formule.
L'algorithme décrit dans la deuxième partie termine pour \LSJ.
Les règles $\land L$, $\land R$, $\lor L$ et $\lor R$ sont inversibles ;
les deux premières prémisses de ${\imp L}$ et la première prémisse de ${\imp R}$ sont inversibles ;
la troisième prémisse de ${\imp L}$ et la deuxième prémisse de ${\imp R}$ ne sont pas inversibles.

%On remarque que les règles $\land L$, $\land R$, $\lor L$ et $\lor R$ sont locales. En revanche, les règles $\to L$ et $\to R$ ne sont pas locales : pour chacune, les formules représentées par $\D$ dans la conclusion n'apparaissent nulle part dans la dernière prémisse, il n'est donc pas possible de retrouver la conclusion en connaissant uniquement cette prémisse, la formule principale et le numéro de la prémisse, puisqu'il n'y a aucun moyen d'en déduire ce qui se trouve dans $\D$. C'est pour cette raison qu'on introduit le calcul \LSJn, dans lequel toutes les règles sont locales.

\

\noindent
\textbf{Non localité de certaines règles.}
Les règles $\to L$ et $\to R$ ne sont pas locales : pour chacune, les formules représentées par $\D$ dans la conclusion n'apparaissent nulle part dans la dernière prémisse, il n'est donc pas possible de retrouver la conclusion en connaissant uniquement cette prémisse, la formule principale et le numéro de la prémisse, puisqu'il n'y a aucun moyen d'en déduire ce qui se trouve dans $\D$. C'est pour cette raison qu'on introduit le calcul \LSJn, dans lequel toutes les règles sont locales.


%

\subsection{Séquents et règles de \LSJn}

Le calcul \LSJn\ est très proche du calcul \LSJ : chaque règle de \LSJn\ est l'adaptation directe d'une règle de \LSJ\ à une autre structure des séquents. Contrairement à \LSJ, les règles de \LSJn\ sont toutes locales.
Pour cela, les séquents de \LSJn\ représentent chacun un séquent de \LSJ, avec un peu plus d'informations : celles qui sont parfois nécessaire pour retrouver la conclusion à partir d'une prémisse. Cette représentation est exhaustive et correcte. On définit en effet une surjection $\surj$ de l'ensemble des séquents de \LSJn\ dans l'ensemble des séquents de \LSJ, et on montre dans la sous-section suivante qu'un séquent de \LSJn\ est prouvable dans \LSJn\ si, et seulement si, son image par $\surj$ est prouvable dans \LSJ.

\begin{df}
Un \textbf{\emph{séquent}} de \LSJn\ est la donnée de deux multiensembles $\Gp$ et $\Dp$ de couples $entier\,:\,formule$, et d'un entier naturel $n$, tels que tous les entiers présents dans $\Gp$ sont $\leq n+1$ et tous ceux présents dans $\Dp$ sont $\leq n$ ; on écrit $\Gp \Rightarrow_{n} \Dp$.
\end{df}

\noindent
\textbf{Lien avec les séquents de \LSJ\ : l'application $\surj$.}
Soit $M$ un multiensemble de couples $entier\,:\,formule$, l'entier d'un couple étant appelé son indice. On note $M_{k}$ le multiensemble obtenu à partir de $M$ en ne gardant que les couples d'indice $k$, et $M_{\leq k}$ celui obtenu en ne gardant que les couples d'indice inférieur à $k$. On note $\forget(M)$ le multiensemble de formules obtenu en oubliant l'indice et ne gardant que la formule de chaque couple de $M$.
On définit l'application $\surj$ de 
l'ensemble des séquents de \LSJn\ dans l'ensemble des séquents de \LSJ
%$\Sig'$ dans $\Sig$
, qui à $\G' \To_{n} \D'$ associe $\Th\, ;\G \To \D$ %\quad 
\noindent
où~:~
$\left\{
\begin{array}{l}
%	\Th = \{ A \:|\: n+1:A \in \G'\} \\
%	\G = \{ A \:|\: \exists i\leq n,\ i:A \in \G'\} \\
%	\D = \{ A \:|\: n:A \in \D'\}
	\Th = \forget (\G'_{n+1}) \\
	\G = \forget (\G'_{\leq n}) \\
	\D = \forget (\D'_{n})
\end{array}
\right.$.
C'est une \textbf{surjection} : en effet tout séquent $\Th \,;\G\To\D$ de \LSJ\ a au moins pour antécédent le séquent $\G' \To_{0} \D'$, 
%avec $\G' = \{ 0:A \:|\: A \in \G\} \cup \{ 1:A \:|\: A \in \Th\}$ et $\D' = \{ 0:A \:|\: A \in \D\}$.
où $\G'$ est l'union de $0 : \G$ (le multiensemble de couples obtenu à partir de $\G$ en rempla\c cant chaque occurrence d'une formule $A$ par une occurrence du couple $0:A$) avec $1:\Th$, et où $\D'=0:\D$.



\def\mywidthbis{0.79\textwidth}%0.79
\begin{floatingfigure}[r]{\mywidthbis}
\centering

\resizebox{\mywidthbis}{!}{

%\emph{$n$ et parfois $i$ désignent toujours des entiers naturels, avec $i\leq n$}

$\begin{array}{cc}
	\multicolumn{2}{c}{\emph{$n$ et parfois $i$ désignent toujours des entiers naturels, avec $i\leq n$}} \\\\
	\LSJLfauxL & \Id \\\\
	\LSJLetL & \LSJLetR \\\\
	\LSJLouL & \LSJLouR \\\\
	\multicolumn{2}{c}{\LSJLimpL}\\\\
	\multicolumn{2}{c}{\LSJLimpR}
\end{array}$

}

\caption{Les règles du calcul \LSJn}
\label{fig:reglesLSJn}
\end{floatingfigure}

\

Les \textbf{\emph{règles}} du calcul \LSJn\ sont données dans la figure~\ref{fig:reglesLSJn}. Chacune correspond à une règle de \LSJ.

\

\LSJn\ présente les mêmes propriétés que \LSJ, auxquelles s'ajoute la localité de toutes les règles.

\

%

\subsection{\'Equivalence entre \LSJn\ et \LSJ}

On note $\Sig$ l'ensemble des séquents de \LSJ, et $\Sig'$ l'ensemble des séquents de \LSJn.
Soit $\sigma\in\Sig$, on note $\vdash\sigma$ si $\sigma$ est prouvable dans \LSJ\ ; soit $\sigma'\in\Sig'$, on note $\vdash'\sigma'$ si $\sigma'$ est prouvable dans \LSJn.
Montrons que pour tous $\s\in\Sig$ et $\s'\in\Sig'$ tels que $\s=\surj(\s')$, on a $\vdash\s$ si et seulement si $\vdash\s'$, où $\surj$ est la surjection de $\Sig'$ sur $\Sig$ définie précédemment.

Soit $\mathcal R$ une règle de \LSJ. On note $\mathcal R'$ la règle de \LSJn\ qui lui correspond. On écrit \instanceR\ et \instanceRp\ des instances de ces règles.

\begin{lm}
Soit $\sigma\in\Sig$ et $\sigma'\in\Sig'$ tels que $\sigma=\surj(\sigma')$ et soit $\mathcal R$ une règle de \LSJ.

1) Si \instanceR alors il existe $\s'_{1}$, ... , $\s'_{p}$ tels que pour tout $k$, $\s_{k} = \surj (\s'_{k})$, et \instanceRp.

2) Si \instanceRp, posons pour tout $k$, $\s_{k} = \surj (\s'_{k})$, alors \instanceR.

\noindent
Pour un axiome $\mathcal A$, cela signifie simplement : \instanceAx si et seulement si \instanceAxp.
\end{lm}

\begin{dem}
On le montre pour chaque règle ; c'est une conséquence assez directe de la définition de $\surj$. Faisons-le par exemple pour Id et $\to\negthickspace L$. \`A chaque fois, on se donne $\s = \Th\, ;\G \To \D$ et $\s' = \G' \To_{n} \D' \in\Sig'$ tels que $\s=\surj(\s')$.

%\noindent
\textbf{Id}: \quad On a\instanceId\ si et seulement s'il existe une formule $A$ appartenant à la fois à $\G$ et $\D$, ce qui équivaut, par définition de $\surj$, à : il existe $A$ et $i\leq n$ tels que $n:A\in\D'$ et $i:A\in\G'$, c'est-à-dire \instanceIdp.


%\noindent 
%$\boldsymbol\land \boldsymbol R$ :	\quad
%%
%1) Si \instanceetR\ alors il existe des formules $A$ et $B$ et un multiensemble $\Dt$ tels que $\D = A \land B, \Dt$ et $\s_{1} = \Th\, ;\G \To A,\Dt$ et $\s_{2} = \Th\, ;\G \To B,\Dt$.
% Posons $\Dt' = \D' - n:A \land B$ le multiensemble obtenu en retirant une seule occurrence de $n:A\land B$ à $\D'$ (qui contient cet élément parce que $\D$ contient $A\land B$ et par définition de $\surj$),
% et $\s'_{1} = \G' \To_{n} n:A,\Dt'$ et $\s'_{2} = \G' \To_{n} n:B,\Dt'$.
% Alors on a bien $\s_{1}=\surj(\s'_{1})$ et $\s_{2}=\surj(\s'_{2})$ (en remarquant que 
% %$\Dt = \{ C \:|\: n:C \in \Dt'\}$
%$\Dt = \forget (\Dt'_{n})$
%), et \instanceetRp (en remarquant que $\s' = \G' \To_{n} n:A \land B,\Dt'$).
%%
%\quad2)~
%Si \instanceetRp\ alors il existe $A$, $B$ et $\Dt'$ tels que $\D' = n:A \land B, \Dt'$ et $\s'_{1} = \G' \To_{n} n:A,\Dt'$ et $\s'_{2} = \G' \To_{n} n:B,\Dt'$ ; 
% on pose $\Dt = \D - A \land B$ le multiensemble obtenu en retirant une seule occurrence de $A\land B$ à $\D$,
% et $\s_{1}=\surj(\s'_{1})$ et $\s_{2}=\surj(\s'_{2})$ ; on obtient $\s = \Th\, ;\G \To A\land B,\Dt$ et $\s_{1} = \Th\, ;\G \To A,\Dt$ et $\s_{2} = \Th\, ;\G \To B,\Dt$\; d'où\instanceetR.

%\noindent 
$\boldsymbol\to \negthickspace \boldsymbol L$ :	\quad
%
1) Si \instanceimpL\ alors il existe $A$, $B$ et $\Gt$ tels que $\G=A\to B,\Gt$ et $\s_{1} = \Th\, ;B,\Gt \To \D$ et $\s_{2} = B,\Th\, ;\Gt \To A,\D$ et $\s_{3} = B \,; \Th,\Gt \To A$ ; et il existe $i\leq n$ tel que $i:A\to B\in\G'$. On pose $\Gt' = \G' - i:A\to B$ (on retire une seule occurrence de $i:A\to B$ de $\G'$) et $\s'_{1} = i:B,\Gt' \To_{n} \D'$ et $\s'_{2} = n+1:B,\Gt' \To_{n} n:A,\D'$ et $\s'_{3} = n+2:B,\Gt' \To_{n+1} n+1:A, \D'$ et on vérifie qu'on a bien
$\s_{1}=\surj(\s'_{1})$ et $\s_{2}=\surj(\s'_{2})$ et $\s_{3}=\surj(\s'_{3})$ (en remarquant que 
$\Gt = \forget (\Gt'_{\leq n})$
), et aussi\instanceimpLp).
\linebreak
%
\quad2)~
Si \instanceimpLp\ alors il existe $i$, $A$, $B$ et $\Gt'$ tels que $\G'=i:A\to B,\Gt'$ et $\s'_{1}$, $\s'_{2}$ et $\s'_{3}$ ont la forme donnée ci-dessus ; on pose $\Gt = \G - A\to B$ (on retire une seule occurrence de $A\to B$ de $\G$), alors les images $\s_{1}$, $\s_{2}$ et $\s_{3}$ par $\surj$ de $\s'_{1}$, $\s'_{2}$ et $\s'_{3}$ respectivement s'écrivent comme ci-dessus et donc ${\instanceimpL.}$
\end{dem}



\begin{theo}
Soit $\sigma\in\Sig$ et $\sigma'\in\Sig'$ tels que $\sigma=\surj(\sigma')$, alors $\vdash \sigma$ si et seulement si $\vdash' \sigma'$.
%Soit $\sigma$ un séquent de \LSJ\ et $\sigma'$ un séquent de \LSJn\ tels que $\sigma=\surj(\sigma')$, alors $\vdash \sigma$ si et seulement si $\vdash' \sigma'$.
\end{theo}

\begin{dem}
Par récurrence sur la \emph{taille} de $\s\in\Sig$, c'est-à-dire la somme des tailles des formules des trois multiensembles apparaissant dans $\s$.

\

\noindent
On initialise pour tout $\sigma = \Th\, ;\G \To \D$ tel que toutes les formules dans $\G$ et dans $\D$ sont atomiques : soit $\sigma' = \G' \To_{n} \D' \in\Sig'$ tel que $\sigma=\surj(\sigma')$. Alors toutes les formules associées à un $i \leq n$ dans $\G'$ et toutes les formules associées à $n$ dans $\D'$ sont aussi atomiques. En étudiant la forme des conclusions des règles non axiomatiques de \LSJ\ comme de \LSJn,
on remarque que si $\s$ (resp. $\s'$) est la conclusion d'une règle de \LSJ\ (resp. \LSJn), alors la règle est un axiome. L'initialisation est donc un cas particulier de ce qui suit avec $p=0$ (ce qui entraîne qu'on n'utilise en fait pas l'hypothèse de récurrence).

% on obtient que : $\vdash \s$ si et seulement si $\s$ est une conséquence directe d'un axiome de \LSJ, et $\vdash' \s'$ si et seulement si $\s'$ est une conséquence directe d'un axiome de \LSJn. Or d'après le lemme, pour $\mathcal A$ axiome de \LSJ, \instanceAx si et seulement si \instanceAxp. On en déduit $\vdash \sigma$ si et seulement si $\vdash' \sigma'$.

\

\noindent
Soit $\s = \Th\, ;\G \To \D \in\Sig$. Soit $\sigma' = \G' \To_{n} \D' \in\Sig'$ tel que $\sigma=\surj(\sigma')$.

On suppose $\vdash \s$. Alors il existe une règle $\mathcal R$ de \LSJ\ et $\s_{1}$, ... , $\s_{p} \in\Sig$ (avec éventuellement $p$ nul) tels que $\vdash \s_{k}$ pour tout $k$ et\instanceR. D'après le lemme, il existe $\s'_{1}$, ... , $\s'_{p} \in\Sig'$ tels que $\s_{k}=\surj(\s'_{k})$ pour tout $k$ et\instanceRp. Pour tout $k$, on applique l'hypothèse de récurrence à $\s_{k}$ qui a une \emph{taille} strictement inférieure à celle de $\s$, et on obtient $\vdash' \s'_{k}$. On en déduit $\vdash' \s'$.

On suppose $\vdash' \s'$. Alors il existe une règle $\mathcal R'$ de \LSJn\ et $\s'_{1}$, ... , $\s'_{p} \in\Sig'$ tels que $\vdash' \s'_{k}$ pour tout $k$ et\instanceRp. On pose $\s_{k}=\surj(\s'_{k})$ pour tout $k$. D'après le lemme on a \instanceR, en particulier on peut appliquer l'hypothèse de récurrence aux $\s_{k}$ donc $\vdash \s_{k}$ pour tout $k$, d'où $\vdash \s$.

\end{dem}



%%%%%

\pagebreak

\section*{Efficacité de \LSJ}


L'étude qui suit porte sur le calcul \LSJ. En effet, \LSJn\ hérite de toutes les propriétés intéressantes de \LSJ, en apportant une localité des règles qui facilite une implémentation économe en mémoire.


\subsection{Propriété de la sous-formule et indexation}

$B$ est une \textbf{sous-formule} de $A$ si $B=A$ ou si $A$ est de la forme $A_{1}$`connecteur'$A_{2}$ et ($B$ est une sous-formule de $A_{1}$ ou $B$ est une sous-formules de $A_{2}$). Un calcul de séquents vérifie la \textbf{propriété de la sous-formule} si tout séquent prouvable $\s$ admet une preuve telle que toute formule apparaissant dans (un séquent de) la preuve est une sous-formule d'une formule de $\s$. En particulier, le séquent $\To A$ a une preuve dans laquelle toute formule est une sous-formule de $A$.

Le calcul \LSJ vérifie la propriété de la sous-formule : on le constate aisément en observant chaque règle.

La propriété de la sous-formule est très recherchée en calcul des séquents. D'une part, elle donne une borne sur les formules qu'il faudra manipuler au cours d'une recherche de preuve, qui sont évidemment toutes plus petites que la formule qu'on essaie de prouver. Mais surtout, elle permet de connaître à l'avance la liste exhaustive des formules qu'on pourra rencontrer. On peut donc à l'avance les numéroter : ainsi, les formules d'un séquents sont simplement représentées par un entier. Il faut quelques informations sur ces numéros : par exemple pour une formule $A\land B$, il faut savoir qu'il s'agit d'un ``et'', et pouvoir déterminer $A$ et $B$. Il faut aussi pouvoir reconnaître quand l'axiome Id (une même formule apparaît des deux côtés du séquent) s'applique : pour cela on associe à chaque formule une classe, qui correspond à une classe d'équivalence de la relation d'égalité structurelle. La taille de toutes ces informations réunies est linéaire en la taille de la formule de départ (c'est-à-dire le nombre de n\oe uds de l'arbre qui la représente, qui est aussi le nombre de sous-formules avec multiplicité). Un exemple est donné par la figure~\ref{fig:indexation}.

La propriété de la sous-formule est encore plus intéressante dans le cadre de la recherche de preuve compilée : connaître à l'avance les formules qui apparaîtront permet d'écrire pour chacune des fonctions agissant sur le séquent, au lieu de les calculer au cours de la recherche de preuve (voir ??).

\begin{figure}[h]
%\centering
\includegraphics[width=0.3\linewidth]{indexation} %Quelques_formules.f12
\caption{Indexation de la formule $(a\land b)\land(\lnot c \lor (a\land b))$}
\label{fig:indexation}
\end{figure}

%\subsection{Absence de duplication}
%
%
%\
%
%\
%\subsection{Inversibilité de certaines prémisses de $\to L$ et $\to R$}
%
%
%$((\bigwedge_{i=1}^{n}p_{i} \lor (\lnot\lnot p_{1}\to f) \lor \bigvee_{i=2}^{n}(p_{i}\to f))\to f)\to f$
%
%\
%
%$(\;[ \;(p_{1}\land p_{2} \land ... \land p_{n}) \lor (\lnot\lnot p_{1}\to f) \lor (p_{2}\to f) \lor ... \lor (p_{n}\to f)\;]\to f\;)\to f$
%
%\
%
%$1:f \quad\To_{0}\quad 0:  p1 \land ( p2 \land p3 )  \;,\; 0: \lnot\lnot p1 \to f  \;,\;  0: p2 \to f  \;,\;  0: p3 \to f  \;,\; 0: f$
%
%\
%
%$f\;;\;\emptyset \quad\To\quad p_{1} \land p_{2} \land ... \land p_{n} \;,\; \lnot\lnot p_{1}\to f \;,\; p_{2}\to f \;,\; ...  \;,\; p_{n}\to f \;,\; f$
%
%
%
%\section{Quelques explications sur l'implémentation}
%
%\subsection{Précalculs : indexation, classes, priorités}
%
%\subsection{Gestion efficace des formules du séquent : insertion et suppression, choix de la formule principale}
%
%
%
%\section{Vers une recherche de preuve compilée et certifiée}
%
%\subsection{Un langage simple pour la certification}
%
%\subsection{Compilation : des fonctions pour chaque sous-formule}
%
%











\section{Implémentation}
\subsection{Indexation}

cf ``Propriété de la sous-formule et indexation'' + explication sur les classes (et priorités) et les champs axiomes du séquent



\subsection{Structure de données pour le séquent}

Au cours de l'algorithme, on manipule un ``séquent'', censé représenter un séquent du calcul \LSJn, contenant les informations suivantes :

\noindent-\;
des informations de taille constante : l'indice $n$ du séquent, et des booléens $id$ et $fauxL$, indiquant si les axiomes de même nom sont applicables au séquent ;

\noindent-\;
les couples \emph{indice}: \emph{formule} contenus dans les champs $\G$ et $\D$ du séquent.

Comme nous l'avons expliqué en introduisant le calcul \LSJn, le but de celui-ci est de pouvoir effectuer la recherche de preuve en ne gardant à chaque instant qu'un seul séquent en mémoire.

\


Intéressons-nous maintenant à la complexité temporelle.

Celle-ci dépend du nombre de règles qu'on essaie d'appliquer, c'est-à-dire le nombre d'appels récursifs à la fonction \emph{prouvable} (?) dont le pseudo-code est donné en figure ? page ?. Ce nombre dépend de la taille de la formule et des connecteurs présents dedans (et selon l'ordre dans lequel on choisit les formules principales cela peut beaucoup varier pour une même formule, mais on s'intéresse à la complexité dans le pire cas). Mais il ne dépend pas de notre choix d'implémentation (sauf pour l'ordre des ``implique'', mais encore une fois pas si on regarde le pire cas).










\bibliographystyle{plain}
\bibliography{LSJn}

\end{document}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
.
\pagebreak

\section{Le calcul \LSJ}

L'article \cite{LSJ} définit un calcul de séquents \LSJ. Une sémantique naturelle des séquents est définie à l'aide des modèles de Kripke, mais nous ne la présentons pas. En effet, ce qui nous intéresse est l'existence, pour toute formule, d'un séquent qui est prouvable dans le calcul \LSJ\ si, et seulement si, la formule est prouvable en logique intuitionniste. Nous renvoyons à l'article pour les démonstrations, notamment celle de la complétude du calcul.

\subsection{Les séquents}

On s'intéresse à des \emph{multiensembles}, c'est-à-dire des collections où le nombre d'occurrences est pris en compte, mais non l'ordre des éléments. Cela permettra de ne pas avoir besoin de règles explicites d'échange.

Un \textbf{séquent} est la donnée de trois multiensembles $\Th$, $\G$ et $\D$ de formules ; on écrit alors $\Th\;;\;\G\;\To\;\D$.

Une définition d'un séquent \textbf{réfutable} est donnée dans l'article à l'aide des modèles de Kripke. Nous ne la détaillons pas ici, car ce qui nous intéresse surtout est la propriété suivante qui en découle, démontrée dans l'article. La définition de \textbf{prouvable} sera donnée plus tard car elle est liée aux règles du calcul, mais ceci illustre son intérêt.
\begin{prop}\label{propSignificationSequent}
%Soit $\G$, $\D$ des multiensembles de formules. Le séquent $\emptyset\;;\;\G\;\To\;\D$ est \textbf{prouvable} dans \LSJ, c'est-à-dire non réfutable, si et seulement si la formule $\bigwedge_{A\in\G}A\,\to\,\bigvee_{B\in\D}B$ est valide en logique intuitionniste.
Un séquent $\emptyset\;;\;\G\;\To\;\D$ est \textbf{réfutable} si, et seulement si, la formule $\bigwedge_{A\in\G}A\,\to\,\bigvee_{B\in\D}B$ n'est pas valide en logique intuitionniste. Un séquent est \textbf{prouvable} dans \LSJ\ si, et seulement si, il n'est pas réfutable.

\end{prop}
\begin{cor}
Soit $A$ une formule, elle est valide en logique intuitionniste si et seulement si le séquent $\emptyset;\emptyset\To A$ est  prouvable dans \LSJ.
\end{cor}

Les multiensembles $\G$ et $\D$, et leur signification dans la propriété \ref{propSignificationSequent} sont des éléments habituels en calcul des séquents. En revanche, $\Th$ est propre à \LSJ, et est difficile à interpréter car contrairement au cas où $\Th$ est vide, un séquent avec $\Th$ quelconque ne peut pas être représenté par une formule. On peut dire est que $\Th$ contient des formules gardées en réserve, non visibles directement dans le séquent (une formule de $\Th$ ne peut pas être \emph{formule principale}), mais qui peuvent être transférées dans $\G$ et ainsi devenir visibles. On verra que les seules règles qui agissent sur $\Th$ sont celles qui concernent le connecteur $\to$.

Pour un séquent $\Th\;;\;\G\;\To\;\D$, on appellera les formules de $\G$ les \textbf{formules de gauche}, celles de $\D$ les \textbf{formules de droite}, et celles de $\Th$ les \textbf{formules de réserve} du séquent (appellations non conventionnelles).

%

\subsection{Les règles}

%Une règle est de la forme\regle où $\mathcal R$ est le nom de la règle, et $prem_{1}$, ... , $prem_{p}$, $concl$ décrivent des séquents d'une certaine forme. Par exemple $\Th\;;\;A\lor B,\G\;\To\;\D$ représente n'importe quel séquent où au moins une des formules de gauche est une disjonction, et si $\Th\;;\;A,\G\;\To\;\D$ se trouve dans la même règle, cela représente un séquent obtenu à partir du précédent en rempla\c cant une disjonction de gauche $A\lor B$ par son premier terme $A$.



Les règles du calcul \LSJ\ sont données dans la figure~\ref{fig:reglesLSJ}. La notation $A,\G$ représente le multiensemble obtenu à partir de $\G$ en ajoutant une occurrence de $A$. Pour une règle \regle, $\mathcal R$ est le nom de la règle, $prem_{1}$, ... , $prem_{p}$ sont les (resp. première, ... , $p$-ième) \textbf{prémisses}, et $concl$ la \textbf{conclusion}. Les \textbf{axiomes} sont les règles sans prémisse. Pour toutes les autres règles, une unique formule apparaît de manière explicite dans la conclusion : c'est la \textbf{formule principale}. Les règles dites de gauche, ou d'introduction à gauche, contenant un $L$ dans leur nom, sont celles où la formule principale se trouve à gauche dans la conclusion, de même pour les règles de droite.

\begin{figure}
\centering

$$\begin{array}{cc}
	\LSJfauxL & \Id \\\\
	\LSJetL & \LSJetR \\\\
	\LSJouL & \LSJouR \\\\
	\multicolumn{2}{c}{\LSJimpL}\\\\
	\multicolumn{2}{c}{\LSJimpR}
\end{array}$$

\caption{Les règles du calcul \LSJ}
\label{fig:reglesLSJ}
\end{figure}


Une \textbf{instance} d'une règle $\mathcal R$ a la même forme que la règle : \instance, mais ici les $\s_{i}$ et $\s$ sont des séquents connus explicitement ; bien entendu il faut qu'il s'agisse de séquents qui ont bien la forme donnée par la définition de la règle. Par exemple \LSJetL\ devient une instance de la règle $\land L$ (qui a la même écriture que la règle) lorsqu'on connaît les formules $A$ et $B$ et toutes les formules de $\Th$, $\G$, $\D$.

Une \textbf{preuve} est un arbre dont les n\oe uds sont étiquetés par un séquent et une règle et ont la même arité que le nombre de prémisses de la règle, et tel que : pour tout n\oe ud de séquent $\s$ et règle $\mathcal R$, si $\s_{1}$, ... , $\s_{p}$ sont les séquents associés à chacun de ses fils respectivement, alors \instance\ est une instance de $\mathcal R$. Les feuilles d'un tel arbre sont les n\oe uds auxquels est associé un axiome.

Un séquent est \textbf{prouvable} s'il existe une preuve à la racine de laquelle il est associé.

De manière équivalente, on peut définir l'ensemble des formules prouvables comme le plus petit ensemble vérifiant : pour toute instance \instance\ d'une règle de \LSJ, si pour tout $i$, $\s_{i}$ est prouvable, alors $\s$ est prouvable (en particulier pour toute instance \instanceAx\ d'un axiome $\mathcal A$, $\s$ est prouvable).



\subsection{Conditions de non-prouvabilité}

Pour montrer qu'un séquent est prouvable, il suffit d'en exhiber une preuve. Comment montrer le contraire ? D'après la définition précédente, un séquent n'est pas prouvable s'il n'existe aucune instance de règle\instance telle que tous les $\s_{i}$ sont prouvables. Or les $\s_{i}$ ne dépendent que de $\s$, $\mathcal R$ et du choix de la formule principale : il est donc possible de tester toutes les instances possibles. Cela fournit un premier algorithme de recherche de preuve : récursivement, pour chercher si un séquent $\s$ est prouvable, on considère toutes les instances de règles dont $\s$ est la conclusion et pour chacune on détermine récursivement si chaque prémisse est prouvable. Si on trouve une instance telle que toutes les prémisses sont prouvables, alors $\s$ est prouvable (et on obtient une preuve de $\s$ si on connaît une preuve de chacune de ces prémisses), sinon $\s$ n'est pas prouvable. Cet algorithme est très long. En fait, c'est à peu près ce qu'on se retrouve à faire dans les cas extrêmement défavorables. Mais heureusement, on a un procédé bien plus économe en moyenne grâce à la notion de règle ou prémisse inversible.

Une prémisse $prem_{i}$ d'une règle\regle(aussi appelée $i$-ème prémisse de $\mathcal R$) est \textbf{inversible} si on a : si $prem_{i}$ est non prouvable, alors $concl$ est non prouvable. Une règle est \textbf{inversible} si toutes ses prémisses sont inversibles.

On admet, une démonstration se trouvant dans l'article \cite{LSJ} :

\noindent- les règles $\land L$, $\land R$, $\lor L$ et $\lor R$ sont inversibles~;

\noindent- les deux premières prémisses de $\to L$ et la première prémisse de $\to R$ sont inversibles~;

\noindent- la troisième prémisse de $\to L$ et la deuxième prémisse de $\to R$ ne sont pas inversibles.



\subsection{Algorithme}


On en déduit le procédé suivant pour essayer d'appliquer une règle à un séquent avec un formule principale donnée : on essaie de prouver les prémisses inversibles, puis l'éventuelle prémisse non inversible (dans \LSJ\ il y en a au plus une). Dès qu'on trouve qu'une prémisse inversible est non prouvable, on s'arrête : le séquent initial n'est pas prouvable non plus. Si toutes les prémisses sont prouvables, le séquent initial est également prouvable. Dans le dernier cas (seule la prémisse non inversible est non prouvable), on essaie une application de règle avec une autre formule principale.

Il ne reste plus qu'à décider dans quel ordre les formules qui peuvent l'être sont choisies comme formule principale pour essayer d'appliquer une règle. On choisit de traiter en premier les règles inversibles, car on sait alors qu'il n'y aura pas besoin d'essayer d'autre application de règle sur le même séquent. 
% : après avoir examiné au pire toutes les prémisses, on sait si le séquent est prouvable.
Parmi celles-ci, on privilégie celles qui n'ont qu'une prémisse ($\land L$ et $\lor R$) sur les autres, qui en ont deux ($\lor L$ et $\land R$).

%L'algorithme est le suivant.

\begin{figure}[!h]
%\centering
\def\true{\emph{vrai}}
\def\false{\emph{faux}}
\def\lett{\textbf{soit }}
\def\if{\textbf{si} }
\def\then{\textbf{alors} }
\def\return{\textbf{retourner} }
\def\select{\textbf{sélectionner} }
\def\from{\textbf{dans} }

\textbf{fonction} estProuvable ($\s$)

\quad \lett $\s=\Th;\G\To\D$

\quad \if ($\bot\in\G$) \then \return \true

\quad \if ($\G\cap\D\neq\emptyset$) \then \return \true

\quad \if ($\G$ et $\D$ ne contiennent que des formules \emph{atomiques}) \then \return \false


\quad \if (il existe $A\land B\in\G$) \then $\{$

\quad \quad \select $H=A\land B$ \from $\G$

\quad \quad \return estProuvable($prem(\land L, \s, H)$)

\quad $\}$


\quad \if (il existe $A\lor B\in\D$) \then $\{$

\quad \quad \select $H=A\lor B$ \from $\D$

\quad \quad \return estProuvable($prem(\lor R, \s, H)$)

\quad $\}$

\quad ...


\caption{Algorithme}
\label{fig:algo}
\end{figure}



\subsection{?}




On voit immédiatement que l'algorithme nécessite de pouvoir déduire d'un séquent, d'une règle et d'une formule principale contenue dans le séquent et sur laquelle la règle peut agir, les séquents correspondant aux différentes prémisses. Ce n'est pas difficile : pour les axiomes il n'y a rien à faire ; pour les autres règles, la formule principale $H$ étant de la forme $A \text{ 'connecteur' } B$, il suffit d'enlever $H$ du séquent et, selon le connecteur et le côté où se trouvait $H$, d'ajouter $A$ ou $B$ à $\Th$, $\G$, $\D$ ou nulle part.

Mais ce n'est pas tout. Lorsqu'on essaie d'appliquer une règle\instancedeux\ au séquent $\s$, on lance une recherche de preuve sur $\s_{1}$ qu'on a obtenu comme décrit ci-dessus. Si on obtient que $\s_{1}$ est prouvable, on lance alors la recherche de preuve sur $\s_{2}$. On doit donc déterminer $\s_{2}$. On a vu qu'on sait le faire à partir de $\s$. Une solution consiste donc à retenir $\s$ pendant qu'on effectue la recherche de preuve sur $\s_{1}$, mais cela peut être coûteux en mémoire. Une autre solution, que nous avons privilégiée, consiste à être capable de retrouver $\s$ à partir de $\s_{1}$ ainsi que de la formule principale, de la règle et du numéro de la prémisse (ici $1$). On a dans ce cas besoin de pouvoir retrouver la conclusion à partir de n'importe laquelle des prémisses, pas seulement par exemple de la première prémisse pour une règle qui n'en a que deux. En effet, utiliser $\s_{1}$ pour retrouver $\s$ suppose qu'à la fin de la recherche de preuve pour $\s_{1}$, on connaît $\s_{1}$. Or, l'idée ici est de n'avoir vraiment qu'un seul séquent en mémoire à tout moment. Ainsi, à la fin de la recherche de preuve pour $\s$, on doit connaître $\s$, donc on doit aussi pouvoir déduire $\s$ de $\s_{2}$ en connaissant la formule principale et le fait qu'on est en train de s'intéresser à la deuxième prémisse.

En résumé, on aimerait (bien que ce ne soit pas nécessaire) que toutes les règles soient \textbf{locales}, avec la définition suivante.

\begin{df}
Une règle est \textbf{locale} si pour toute instance\instance\ de cette règle et pour tout $i$ entre $1$ et $p$, on peut déduire $\s$ à partir de $\s_{i}$ et de la formule principale et de $i$.
\end{df}

On remarque que $\land L$, $\land R$, $\lor L$ et $\lor R$ sont locales. Les axiomes sont également locaux, la définition n'ayant pas grand intérêt pour eux. En revanche, les règles $\to L$ et $\to R$ ne sont pas locales : pour chacune, les formules représentées par $\D$ dans la conclusion n'apparaissent nulle part dans la dernière prémisse, il n'est donc pas possible de retrouver la conclusion en connaissant uniquement cette prémisse, la formule principale et le numéro de la prémisse, puisqu'il n'y a aucun moyen d'en déduire ce qui se trouve dans $\D$.

C'est pour cette raison qu'on introduit le calcul \LSJn, dans lequel toutes les règles sont locales.

\section{Le calcul \LSJn}


%On utilise les définitions et notations de l'article~\cite{LSJ}.
%.
%
%\
%
%Le système \LSJn\ a pour objectif de faire les mêmes calculs que \LSJ, mais en manipulant des séquents qui contiennent un peu plus d'information, afin de pouvoir faire le ``back-tracking'' nécessaire à l'algorithme de \LSJ\ en n'ayant à tout moment en mémoire qu'un seul séquent.
%
%Pour cela, on veut que les séquents de \LSJn\ représentent de manière exhaustive et pertinente ceux de \LSJ\ : on montre qu'il existe une surjection de l'ensemble des séquents de \LSJn\ dans l'ensemble des séquents de \LSJ, telle qu'un séquent de \LSJn\ est prouvable dans \LSJn\ si, et seulement si, son image est prouvable dans \LSJ.
%
%\
%
%Le calcul \LSJn, très proche du calcul \LSJ, manipule des séquents contenant un peu plus d'information afin de n'avoir que des règles locales. 
%Plus précisément, chaque séquent de \LSJn\ a un indice (un entier naturel), et chaque formule du séquent a également un indice.
%Plus précisément, chaque séquent a un indice $n$, qui détermine lesquelles de ses formules, qui ont aussi chacune un indice $i$, sont \emph{actives}, c'est-à-dire peuvent être la formule principale lors d'une application de règle : pour les formules de gauche, la condition est $i\leq n$, et pour celles de droite $i=n$. Ainsi, pour la dernière prémisse des deux règles liées à $\to$ par exemple, les formules de droite de la conclusion peuvent être conservée dans le séquent sans être actives. Il suffit de modifier l'indice du séquent pour changer les formules actives.

Le calcul \LSJn\ est très proche du calcul \LSJ\ : chaque règle de \LSJn\ correspond à une règle de \LSJ, et des arbres de preuve dans les deux systèmes pour la même formule sont fortement liés. Mais contrairement à \LSJ, les règles de \LSJn\ sont toutes locales. Pour cela, les séquents de \LSJn\ représentent chacun un séquent de \LSJ, avec un peu plus d'informations : celles qui sont parfois nécessaire pour retrouver la conclusion à partir d'une prémisse. Cette représentation est exhaustive et correcte. On montre en effet qu'il existe une surjection de l'ensemble des séquents de \LSJn\ dans l'ensemble des séquents de \LSJ, telle qu'un séquent de \LSJn\ est prouvable dans \LSJn\ si, et seulement si, son image est prouvable dans \LSJ.


\subsection{Formalisme de \LSJn}


Un séquent de \LSJn\ est la donnée de deux multiensembles $\Gp$ et $\Dp$ de couples $entier~:~formule$, et d'un entier naturel $n$, tels que tous les entiers présents dans $\Gp$ sont $\leq n+1$ et tous ceux présents dans $\Dp$ sont $\leq n$ ; on écrit $\Gp \Rightarrow_{n} \Dp$.

\

Les règles du calcul \LSJn\ sont décrite dans la figure~\ref{fig:reglesLSJn}. Chacune correspond à une règle de \LSJ.


\begin{figure}[h]
\centering

\emph{$n$ et parfois $i$ désignent toujours des entiers naturels, avec $i\leq n$}
$$\begin{array}{cc}
	\LSJLfauxL & \Id \\\\
	\LSJLetL & \LSJLetR \\\\
	\LSJLouL & \LSJLouR \\\\
	\multicolumn{2}{c}{\LSJLimpL}\\\\
	\multicolumn{2}{c}{\LSJLimpR}
\end{array}$$

\caption{Les règles du calcul \LSJn}
\label{fig:reglesLSJn}
\end{figure}




\subsection{\'Equivalence avec \LSJ}


On note $\Sig$ l'ensemble des séquents de \LSJ, et $\Sig'$ l'ensemble des séquents de \LSJn.

Soit $\sigma\in\Sig$, on note $\vdash\sigma$ si $\sigma$ est prouvable dans \LSJ\ ; soit $\sigma'\in\Sig'$, on note $\vdash'\sigma'$ si $\sigma'$ est prouvable dans \LSJn.

\

Soit $M$ un multiensemble de couples $entier:formule$, l'entier d'un couple étant appelé son indice. On note $M_{k}$ le multiensemble obtenu à partir de $M$ en ne gardant que les couples d'indice $k$, et $M_{\leq k}$ celui obtenu en ne gardant que les couples d'indice inférieur à $k$. On note $\forget(M)$ le multiensemble de formules obtenu en oubliant l'indice et ne gardant que la formule de chaque couple de $M$.

On définit l'application $\surj$ de %l'ensemble des séquents de \LSJn\ dans l'ensemble des séquents de \LSJ,
$\Sig'$ dans $\Sig$, qui à $\G' \To_{n} \D'$ associe $\Th\, ;\G \To \D$ %\quad 

\noindent
où :\;
$\left\{
\begin{array}{l}
%	\Th = \{ A \:|\: n+1:A \in \G'\} \\
%	\G = \{ A \:|\: \exists i\leq n,\ i:A \in \G'\} \\
%	\D = \{ A \:|\: n:A \in \D'\}
	\Th = \forget (\G'_{n+1}) \\
	\G = \forget (\G'_{\leq n}) \\
	\D = \forget (\D'_{n})
\end{array}
\right.$.

C'est une application surjective : en effet tout séquent $\Th \,;\G\To\D$ de \LSJ\ a au moins pour antécédent le séquent $\G' \To_{0} \D'$, 
%avec $\G' = \{ 0:A \:|\: A \in \G\} \cup \{ 1:A \:|\: A \in \Th\}$ et $\D' = \{ 0:A \:|\: A \in \D\}$.
où $\G'$ est l'union de $0 : \G$ (le multiensemble de couples obtenu à partir de $\G$ en rempla\c cant chaque occurrence d'une formule $A$ par une occurrence du couple $0:A$) avec $1:\Th$, et où $\D'=0:\D$.

\




Soit $\mathcal R$ une règle de \LSJ. On note $\mathcal R'$ la règle de \LSJn\ qui lui correspond. On écrit \instanceR\ et \instanceRp\ des instances de ces règles.


\begin{lm}
Soit $\sigma\in\Sig$ et $\sigma'\in\Sig'$ tels que $\sigma=\surj(\sigma')$ et soit $\mathcal R$ une règle de \LSJ.

1) Si \instanceR alors il existe $\s'_{1}$, ... , $\s'_{p}$ tels que pour tout $k$, $\s_{k} = \surj (\s'_{k})$, et \instanceRp.

2) Si \instanceRp, posons pour tout $k$, $\s_{k} = \surj (\s'_{k})$, alors \instanceR.

\noindent
Pour un axiome $\mathcal A$, cela signifie simplement : \instanceAx si et seulement si \instanceAxp.
\end{lm}

\begin{dem}
On le montre pour chaque règle ; c'est une conséquence assez directe de la définition de $\surj$. Faisons-le par exemple pour Id, $\land R$ et $\to L$. \`A chaque fois, on se donne $\s = \Th\, ;\G \To \D$ et $\s' = \G' \To_{n} \D' \in\Sig'$ tels que $\s=\surj(\s')$.

\

%\noindent-\quad 
\noindent Id :\quad On a\instanceId\ si et seulement s'il existe une formule $A$ appartenant à la fois à $\G$ et $\D$, ce qui équivaut, par définition de $\surj$, à : il existe $A$ et $i\leq n$ tels que $n:A\in\D'$ et $i:A\in\G'$, c'est-à-dire \instanceIdp.

\

\noindent $\land R$ :	\quad

1) Si \instanceetR\ alors il existe des formules $A$ et $B$ et un multiensemble $\Dt$ tels que $\D = A \land B, \Dt$ et $\s_{1} = \Th\, ;\G \To A,\Dt$ et $\s_{2} = \Th\, ;\G \To B,\Dt$.
 Posons $\Dt' = \D' - n:A \land B$ le multiensemble obtenu en retirant une seule occurrence de $n:A\land B$ à $\D'$ (qui contient cet élément parce que $\D$ contient $A\land B$ et par définition de $\surj$),
 et $\s'_{1} = \G' \To_{n} n:A,\Dt'$ et $\s'_{2} = \G' \To_{n} n:B,\Dt'$.
 Alors on a bien $\s_{1}=\surj(\s'_{1})$ et $\s_{2}=\surj(\s'_{2})$ (en remarquant que 
 %$\Dt = \{ C \:|\: n:C \in \Dt'\}$
$\Dt = \forget (\Dt'_{n})$
), et \instanceetRp (en remarquant que $\s' = \G' \To_{n} n:A \land B,\Dt'$).

2) Si \instanceetRp\ alors il existe $A$, $B$ et $\Dt'$ tels que $\D' = n:A \land B, \Dt'$ et $\s'_{1} = \G' \To_{n} n:A,\Dt'$ et $\s'_{2} = \G' \To_{n} n:B,\Dt'$ ; 
 on pose $\Dt = \D - A \land B$ le multiensemble obtenu en retirant une seule occurrence de $A\land B$ à $\D$,
 et $\s_{1}=\surj(\s'_{1})$ et $\s_{2}=\surj(\s'_{2})$ ; on obtient $\s = \Th\, ;\G \To A\land B,\Dt$ et $\s_{1} = \Th\, ;\G \To A,\Dt$ et $\s_{2} = \Th\, ;\G \To B,\Dt$\; d'où\instanceetR.

\

\noindent $\to L$ :	\quad

1) Si \instanceimpL\ alors il existe $A$, $B$ et $\Gt$ tels que $\G=A\to B,\Gt$ et $\s_{1} = \Th\, ;B,\Gt \To \D$ et $\s_{2} = B,\Th\, ;\Gt \To A,\D$ et $\s_{3} = B \,; \Th,\Gt \To A$ ; et il existe $i\leq n$ tel que $i:A\to B\in\G'$ ;
 on pose $\Gt' = \G' - i:A\to B$ (on retire une seule occurrence de $i:A\to B$ de $\G'$) et $\s'_{1} = i:B,\Gt' \To_{n} \D'$ et $\s'_{2} = n+1:B,\Gt' \To_{n} n:A,\D'$ et $\s'_{3} = n+2:B,\Gt' \To_{n+1} n+1:A, \D'$ et on vérifie que cela convient.

2) Si \instanceimpLp\ alors il existe $i$, $A$, $B$ et $\Gt'$ tels que $\G'=i:A\to B,\Gt'$ et $\s'_{1}$, $\s'_{2}$ et $\s'_{3}$ ont la forme donnée ci-dessus ; on pose $\Gt = \G - A\to B$ (on retire une seule occurrence de $A\to B$ de $\G$), alors les images $\s_{1}$, $\s_{2}$ et $\s_{3}$ par $\surj$ de $\s'_{1}$, $\s'_{2}$ et $\s'_{3}$ respectivement s'écrivent comme ci-dessus et donc \instanceimpL.
\end{dem}



\begin{theo}
Soit $\sigma\in\Sig$ et $\sigma'\in\Sig'$ tels que $\sigma=\surj(\sigma')$, alors $\vdash \sigma$ si et seulement si $\vdash' \sigma'$.
%Soit $\sigma$ un séquent de \LSJ\ et $\sigma'$ un séquent de \LSJn\ tels que $\sigma=\surj(\sigma')$, alors $\vdash \sigma$ si et seulement si $\vdash' \sigma'$.
\end{theo}

\begin{dem}
Par récurrence sur la \emph{taille} de $\s\in\Sig$, c'est-à-dire la somme des tailles des formules des trois multiensembles apparaissant dans $\s$.

\

\noindent
On initialise pour tout $\sigma = \Th\, ;\G \To \D$ tel que toutes les formules dans $\G$ et dans $\D$ sont atomiques : soit $\sigma' = \G' \To_{n} \D' \in\Sig'$ tel que $\sigma=\surj(\sigma')$. Alors toutes les formules associées à un $i \leq n$ dans $\G'$ et toutes les formules associées à $n$ dans $\D'$ sont aussi atomiques. En étudiant la forme des conclusions des règles non axiomatiques de \LSJ\ comme de \LSJn,
on remarque que si $\s$ (resp. $\s'$) est la conclusion d'une règle de \LSJ\ (resp. \LSJn), alors la règle est un axiome. L'initialisation est donc un cas particulier de ce qui suit avec $p=0$ (ce qui entraîne qu'on n'utilise en fait pas l'hypothèse de récurrence).

% on obtient que : $\vdash \s$ si et seulement si $\s$ est une conséquence directe d'un axiome de \LSJ, et $\vdash' \s'$ si et seulement si $\s'$ est une conséquence directe d'un axiome de \LSJn. Or d'après le lemme, pour $\mathcal A$ axiome de \LSJ, \instanceAx si et seulement si \instanceAxp. On en déduit $\vdash \sigma$ si et seulement si $\vdash' \sigma'$.

\

\noindent
Soit $\s = \Th\, ;\G \To \D \in\Sig$. Soit $\sigma' = \G' \To_{n} \D' \in\Sig'$ tel que $\sigma=\surj(\sigma')$.

On suppose $\vdash \s$. Alors il existe une règle $\mathcal R$ de \LSJ\ et $\s_{1}$, ... , $\s_{p} \in\Sig$ (avec éventuellement $p$ nul) tels que $\vdash \s_{k}$ pour tout $k$ et\instanceR. D'après le lemme, il existe $\s'_{1}$, ... , $\s'_{p} \in\Sig'$ tels que $\s_{k}=\surj(\s'_{k})$ pour tout $k$ et\instanceRp. Pour tout $k$, on applique l'hypothèse de récurrence à $\s_{k}$ qui a une \emph{taille} strictement inférieure à celle de $\s$, et on obtient $\vdash' \s'_{k}$. On en déduit $\vdash' \s'$.

On suppose $\vdash' \s'$. Alors il existe une règle $\mathcal R'$ de \LSJn\ et $\s'_{1}$, ... , $\s'_{p} \in\Sig'$ tels que $\vdash' \s'_{k}$ pour tout $k$ et\instanceRp. On pose $\s_{k}=\surj(\s'_{k})$ pour tout $k$. D'après le lemme on a \instanceR, en particulier on peut appliquer l'hypothèse de récurrence aux $\s_{k}$ donc $\vdash \s_{k}$ pour tout $k$, d'où $\vdash \s$.

\end{dem}






\section{Efficacité de \LSJ}


L'étude qui suit porte sur le calcul \LSJ. En effet, \LSJn\ hérite de toutes les propriétés intéressantes de \LSJ, en apportant une localité des règles qui facilite une implémentation économe en mémoire.


\subsection{Propriété de la sous-formule et indexation}

$B$ est une \textbf{sous-formule} de $A$ si $B=A$ ou si $A$ est de la forme $A_{1}$`connecteur'$A_{2}$ et ($B$ est une sous-formule de $A_{1}$ ou $B$ est une sous-formules de $A_{2}$). Un calcul de séquents vérifie la \textbf{propriété de la sous-formule} si tout séquent prouvable $\s$ admet une preuve telle que toute formule apparaissant dans (un séquent de) la preuve est une sous-formule d'une formule de $\s$. En particulier, le séquent $\To A$ a une preuve dans laquelle toute formule est une sous-formule de $A$.

Le calcul \LSJ vérifie la propriété de la sous-formule : on le constate aisément en observant chaque règle.

La propriété de la sous-formule est très recherchée en calcul des séquents. D'une part, elle donne une borne sur les formules qu'il faudra manipuler au cours d'une recherche de preuve, qui sont évidemment toutes plus petites que la formule qu'on essaie de prouver. Mais surtout, elle permet de connaître à l'avance la liste exhaustive des formules qu'on pourra rencontrer. On peut donc à l'avance les numéroter : ainsi, les formules d'un séquents sont simplement représentées par un entier. Il faut quelques informations sur ces numéros : par exemple pour une formule $A\land B$, il faut savoir qu'il s'agit d'un ``et'', et pouvoir déterminer $A$ et $B$. Il faut aussi pouvoir reconnaître quand l'axiome Id (une même formule apparaît des deux côtés du séquent) s'applique : pour cela on associe à chaque formule une classe, qui correspond à une classe d'équivalence de la relation d'égalité structurelle. La taille de toutes ces informations réunies est linéaire en la taille de la formule de départ (c'est-à-dire le nombre de n\oe uds de l'arbre qui la représente, qui est aussi le nombre de sous-formules avec multiplicité). Un exemple est donné par la figure~\ref{fig:indexation}.

La propriété de la sous-formule est encore plus intéressante dans le cadre de la recherche de preuve compilée : connaître à l'avance les formules qui apparaîtront permet d'écrire pour chacune des fonctions agissant sur le séquent, au lieu de les calculer au cours de la recherche de preuve (voir ??).

\begin{figure}
%\centering
\includegraphics[width=0.3\linewidth]{indexation} %Quelques_formules.f12
\caption{Indexation de la formule $(a\land b)\land(\lnot c \lor (a\land b))$}
\label{fig:indexation}
\end{figure}

%\subsection{Absence de duplication}
%
%
%\
%
%\
%\subsection{Inversibilité de certaines prémisses de $\to L$ et $\to R$}
%
%
%$((\bigwedge_{i=1}^{n}p_{i} \lor (\lnot\lnot p_{1}\to f) \lor \bigvee_{i=2}^{n}(p_{i}\to f))\to f)\to f$
%
%\
%
%$(\;[ \;(p_{1}\land p_{2} \land ... \land p_{n}) \lor (\lnot\lnot p_{1}\to f) \lor (p_{2}\to f) \lor ... \lor (p_{n}\to f)\;]\to f\;)\to f$
%
%\
%
%$1:f \quad\To_{0}\quad 0:  p1 \land ( p2 \land p3 )  \;,\; 0: \lnot\lnot p1 \to f  \;,\;  0: p2 \to f  \;,\;  0: p3 \to f  \;,\; 0: f$
%
%\
%
%$f\;;\;\emptyset \quad\To\quad p_{1} \land p_{2} \land ... \land p_{n} \;,\; \lnot\lnot p_{1}\to f \;,\; p_{2}\to f \;,\; ...  \;,\; p_{n}\to f \;,\; f$
%
%
%
%\section{Quelques explications sur l'implémentation}
%
%\subsection{Précalculs : indexation, classes, priorités}
%
%\subsection{Gestion efficace des formules du séquent : insertion et suppression, choix de la formule principale}
%
%
%
%\section{Vers une recherche de preuve compilée et certifiée}
%
%\subsection{Un langage simple pour la certification}
%
%\subsection{Compilation : des fonctions pour chaque sous-formule}
%
%











\section{Implémentation}
\subsection{Indexation}

cf ``Propriété de la sous-formule et indexation'' + explication sur les classes (et priorités) et les champs axiomes du séquent



\subsection{Structure de données pour le séquent}

Au cours de l'algorithme, on manipule un ``séquent'', censé représenter un séquent du calcul \LSJn, contenant les informations suivantes :

\noindent-\;
des informations de taille constante : l'indice $n$ du séquent, et des booléens $id$ et $fauxL$, indiquant si les axiomes de même nom sont applicables au séquent ;

\noindent-\;
les couples \emph{indice}: \emph{formule} contenus dans les champs $\G$ et $\D$ du séquent.

Comme nous l'avons expliqué en introduisant le calcul \LSJn, le but de celui-ci est de pouvoir effectuer la recherche de preuve en ne gardant à chaque instant qu'un seul séquent en mémoire.

\


Intéressons-nous maintenant à la complexité temporelle.

Celle-ci dépend du nombre de règles qu'on essaie d'appliquer, c'est-à-dire le nombre d'appels récursifs à la fonction \emph{prouvable} (?) dont le pseudo-code est donné en figure ? page ?. Ce nombre dépend de la taille de la formule et des connecteurs présents dedans (et selon l'ordre dans lequel on choisit les formules principales cela peut beaucoup varier pour une même formule, mais on s'intéresse à la complexité dans le pire cas). Mais il ne dépend pas de notre choix d'implémentation (sauf pour l'ordre des ``implique'', mais encore une fois pas si on regarde le pire cas).










\bibliographystyle{plain}
\bibliography{LSJn}

\end{document}












