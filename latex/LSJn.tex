\input{preamble}



\begin{document}
%\renewcommand{\labelitemi}{$\diamond$}
\renewcommand{\labelitemi}{$\bullet$}
\vspace{2cm}~~\\

\input{bussproofs}

\tableofcontents

\pagebreak






\section{Logique intuitionniste propositionnelle : approche par le calcul de séquents \LJ}




Il existe de nombreuses approches de la logique intuitionniste : on choisit ici celle par le calcul de séquents \LJ\ introduit par Gentzen. 
Elle fournit une définition de la prouvabilité d'une formule en logique intuitionniste qui n'est pas la plus courante ni la plus rapide à exposer ; mais elle permet de présenter un premier calcul de séquents avec de nombreuses définitions qui seront utiles par la suite.
%Cela permet de se familiariser avec les calculs de séquents, avant de discuter




%Il existe de nombreuses approches de la logique intuitionniste : on choisit ici celle par un calcul de séquents.

\

On s'intéresse à la partie propositionnelle de la logique intuitionniste : 
les formules sont construites à partir de la constante $\bot$ (\emph{faux}), de variables propositionnelles et des connecteurs binaires $\land$ (\emph{et}), $\lor$ (\emph{ou}), $\to$ (\emph{implique}). Une formule est \emph{atomique} si elle est réduite à une variable propositionnelle ou $\bot$. La notation $\lnot A$ signifie $A\to\bot$.





%\subsection{LJ : le calcul originel de la logique intuitionniste}
%\subsection{De \LK\ à \LJ}
\subsection{Définition du calcul \LJ}


%Un calcul de séquents se caractérise en général par sa propre définition d'un séquent, ainsi qu'un ensemble de règles. Voici
%Comme la plupart des calculs de séquents, le calcul \LJ\ se caractérise par une définition de ses \emph{séquents} ainsi qu'un ensemble de \emph{règles}.
Les éléments qui caractérisent généralement un calcul de séquents sont une définition de ses \emph{séquents} et un ensemble de \emph{règles}. Présentons ceux du calcul \LJ.

\

\noindent
\textbf{Multiensembles et notations.}
On s'intéresse à des \emph{multiensembles}, c'est-à-dire des collections où le nombre d'occurrences est pris en compte, mais non l'ordre des éléments. Cela permettra de ne pas avoir besoin de règles explicites d'échange. On utilise des lettres romaines (typiquement $A$, $B$, $D$, $G$) pour désigner les formules et des lettres grecques ($\G$, $\D$) pour les multiensembles de formules. La notation `` $A,\G$ '' représente le multiensemble obtenu à partir de $\G$ en ajoutant une occurrence de $A$.

\begin{df}
%est la donnée de
%est constitué de
Un \textbf{\emph{séquent}} de \LJ\ consiste en un multiensemble de formules $\G$ (les ``hypothèses'') et une formule $D$ (la ``conclusion'') ; on écrit $\G \To D$.
\end{df}



Les \textbf{\emph{règles}} du calcul \LJ\ sont données dans la figure~\ref{fig:reglesLJ}.  Pour une règle ${\regle,}$ $\mathcal R$ est le nom de la règle, $prem_{1}$, ... , $prem_{p}$ sont les \textbf{\emph{prémisses}}, et $concl$ la \textbf{\emph{conclusion}}. 
%%%%%%%%%%%%
%%%%%%%%%%%%
%%%%%%%%%%%%
%On pourra désigner précisément $prem_{k}$ par la \emph{$k$-ième prémisse} ou \emph{prémisse numéro $k$}.
$prem_{k}$ sera appelée la \emph{$k$-ième prémisse} ou \emph{prémisse numéro $k$}.
Les prémisses et la conclusion sont des séquents où $A$, $B$, $D$ sont des formules quelconques et $\G$ un multiensemble de formules quelconques. 
%La distinction entre règles \emph{logiques} et \emph{structurelles} sera expliquée plus loin.
 Les \textbf{\emph{axiomes}} sont les règles sans prémisse.
On distingue deux grandes familles de règles. Les \emph{règles logiques} remplacent une formule de la conclusion par une ou des formules plus simples. La formule remplacée, appelée \emph{formule principale}, doit avoir une forme donnée en fonction de la règle. Les \emph{règles structurelles} manipulent la structure du séquent en enlevant, dupliquant, dépla\c cant des formules dont on n'a pas besoin de connaître la forme. Elles dépendent du choix de structure du séquent : si on avait 
%choisi de réprésenter 
représenté
$\G$ par une liste et non un multiensemble, on aurait eu besoin d'ajouter une règle d'échange\LJechange.

%On distingue généralement deux sortes de règles. Les \emph{règles logiques} remplacent une formule de la conclusion par une ou des formules plus simples. La formule remplacée, appelée \emph{formule principale}, doit avoir une forme donnée en fonction de la règle. Les \emph{règles structurelles} manipulent la structure du séquent en enlevant, dupliquant, dépla\c cant des formules dont on n'a pas besoin de connaître la forme. Elles dépendent du choix de structure du séquent : pour le calcul \LJ, si on avait choisi de réprésenter $\G$ par une liste et non un multiensemble, on aurait eu besoin d'ajouter une règle d'échange \echange.



Cette présentation est à peu près celle donnée par Dyckhoff dans \cite{LJT}. Elle diffère de celle de Gentzen, mais elle en est suffisamment proche pour qu'on puisse quand même l'appeler le calcul \LJ. On peut d'ailleurs facilement passer d'une définition à l'autre à l'aide des règles structurelles.

{
\renewcommand{\arraystretch}{2}

\begin{figure}[h]
\centering

%$\begin{tabular}{cc|}
%	\LJbotL & \LJid \\ \hline
%	\LJetL & \LJetR \\
%	\LJouL & \quad\LJouRun \quad \LJouRdeux \\
%	\LJimpL & \LJimpR 
%%	\multicolumn{2}{c}{\impL}\\\\
%%	\multicolumn{2}{c}{\impR}
%\end{tabular}$

%\def\identite{
%\begin{tabular}{cc}
%	\emph{Identité} \qquad&\qquad \LJid
%\end{tabular}
%}
%\def\coupure{
%\begin{tabular}{cc}
%	\emph{Coupure} & \LJcut
%\end{tabular}
%}
%\def\logiques{
%$\begin{tabular}{cc}
%%	\LJbotL & \LJid \\ \hline
%%	\multicolumn{2}{c}{\emph{Règles logiques}} \\
%	\LJbotL & \emph{Règles logiques} \\
%	\LJetL & \LJetR \\
%	\LJouL & \LJouRun \LJouRdeux \\
%	\LJimpL & \LJimpR 
%\end{tabular}$
%}
%\def\structurelles{
%$\begin{tabular}{c}
%	\emph{Règles structurelles} \\
%	\LJweakening \\
%	\LJcontraction
%\end{tabular}$
%}
%
%%$\begin{tabular}{cc|}
%%%	\LJbotL & \LJid \\ \hline 
%%	\multicolumn{2}{c}{\logiques}
%%\end{tabular}$
%$\begin{tabular}{|c|c|}
%	\hline
%	\identite & \coupure \\
%	\hline 
%	{\logiques} & \structurelles \\
%	\hline
%\end{tabular}$

\resizebox{\textwidth}{!}{

$\begin{tabular}{|cc|c|}
	\hline
	\textbf{\large{Identité}} & \LJid & \textbf{\large{Coupure}} \\
	\cline{1-2}
	\LJbotL & \textbf{\large{Règles logiques}} & \LJcut \\[4pt]
	\cline{3-3}
	\LJetL & \LJetR & \textbf{\large{Règles structurelles}} \\
	\LJouL & \LJouRun \LJouRdeux & \LJweakening \\
	\LJimpL & \LJimpR & \LJcontraction \\[4pt]
	\hline
%
%	\emph{Règles structurelles} \\
%	\LJweakening \\
%	\LJcontraction
\end{tabular}$

}

\caption{Règles du calcul \LJ}
\label{fig:reglesLJ}
\end{figure}
}

%\
%
%On dispose de \textbf{règles}, données sous la forme \regle. $\mathcal R$ est le nom de la règle. $prem_{1}$, ... , $prem_{p}$ sont les 
%%(resp. première, ... , $p$-ième) 
%\textbf{prémisses}, et $concl$ la \textbf{conclusion}. Les prémisses et la conclusion sont des séquents où $A$, $B$, $D$ sont des formules quelconques et $\G$ un multiensemble de formules quelconques.
%
%Les \textbf{axiomes} sont les règles sans prémisse. Un calcul de séquents comporte en général deux sortes de règles en plus de quelques axiomes : des \emph{règles logiques} et des \emph{règles structurelles}. Pour les règles logiques, il existe une unique formule de la conclusion dont on connaît le connecteur : c'est la \textbf{formule principale}, qui disparaît généralement dans les prémisses au profit de formules plus simples. Les règles structurelles ne se préoccupent pas des connecteurs, mais, comme leur nom l'indique, de la structure du séquent. Elles dépendent fortement du choix de définition d'un séquent : les règles d'échange comme\echange\ font partie des règles structurelles lorsqu'on retient les formules de $\G$ sous la forme d'une liste ; comme nous travaillons avec un mutiensemble, nous n'en avons pas besoin.
%
%Les axiomes et règles logiques de \LJ\ sont données dans la figure~\ref{fig:reglesLJ}. Comme règle structurelle, on ne considère que\contraction\ : cela suffit pour avoir un calcul complet (voir ??). 
%%Cette présentation du calcul \LJ\ diffère un peu de celle de Gentzen, mais on peut facilement passer de l'une à l'autre à l'aide des règles structurelles de Gentzen.
%Cette présentation diffère de celle de Gentzen, mais elle en est suffisamment proche pour qu'on puisse quand même l'appeler le calcul \LJ. On peut d'ailleurs facilement passer d'une définition à l'autre à l'aide des règles structurelles, si on rajoute la règle structurelle \weakening\ qui est juste mais pas nécessaire pour la complétude de notre approche.




%\subsection{Prouvabilité}
%
%
%
%Une \textbf{\emph{instance}} d'une règle $\mathcal R$ a la même forme que la règle : \instance, mais ici les $\s_{i}$ et $\s$ sont des séquents connus explicitement ; bien entendu il faut qu'il s'agisse de séquents qui correspondent à la forme donnée par la définition de la règle. %Par exemple \etL\ devient une instance de la règle $\land L$ (qui a la même écriture que la règle) lorsqu'on connaît les formules $A$ et $B$ et toutes les formules de $\Th$, $\G$, $\D$.
%
%Une \textbf{\emph{preuve}} (ou \emph{arbre de preuve}) est un arbre dont les n\oe uds sont étiquetés par un séquent et une règle et ont la même arité que le nombre de prémisses de la règle, et tel que : pour tout n\oe ud de séquent $\s$ et de règle $\mathcal R$, si $\s_{1}$, ... , $\s_{p}$ sont les séquents associés à chacun de ses fils respectivement, alors\instance\ est une instance de $\mathcal R$. Les feuilles d'un tel arbre sont les n\oe uds auxquels est associé un axiome.
%
%\begin{df*}
%Un séquent $\s$ est \textbf{\emph{prouvable}} par le calcul \LJ\ s'il existe un arbre de preuve tel que le séquent associé à la racine est $\s$. De manière équivalente, on peut définir l'ensemble des séquents prouvables comme le plus petit ensemble vérifiant : pour toute instance \instance\ d'une règle, si pour tout $i$, $\s_{i}$ est prouvable, alors $\s$ est prouvable (en particulier pour toute instance \instanceAx\ d'un axiome $\mathcal A$, $\s$ est prouvable).
%\end{df*}
%
%Ceci nous permet de définir la prouvabilité en logique intuitionniste.
%
%\begin{df*}
%Une formule $A$ est \textbf{\emph{prouvable en logique intuitionniste}} si le séquent $\;\To A$ est prouvable par le calcul \LJ\ (on écrit $\;\To A$ pour $\emptyset \To A$).
%\end{df*}
%
%\noindent
%\textbf{Interprétation d'un séquent.}
%%Les séquents sont des structures pratiques pour le calcul de séquents où ils sont manipulés à l'aide de règles, mais ils 
%%Les séquents, en plus d'être des structures pratiques pour le calcul de séquents où ils sont manipulés à l'aide de règles, 
%Les séquents, en plus d'être des structures pratiques à manipuler à l'aide de règles, 
%ont en eux-mêmes une interprétation logique très simple grâce à la propriété suivante : un séquent $\G \To D$ est prouvable par le calcul \LJ\ si, et seulement si, la formule $\left(\bigwedge_{G\in\G}G\right)\to D$ est prouvable en logique intuitionniste.
%



\subsection{Prouvabilité d'un séquent}
\label{ProuvabiliteSequent}

Les définitions suivantes s'appliquent aux calculs de séquents en général, pas seulement \LJ.
Une \textbf{\emph{instance}} d'une règle $\mathcal R$ a la même forme que la règle : \instance, mais ici les $\s_{i}$ et $\s$ sont des séquents connus explicitement ; bien entendu il faut qu'il s'agisse de séquents qui correspondent à la forme donnée par la définition de la règle. %Par exemple \etL\ devient une instance de la règle $\land L$ (qui a la même écriture que la règle) lorsqu'on connaît les formules $A$ et $B$ et toutes les formules de $\Th$, $\G$, $\D$.
Une \textbf{\emph{preuve}} (ou \textbf{\emph{arbre de preuve}}) est un arbre dont les n\oe uds sont étiquetés par un séquent et une règle et ont la même arité que le nombre de prémisses de la règle, et tel que : pour tout n\oe ud de séquent $\s$ et de règle $\mathcal R$, si $\s_{1}$, ... , $\s_{p}$ sont les séquents associés à chacun de ses fils respectivement, alors\instance\ est une instance de $\mathcal R$. Les feuilles d'un tel arbre sont les n\oe uds auxquels est associé un axiome.

\begin{df}
Un séquent $\s$ est \textbf{\emph{prouvable}} \emph{dans} 
%(ou \emph{par}) 
%ou \emph{par}
\emph{un calcul de séquents} s'il existe un arbre de preuve tel que le séquent associé à la racine est $\s$. De manière équivalente, on peut définir l'ensemble des séquents prouvables comme le plus petit ensemble vérifiant : pour toute instance \instance\ d'une règle, si pour tout $i$, $\s_{i}$ est prouvable, alors $\s$ est prouvable (en particulier pour toute instance \instanceAx\ d'un axiome $\mathcal A$, $\s$ est prouvable).
\end{df}

\subsection{Une définition de la prouvabilité en logique intuitionniste}

On peut maintenant donner une définition de la prouvabilité d'une formule en logique intuitionniste. L'idée est qu'un séquent $\G\To D$ représente la formule $\left(\bigwedge_{G\in\G}G\right)\to D$.

\begin{df}
Une formule $A$ est \textbf{\emph{prouvable en logique intuitionniste}} si le séquent $\;\To A$ est prouvable par le calcul \LJ\ (on écrit $\;\To A$ pour $\emptyset \To A$).
\end{df}

Il existe de nombreuses autres manières d'aborder la logique intuitionniste. Celle-ci n'est pas la plus courante, mais a permis d'introduire des définitions sur les calculs de séquents qui seront utiles par la suite.
%par exemple avec les modèles de Kripke (?).





\subsection{Comparaison avec la logique classique (calcul \LK)}
%\
%\noindent
%\emph{Remarque.}
%Le calcul \LJ\ a été dérivé d'un calcul \LK\
%La logique classique peut être définie à l'aide d'un calcul de séquents appelé \LK, très similaire à \LJ\ (en fait, c'est \LJ\ qui a été dérivé de \LK\ pour passer de la logique classique à la logique intuitionniste). 
%La logique classique peut être définie à l'aide d'un calcul de séquents appelé \LK, dont \LJ\, qui en a été dérivé pour la logique intuitionniste, est très proche.
La logique classique peut être définie à l'aide d'un calcul de séquents appelé \LK, dont \LJ\ a été dérivé pour la logique intuitionniste. Un séquent de \LK\ comporte un autre multiensemble $\D$ de ``conclusions'' au lieu d'une unique conclusion $D$ : on écrit $\G \To \D$. Un tel séquent a également une interprétation logique : 
%il est prouvable par \LK\ si, et seulement si, la formule $\left(\bigwedge_{G\in\G}G\right)\to\left(\bigvee_{D\in\D}D\right)$ est vraie en logique classique.
il représente la formule $\left(\bigwedge_{G\in\G}G\right)\to\left(\bigvee_{D\in\D}D\right)$ en logique classique.
%
Les règles %sont modifiées
diffèrent en conséquence : par exemple\LKetR\ remplace ${\LJetR\,.}$ Bien entendu, on ajoute aussi des règles structurelles agissant sur $\D$.
 Mais surtout, on n'a plus qu'une règle pour le $\lor$ à droite : ${\LKouR\,.}$ (Dans d'autres définitions, on conserve deux règles distinctes, mais la règle que nous donnons ici peut être déduite de ces deux règles et de règles structurelles.)
 
\begin{floatingfigure}%[h]
	[r]{3.7cm}
\centering
\LKTiersExclu

%\caption{Preuve dans \LK\ de $A\lor\lnot A$}
\caption{Preuve de $A\lor\lnot A$ dans \LK}
\label{fig:LKTiersExclu}
\end{floatingfigure}

C'est la possibilité d'avoir plusieurs formules dans la partie droite du séquent qui permet de prouver davantage de séquents dans \LK\ que dans \LJ. On comprend ainsi la différence entre le ``ou'' classique et le ``ou'' intuitionniste. En logique classique, prouver $A\lor B$, c'est prouver le séquent $\;\To A,B$ : les deux formules sont encore présentes. Un bon exemple est la preuve du principe du tiers exclu $A\lor\lnot A$ (figure~\ref{fig:LKTiersExclu} ; on rappelle que $\lnot A$ est une notation pour $A\to\bot$) : si on peut appliquer l'axiome $id$ à la formule $A$ (ce qui nécessite deux occurrences distinctes de la formule, une de chaque côté), c'est bien parce qu'on a conservé les deux parties de la formule initiale. Tandis qu'en logique intuitionniste, pour prouver $A\lor B$ c'est-à-dire $\;\To A\lor B$, les seules règles applicables sont $\lor R_{1}$ et $\lor R_{2}$ : il faut donc prouver $\;\To A$ ou prouver $\;\To B$ ; une fois qu'on a choisi lequel on va prouver, on n'a plus accès à l'autre. Ainsi, on ne peut pas prouver $A\lor\lnot A$, car ni $\;\To A$ ni $\;\To \lnot A$ n'est prouvable.

 %on ne peut prouver le séquent $\To A$, ni le séquent $\To 
%, où on applique l'axiome $id$ à une occurrence de $A$ venant du $\lnot A$ 



%%%%
%
%%\section{Avantages et inconvénients de différents calculs de séquents pour la logique intuitionniste}
%\section{Application du calcul de séquents à la recherche de preuve automatisée. Comparaison des différents systèmes}
%
%Un calcul de séquents est généralement défini par sa propre définition d'un séquent ainsi qu'un ensemble de règles. Il est souvent attaché à une logique : à partir d'une formule, on peut construire un séquent qui est prouvable si et seulement si la formule est ``prouvable'' ou ``vraie'' dans la logique en question (l'appellation dépend de la logique). Il existe plusieurs calculs de séquents pour la logique intuitionniste, sans parler des nombreuses autres logiques existantes.
%
%\
%
%\noindent
%\textbf{Algorithme.}
%Un calcul de séquents suggère naturellement un algorithme de recherche de preuve : pour essayer de prouver un séquent, on choisit une règle dont il peut être la conclusion et on essaie de prouver les prémisses correspondantes. Si elles sont toutes prouvables (notamment, s'il n'y en a pas : si le séquent est la conclusion d'un axiome), alors par définition le séquent initial est aussi prouvable. Sinon, on essaie une autre règle (sauf dans certains cas où on peut conclure grâce à la notion de règle ou prémisse inversible que nous verrons plus loin). Si on a essayé toutes les règles applicables au séquent sans succès (pour chacune, au moins une prémisse est non prouvable), on conclut que le séquent initial n'est pas prouvable.
%
%Un tel algorithme est correct par construction et d'après la définition de la prouvabilité d'un séquent. En revanche, les causes possibles de non terminaison sont nombreuses. Assurer la terminaison est une des raisons qui rendent certaines propriétés sur les calculs de séquents très intéressantes.
%
%
%\
%
%\noindent
%\textbf{Classification des règles.}
%On distingue généralement deux sortes de règles. Les \emph{règles logiques} remplacent une formule de la conclusion par une ou des formules plus simples. La formule remplacée, appelée \emph{formule principale}, doit avoir une forme donnée en fonction de la règle. Les \emph{règles structurelles} manipulent la structure du séquent en enlevant, dupliquant, dépla\c cant des formules dont on n'a pas besoin de connaître la forme. Elles dépendent du choix de structure du séquent : pour le calcul \LJ, si on avait choisi de réprésenter $\G$ par une liste et non un multiensemble, on aurait eu besoin d'ajouter une règle d'échange \echange.
%
%\
%
%\noindent
%\textbf{Coupure.}
%La règle de coupure (figure~1, ``cut'') condamne l'algorithme à elle seule, puisqu'il peut y avoir une infinité de prémisses associées à une conclusion donnée. Heureusement, cette règle est souvent non nécessaire : de nombreux calculs de séquents possèdent la propriété d'élimination de la coupure, si bien qu'on peut faire comme si cette règle n'existait pas. C'est une propriété souvent difficile à démontrer, mais on ne s'y intéressera pas. Désormais, on présentera des calculs sans donner de règle de coupure.
%
%
%\
%
%\noindent
%\textbf{Règles structurelles et coupure à éviter.}
%
%
%
%
%La règle de coupure (figure~1, ``cut'') condamne l'algorithme à elle seule, puisqu'il peut y avoir une infinité de prémisses associées à une conclusion donnée. Pour commencer, on veut donc un calcul où le nombre d'instances ayant une conclusion donnée est toujours fini. Mais même ainsi, comme pour essayer de prouver un séquent, on rappelle l'algorithme sur d'autres séquents, il faut un argument soigneux de terminaison : par exemple, associer à chaque séquent une ``taille'' entière positive, telle que pour toute instance des règles, les ``tailles'' de toutes les prémisses sont strictement inférieures à celle de la conclusion. Comme on le verra, la propriété de la sous-formule est bien pratique pour ce point-là.
%
%%il n'a pas de raison de terminer a priori. 
%
%%:  si on obtient qu'un séquent est prouvable, on  a en fait trouvé un arbre de preuve correspondant par construction de l'algorithme ; si on obtient qu'il n'est pas prouvable, cela signifie qu'il n'existe aucune instance de règle dont il est la conclusion et dont les prémisses sont prouvables, donc il ne peut pas être associé à la racine d'un arbre de preuve.
%
%
%
%
%\subsection{\LJ\ : existence de cycles}
%
%
%
%
%
%
%\
%
%
%nécessité de contraction ou réécriture de $\to L$ (preuve de $\lnot\lnot(A\lor\lnot A)$)
%
%LJT


%%%%%%%%%


%\section{D'un calcul de séquents à une recherche de preuve automatisée. Avantages et inconvénients de différents calculs}
\section{Propriétés favorisant l'application d'un calcul de séquents à la recherche automatisée de preuve et exemples de calculs}


Il existe plusieurs calculs de séquents pour la logique intuitionniste, sans parler des nombreuses autres logiques existantes. Un tel calcul comporte ses propres définition d'un séquent, règles, et construction pour chaque formule d'un séquent qui est prouvable par le calcul si et seulement si la formule est prouvable en logique intuitionniste. En dériver l'algorithme de recherche de preuve ci-après est assez naturel. Sa correction est immédiate par construction. En revanche, la terminaison pose problème. 
%Il faut parfois complexifier beaucoup l'algorithme pour l'assurer. Afin d'éviter de devoir le faire, il faut certaines propriétés sur le calcul de séquents. 
Elle n'est pas toujours assurée, et même quand elle l'est, souvent difficile à prouver.
Nous présentons %l'algorithme générique, puis 
quelques propriétés sur les calculs de séquents
qui sont intéressantes pour assurer la terminaison et améliorer la complexité de l'algorithme qui leur est associé. Enfin, nous donnons deux exemples de calculs de séquents existants pour la logique intuitionniste, antérieurs au calcul que nous utilisons pour l'implémentation.



\subsection{Algorithme de recherche de preuve}
\label{algoGeneral}

%Un calcul de séquents suggère naturellement un algorithme de recherche de preuve : pour essayer de prouver un séquent, 
On considère un calcul de séquents. Pour déterminer si un séquent est prouvable,
on choisit une règle dont il peut être la conclusion et on 
%essaie de prouver les 
applique récursivement la recherche de preuve aux
prémisses correspondantes. Si elles sont toutes prouvables (en particulier, s'il n'y en a pas : si le séquent est la conclusion d'un axiome), alors par définition le séquent initial est aussi prouvable ; de plus, si on a calculé un arbre de preuve pour chaque prémisse, on en obtient un pour le séquent initial. Sinon, on essaie une autre règle (sauf dans certains cas où on peut conclure grâce à la notion de règle ou prémisse inversible que nous verrons plus loin). Si on a essayé toutes les règles applicables au séquent sans succès, c'est-à-dire que pour chacune, au moins une prémisse est non prouvable (en particulier, s'il n'y a aucune règle applicable : si le séquent n'est la conclusion d'aucune instance), on conclut que le séquent initial n'est pas prouvable.

Cet algorithme est correct par construction et d'après la définition de la prouvabilité d'un séquent. En revanche, 
%sans certaines conditions, il ne termine pas toujours.
il y a des causes possibles de non terminaison, qui se regroupent en deux catégories : ``largeur'' infinie, ``profondeur'' infinie. Pour éviter une ``largeur'' infinie,
il faut que pour un séquent donné, le nombre d'instances dont il est conclusion soit fini.
En ce qui concerne le problème de ``profondeur'' dû à la récursivité, on peut souvent
%associer à chaque séquent une valeur dans un ensemble bien ordonné, de sorte que pour toute instance de règle, les valeurs associées aux prémisses sont toutes strictement inférieures à celle associée à la conclusion. 
munir les séquents d'un ordre bien fondé, de sorte que pour toute instance de règle, les prémisses sont toutes strictement inférieures à la conclusion.
%Comme on le verra, la propriété de la sous-formule est bien pratique pour cela.
%La propriété de la sous-formule qu'on verra plus loin est bien pratique pour cela.
%associer à chaque séquent un entier positif, de sorte que pour toute instance de règle, les entiers associés aux prémisses sont tous strictement inférieurs à celui associé à la conclusion. Comme on le verra, la propriété de la sous-formule est bien pratique pour cela.

\

\noindent
\textit{Remarque : la règle de coupure.}
La règle de coupure, par exemple pour \LJ\ : \\${\LJcut,}$ rend l'algorithme proposé inutilisable parce qu'il ne termine jamais. En effet, on explore indéfiniment en ``largeur'', car le nombre d'instances dont un séquent donné est conclusion est infini, $A$ pouvant être n'importe quelle formule. Heureusement, cette règle est souvent non nécessaire. De nombreux calculs la formulent car c'est une bonne chose que l'implication représentée par un séquent soit transitive, mais s'en passent ensuite grâce à un \emph{théorème d'élimination de la coupure} (souvent difficile à établir). Quoi qu'il en soit, on ne s'intéresse désormais qu'à des calculs dans lesquels cette règle n'est pas énoncée.

\subsection{Propriétés intéressantes des calculs de séquents}

\subsectionDescription{
%Remarque : la règle de coupure.
Absence de contraction.
Propriété de la sous-formule.
Inversibilité de certaines règles ou prémisses.
Localité des règles.
}

%Nous présentons %l'algorithme générique, puis 
%quelques propriétés sur les calculs de séquents
%qui sont intéressantes pour assurer la terminaison et améliorer la complexité de l'algorithme qui leur est associé.

Un calcul de séquents peut présenter certaines des propriétés suivantes, qui contribuent à assurer la terminaison ou à améliorer la complexité de l'algorithme précédent.

\

\noindent
\textbf{Absence de contraction.}
%Les règles de duplication, par exemple 
Certaines règles, comme la contraction à gauche de \LJ\ : 
%
%\noindent
\linebreak
${\LJcontraction}$, sont problématiques pour la terminaison de l'algorithme. En effet, pour essayer de prouver $\G,A\To D$, on peut être amené à essayer de prouver $\G,A,A\To D$, puis en appliquant encore la même règle à essayer de prouver $\G,A,A,A\To D$, et ainsi de suite, sans fin. 
%On parle de duplication car au cours de notre recherche de preuve, on passe de la conclusion à la prémisse en dupliquant la formule $A$. 
Il est parfois possible d'adapter l'algorithme à une possibilité de contraction en prenant certaines précautions, comme on le verra pour le calcul \LJ.
%Il est tout de même possible d'adapter l'algorithme à une duplication dans certains cas, comme on le verra pour le calcul \LJ.

\

\noindent
\textbf{Propriété de la sous-formule.}
La formule $B$ est une \textbf{\emph{sous-formule}} de la formule $A$ si $B$ est égale à $A$ ou si $A$ est de la forme $A_{1}\diamond A_{2}$ où $\diamond$ est un connecteur et [$B$ est une sous-formule de $A_{1}$ ou $B$ est une sous-formule de $A_{2}$]. Un calcul de séquents vérifie la \textbf{\emph{propriété de la sous-formule}} si tout séquent prouvable $\s$ admet une preuve telle que toute formule apparaissant dans (un séquent de) cette preuve est une sous-formule d'une formule de $\s$. 
%En particulier, le séquent $\To A$ a une preuve dans laquelle toute formule est une sous-formule de $A$.
%
La propriété de la sous-formule est très utile pour un calcul de séquents. 
%Souvent, le calcul présente une propriété un peu plus forte, qui assure la terminaison de l'algorithme : toutes les règles sont des règles logiques où on passe de la conclusion aux prémisses en rempla\c cant une formule principale d'une forme donnée par une ou plusieurs sous-formules strictes. Dans ce cas
Souvent, elle fait partie des arguments qui permettent de montrer la terminaison. Elle fournit en effet un ordre bien fondé sur les formules, qu'il reste à étendre de fa\c con bien choisie aux séquents.
%Elle permet de montrer assez facilement la terminaison de l'algorithme dans le cas où toutes les règles sont des règles logiques : on remplace une formule d'une forme donnée dans la conclusion par des
%
%La propriété de la sous-formule
Elle est également utile lors de l'implémentation : si on veut appliquer la recherche de preuve à un séquent donné, on peut connaître à l'avance la liste exhaustive de toutes les formules susceptibles d'apparaître. On peut donc effectuer une indexation préliminaire, puis représenter les formules par des objets de taille constante, par exemple des entiers, au lieu d'arbres qui peuvent être coûteux en mémoire. Voir la sous-section ? pour un exemple détaillé d'une telle indexation.

\

\noindent
\textbf{Inversibilité de certaines règles ou prémisses.}
Dans l'algorithme proposé, il peut être assez long de montrer qu'un séquent n'est pas prouvable, puisqu'on essaie toutes les instances dont il est la conclusion. La notion d'inversibilité permet de terminer beaucoup plus rapidement dans certains cas. 
Une prémisse $prem_{i}$ d'une règle\regle(aussi appelée \emph{$i$-ème prémisse de $\mathcal R$}) est \textbf{\emph{inversible}} si on a : si $prem_{i}$ est non prouvable, alors $concl$ est non prouvable. Une règle est \textbf{\emph{inversible}} si toutes ses prémisses sont inversibles. Ainsi, si au cours de la recherche de preuve, on obtient qu'une prémisse inversible est non prouvable, on peut directement conclure que la conclusion ne l'est pas non plus, sans avoir besoin d'essayer d'autre règle.

\

\noindent
\textbf{Localité des règles.} 
L'algorithme nécessite de savoir déterminer, pour un séquent donné, toutes les instances dont il est conclusion, et en particulier calculer les prémisses de ces instances. 
Pour une instance, la \emph{formule principale} est la formule de la conclusion qui est remplacée dans les prémisses par d'autres formules (règles logiques), ou dupliquée ou supprimée (règles structurelles). Dans le cas des règles logiques, la formule principale doit avoir une forme particulière, par exemple présenter un connecteur donné.
Souvent, pour une conclusion et une règle données et un choix de formule principale autorisé par la règle, il existe une unique instance correspondante, dont on peut facilement calculer toutes les prémisses.
%
Parfois, on a aussi le sens inverse : à partir de la $k$-ième prémisse, si on connaît la règle et le numéro $k$ et la formule principale, on peut construire la conclusion. On dit qu'une règle est \textbf{\emph{locale}} si on a cette dernière propriété pour toutes les prémisses de toutes ses instances.
%
Si toutes les règles sont locales (et si on cherche juste à décider si un séquent est prouvable sans demander d'arbre de preuve le cas échéant), alors on peut ne garder qu'un seul séquent en mémoire à tout moment, plus des informations (numéro de prémisse, formule principale) qui sont moins coûteuses. %C'est donc plus efficace en terme de complexité spatiale.
Lorsqu'on s'intéresse à une instance dont le séquent retenu est conclusion, on transforme ce séquent en une prémisse, sur laquelle on relance l'algorithme. Et inversement, on a parfois besoin de revenir à la conclusion à partir d'une prémisse et des informations supplémentaires retenues : par exemple pour ensuite calculer une autre prémisse de l'instance, ou encore pour essayer d'appliquer une autre règle à la conclusion si on a trouvé une prémisse non prouvable et non inversible.
Ainsi, si toutes les règles du calcul sont locales, on peut améliorer la complexité spatiale de l'algorithme.

%L'algorithme nécessite de savoir déterminer, pour un séquent donné, toutes les instances dont il est conclusion, et en particulier calculer les prémisses de ces instances. Pour une instance, la \emph{formule principale} est la formule de la conclusion qui joue un rôle particulier : elle est remplacée dans les prémisses par une ou plusieurs formules plus simples (règles logiques ; dans ce cas la formule doit avoir une forme particulière, par exemple présenter un connecteur donné), ou dupliquée ou supprimée (règles structurelles). Sous certaines conditions (notamment, absence de règle de coupure) souvent vérifiées, on peut facilement calculer, à partir d'une conclusion donnée et d'une règle et d'un choix de formule principale %adaptée à 
%autorisé par la règle, toutes les prémisses de la seule instance correspondante. Mais ce n'est pas tout. Lorsqu'on s'intéresse à une prémisse, on risque d'avoir à nouveau besoin plus tard de la conclusion, par exemple pour calculer une autre prémisse, ou essayer une autre instance s'il y a une prémisse non inversible non prouvable.
%%
%Une solution consiste à retenir la conclusion pendant qu'on effectue la recherche de preuve sur les différentes prémisses, mais cela peut être coûteux en mémoire. Une autre solution est possible si on sait retrouver la conclusion à partir de n'importe quelle prémisse et %d'informations moins coûteuses : le 
%du numéro de la prémisse concernée et de la formule principale. Une règle dont toutes les instances vérifient ce qui précède est dite \textbf{\emph{locale}}. Si toutes les règles sont locales, on peut ne garder qu'un seul séquent en mémoire à tout moment, plus des informations (numéro de prémisse et formule principale) qui sont moins coûteuses. C'est donc plus efficace en terme de complexité spatiale.





\subsection{Deux exemples de calculs de séquents pour la logique intuitionniste}

%\subsectionDescription{
%LJ.
%LJT.
%}
%\subsectionDescription{LJLJT}

\noindent
\textbf{\LJ.}
%Le calcul \LJ\ présenté dans la première partie %peut difficilement être appliqué à une recherche automatique de preuve tel quel.
%a besoin de quelques ajustements pour pouvoir être appliqué à la recherche automatique de preuves
Pour appliquer le calcul \LJ\ présenté dans la première partie à la recherche automatique de preuves, il faut quelques ajustements sur le calcul lui-même et sur l'algorithme proposé. Il faut notamment enlever la règle de coupure (figure~\ref{fig:reglesLJ}, \emph{cut}), ce qui est possible car le calcul reste évidemment correct, mais surtout complet. Pour la même raison, on peut aussi enlever la règle \emph{weakening}. En revanche, on ne peut pas supprimer purement et simplement la règle\LJcontraction. On ne pourrait 
%en effet 
par exemple
plus prouver la formule %bien connue 
${\lnot\lnot(A\lor\lnot A)}$%, dont une preuve est donnée en figure ?
.
%\ (voir figure~\ref{fig:LJnnTiersExclu}). 
Mais comme on l'a vu, cette règle pose un problème de terminaison de l'algorithme. Une solution consiste à remplacer les deux règles $contraction\ L$ et \LJimpL\ par une seule règle \LJimpLcontr. On n'a alors plus d'appels récursifs sur des séquents strictement croissants $\G,A\To D$ puis $\G,A,A\To D$ puis $\G,A,A,A\To D$ etc. En revanche, on peut avoir un appel récursif sur un séquent déjà rencontré, par exemple si $D=A$, une prémisse est identique à la conclusion dans \LJimpLcontrA. On ajoute alors un système de détection de cycles en retenant tous les séquents rencontrés. L'algorithme obtenu est correct et termine. On a la propriété de la sous-formule. Les règles sont toutes inversibles et locales sauf $\to L$, dont seule la deuxième prémisse est inversible. Mais la détection de cycles est très coûteuse.

%\begin{figure}[h]
%\centering
%\LJnnTiersExclu
%
%\caption{Preuve dans \LJ\ de $\lnot\lnot(A\lor\lnot A)$% : on a besoin de la règle $contraction\ L$
%. Sans la règle $contraction\ L$, le séquent surligné serait $\;\To A\lor\lnot A$ qui n'est pas prouvable.
%}
%\label{fig:LJnnTiersExclu}
%\end{figure}

\

\noindent
\textbf{\LJT.}
Le calcul \LJT\ est introduit par R. Dyckhoff dans \cite{LJT} pour pallier le problème de cycles de \LJ. Il n'y a pas de règle de contraction, et la règle $\to L$ est remplacée par quatre règles selon la structure de $A$ dans la formule principale $A\to B$ : par exemple \LJTimpLun où $A$ doit être %\emph{atomique} c'est-à-dire 
réduite à une variable, ou encore \LJTimpLdeux. On n'a pas la propriété de la sous-formule, mais on peut quand même déterminer toutes les formules susceptibles d'apparaître lorsqu'on essaie de prouver un séquent donné. Dyckhoff montre que l'algorithme termine en choisissant bien un bon ordre sur les formules puis sur les séquents. Toutes les règles sont inversibles et locales sauf une des règles qui remplacent $\imp L$, qui comporte deux prémisses dont seule la deuxième est inversible.




%%%%%


\section{Le calcul de séquents utilisé pour l'implémentation : \LSJ, légèrement modifié en \LSJn}

Le calcul de séquents utilisé pour l'implémentation est \LSJn, une variante de \LSJ. Le calcul \LSJ\ est présenté par M. Ferrari, C. Fiorentini et G. Fiorino dans \cite{LSJ}. Il présente des priopriétés très intéressantes pour l'application à la recherche de preuve. \LSJn\ est fondamentalement le même calcul, %où les séquents sont représentés
avec une représentation des séquents un peu plus riche en informations. Il a été proposé par mon maître de stage D. Larchey-Wendling. \LSJn\ hérite de toutes les bonnes propriétés de \LSJ, en ajoutant la localité des règles.

%

\subsection{Séquents et règles de \LSJ}

%L'article \cite{LSJ} définit le calcul de séquents \LSJ. Une sémantique naturelle des séquents est proposée à l'aide des modèles de Kripke, mais nous ne la présentons pas. En effet, ce qui nous intéresse est l'existence, pour toute formule, d'un séquent qui est prouvable dans le calcul \LSJ\ si, et seulement si, la formule est prouvable en logique intuitionniste. Nous renvoyons à l'article pour les démonstrations, notamment celles de la correction et de la complétude du calcul.



\begin{df}
Un \textbf{\emph{séquent}} de \LSJ\ est la donnée de trois multiensembles $\Th$, $\G$ et $\D$ de formules ; on écrit $\Th\;;\;\G\;\To\;\D$.
\end{df}


%On a vu que dans \LJ, le séquent représente ... et dans \LK,
On a vu que dans les calculs \LK\ et \LJ, le séquent $\G \To \D$ représente la formule \\${\left(\bigwedge_{G\in\G}G\right)\to\left(\bigvee_{D\in\D}D\right)}$, respectivement en logique classique et en logique intuitionniste, avec $\D$ contenant exactement une formule pour \LJ. C'est une interprétation courante en calcul de séquents. Pour \LSJ, on ne sait pas représenter un séquent $\Th\,;\,\G\To\D$ par une seule formule.
%Une sémantique pour les séquents
On a cependant le résultat suivant : un séquent $\emptyset\,;\,\G\To\D$ est prouvable dans \LSJ\ si et seulement si la formule ${\left(\bigwedge_{G\in\G}G\right)\to\left(\bigvee_{D\in\D}D\right)}$ est prouvable en logique intuitionniste.
$\G$ et $\D$ ont donc une signification ordinaire.
En revanche, $\Th$ est propre à \LSJ, et difficile à interpréter. On peut dire que $\Th$ contient des formules gardées en réserve, non accessibles directement (une formule de $\Th$ ne peut pas être \emph{formule principale}), mais qui peuvent être transférées dans $\G$ et ainsi devenir accessibles. On verra que les seules règles qui agissent sur $\Th$ sont celles qui concernent le connecteur $\to$.
L'article \cite{LSJ} propose bien une interprétation du séquent $\Th\;;\;\G\;\To\;\D$ pour $\Th$ quelconque, en utilisant des modèles de Kripke. Nous ne la détaillons pas, car ce qui nous intéresse surtout est la propriété suivante qui découle du résultat énoncé sur un séquent avec $\Th$ vide.
%Une interprétation du séquent $\Th\;;\;\G\;\To\;\D$ pour $\Th$ quelconque est 


%\
%La définition d'un séquent \emph{prouvable} est celle qui a été donnée en \ref{ProuvabiliteSequent} pour le calcul \LJ.
%La définition d'un séquent \emph{prouvable} a été donnée en \ref{ProuvabiliteSequent}.

%\begin{prop}\label{propSignificationSequent}
%%Soit $\G$, $\D$ des multiensembles de formules. Le séquent $\emptyset\;;\;\G\;\To\;\D$ est \textbf{prouvable} dans \LSJ, c'est-à-dire non réfutable, si et seulement si la formule $\bigwedge_{A\in\G}A\,\to\,\bigvee_{B\in\D}B$ est valide en logique intuitionniste.
%Un séquent $\emptyset\;;\;\G\;\To\;\D$ est \textbf{réfutable} si, et seulement si, la formule $\bigwedge_{A\in\G}A\,\to\,\bigvee_{B\in\D}B$ n'est pas valide en logique intuitionniste. Un séquent est \textbf{prouvable} dans \LSJ\ si, et seulement si, il n'est pas réfutable.
%\end{prop}

\begin{prop}
Soit $A$ une formule, elle est valide en logique intuitionniste si et seulement si le séquent \;$\emptyset\,;\,\emptyset\To A$ est  prouvable dans \LSJ.
\end{prop}

\def\mywidth{0.6\textwidth}
\begin{floatingfigure}[r]{\mywidth}
\centering

\resizebox{\mywidth}{!}{

$\begin{array}{cc}
	\LSJfauxL & \LSJid \\\\
	\LSJetL & \LSJetR \\\\
	\LSJouL & \LSJouR \\\\
	\multicolumn{2}{c}{\LSJimpL}\\\\
	\multicolumn{2}{c}{\LSJimpR}
\end{array}$

}

\caption{Les règles du calcul \LSJ}
\label{fig:reglesLSJ}
\end{floatingfigure}

Les \textbf{\emph{règles}} du calcul \LSJ\ sont données dans la figure~\ref{fig:reglesLSJ}. Toutes les règles sont des \emph{axiomes} ou des \emph{règles logiques}. Il n'y a pas de \emph{règle structurelle} ni de règle de \emph{coupure}.

\

\noindent
\textbf{Propriétés de \LSJ.}
(Pour les \\démonstrations, voir \cite{LSJ}.)
Le calcul \LSJ\ est sans contraction et vérifie la propriété de la sous-formule.
L'algorithme décrit dans la deuxième partie termine pour \LSJ.
Les règles $\land L$, $\land R$, $\lor L$ et $\lor R$ sont inversibles ;
les deux premières prémisses de ${\imp L}$ et la première prémisse de ${\imp R}$ sont inversibles ;
la troisième prémisse de ${\imp L}$ et la deuxième prémisse de ${\imp R}$ ne sont pas inversibles.

%On remarque que les règles $\land L$, $\land R$, $\lor L$ et $\lor R$ sont locales. En revanche, les règles $\to L$ et $\to R$ ne sont pas locales : pour chacune, les formules représentées par $\D$ dans la conclusion n'apparaissent nulle part dans la dernière prémisse, il n'est donc pas possible de retrouver la conclusion en connaissant uniquement cette prémisse, la formule principale et le numéro de la prémisse, puisqu'il n'y a aucun moyen d'en déduire ce qui se trouve dans $\D$. C'est pour cette raison qu'on introduit le calcul \LSJn, dans lequel toutes les règles sont locales.

\

\noindent
\textbf{Non localité de certaines règles.}
Les règles $\to L$ et $\to R$ ne sont pas locales : pour chacune, les formules représentées par $\D$ dans la conclusion n'apparaissent nulle part dans la dernière prémisse, il n'est donc pas possible de retrouver la conclusion en connaissant uniquement cette prémisse, la formule principale et le numéro de la prémisse, puisqu'il n'y a aucun moyen d'en déduire ce qui se trouve dans $\D$. C'est pour cette raison qu'on introduit le calcul \LSJn, dans lequel toutes les règles sont locales.


%

\subsection{Séquents et règles de \LSJn}

Le calcul \LSJn\ est très proche du calcul \LSJ : chaque règle de \LSJn\ est l'adaptation directe d'une règle de \LSJ\ à une autre structure des séquents. Contrairement à \LSJ, les règles de \LSJn\ sont toutes locales.
Pour cela, les séquents de \LSJn\ représentent chacun un séquent de \LSJ, avec un peu plus d'informations : celles qui sont parfois nécessaires pour retrouver la conclusion à partir d'une prémisse. Cette représentation est exhaustive et correcte. On définit en effet une surjection $\surj$ de l'ensemble des séquents de \LSJn\ dans l'ensemble des séquents de \LSJ, et on montre dans la sous-section suivante qu'un séquent de \LSJn\ est prouvable dans \LSJn\ si, et seulement si, son image par $\surj$ est prouvable dans \LSJ.

\begin{df}
Un \textbf{\emph{séquent}} de \LSJn\ est la donnée de deux multiensembles $\Gp$ et $\Dp$ de couples \emph{``~entier~:~formule~''}, et d'un entier naturel $n$, tels que tous les entiers présents dans $\Gp$ sont $\leq n+1$ et tous ceux présents dans $\Dp$ sont $\leq n$ ; on écrit $\Gp \Rightarrow_{n} \Dp$.
\end{df}

\noindent
\textbf{Lien avec les séquents de \LSJ\ : l'application $\surj$.}
Soit $M$ un multiensemble de couples ``~\emph{entier~:~formule}~'', l'entier d'un couple étant appelé son indice. On note $M_{k}$ le multiensemble obtenu à partir de $M$ en ne gardant que les couples d'indice $k$, et $M_{\leq k}$ celui obtenu en ne gardant que les couples d'indice inférieur à $k$. On note $\forget(M)$ le multiensemble de formules obtenu en oubliant l'indice et ne gardant que la formule de chaque couple de $M$.
On définit l'application $\surj$ de 
l'ensemble des séquents de \LSJn\ dans l'ensemble des séquents de \LSJ
%$\Sig'$ dans $\Sig$
, qui à $\G' \To_{n} \D'$ associe $\Th\, ;\G \To \D$ %\quad 
\noindent
où~:~
$\left\{
\begin{array}{l}
%	\Th = \{ A \:|\: n+1:A \in \G'\} \\
%	\G = \{ A \:|\: \exists i\leq n,\ i:A \in \G'\} \\
%	\D = \{ A \:|\: n:A \in \D'\}
	\Th = \forget (\G'_{n+1}) \\
	\G = \forget (\G'_{\leq n}) \\
	\D = \forget (\D'_{n})
\end{array}
\right.$.
C'est une \textbf{surjection} : en effet tout séquent $\Th \,;\G\To\D$ de \LSJ\ a au moins pour antécédent le séquent $\G' \To_{0} \D'$, 
avec ${\G' = 0 : \G \cup 1:\Th}$ et ${\D'=0:\D}$, où par exemple $0 : \G$ est le multiensemble de couples obtenu à partir de $\G$ en rempla\c cant chaque occurrence d'une formule $A$ par une occurrence du couple $0:A$.
%où $\G'$ est l'union de $0 : \G$ (le multiensemble de couples obtenu à partir de $\G$ en rempla\c cant chaque occurrence d'une formule $A$ par une occurrence du couple $0:A$) avec $1:\Th$, et où $\D'=0:\D$.



\def\mywidthbis{0.79\textwidth}%0.79
\begin{floatingfigure}[r]{\mywidthbis}
\centering

\resizebox{\mywidthbis}{!}{

%\emph{$n$ et parfois $i$ désignent toujours des entiers naturels, avec $i\leq n$}

$\begin{array}{cc}
	\multicolumn{2}{c}{\emph{$n$ et parfois $i$ désignent toujours des entiers naturels, avec $i\leq n$}} \\\\
	\LSJLfauxL & \LSJLid \\\\
	\LSJLetL & \LSJLetR \\\\
	\LSJLouL & \LSJLouR \\\\
	\multicolumn{2}{c}{\LSJLimpL}\\\\
	\multicolumn{2}{c}{\LSJLimpR}
\end{array}$

}

\caption{Les règles du calcul \LSJn}
\label{fig:reglesLSJn}
\end{floatingfigure}

\

Les \textbf{\emph{règles}} du calcul \LSJn\ sont données dans la figure~\ref{fig:reglesLSJn}. Chacune correspond à une règle de \LSJ.

\

\LSJn\ présente les mêmes propriétés que \LSJ, auxquelles s'ajoute la localité de toutes les règles.

\

%

\subsection{\'Equivalence entre \LSJn\ et \LSJ}

On note $\Sig$ l'ensemble des séquents de \LSJ, et $\Sig'$ l'ensemble des séquents de \LSJn.
Soit $\sigma\in\Sig$, on note $\vdash\sigma$ si $\sigma$ est prouvable dans \LSJ\ ; soit $\sigma'\in\Sig'$, on note $\vdash'\sigma'$ si $\sigma'$ est prouvable dans \LSJn.
Montrons que pour tous $\s\in\Sig$ et $\s'\in\Sig'$ tels que $\s=\surj(\s')$, on a $\vdash\s$ si et seulement si $\vdash\s'$, où $\surj$ est la surjection de $\Sig'$ sur $\Sig$ définie précédemment.

Soit $\mathcal R$ une règle de \LSJ. On note $\mathcal R'$ la règle de \LSJn\ qui lui correspond. On écrit \instanceR\ et \instanceRp\ des instances de ces règles.

\begin{lm}
Soit $\sigma\in\Sig$ et $\sigma'\in\Sig'$ tels que $\sigma=\surj(\sigma')$ et soit $\mathcal R$ une règle de \LSJ.

1) Si \instanceR alors il existe $\s'_{1}$, ... , $\s'_{p}$ tels que pour tout $k$, $\s_{k} = \surj (\s'_{k})$, et \instanceRp.

2) Si \instanceRp, posons pour tout $k$, $\s_{k} = \surj (\s'_{k})$, alors \instanceR.

\noindent
Pour un axiome $\mathcal A$, cela signifie simplement : \instanceAx si et seulement si \instanceAxp.
\end{lm}

\begin{proof}
On le montre pour chaque règle ; c'est une conséquence assez directe de la définition de $\surj$. Faisons-le par exemple pour $id$ et $\to\negthickspace L$. \`A chaque fois, on se donne $\s = \Th\, ;\G \To \D$ et $\s' = \G' \To_{n} \D' \in\Sig'$ tels que $\s=\surj(\s')$.

%\noindent
$\mathbf{id}$: \quad On a\instanceid\ si et seulement s'il existe une formule $A$ appartenant à la fois à $\G$ et $\D$, ce qui équivaut, par définition de $\surj$, à : il existe $A$ et $i\leq n$ tels que $n:A\in\D'$ et $i:A\in\G'$, c'est-à-dire \instanceidp.


%\noindent 
%$\boldsymbol\land \boldsymbol R$ :	\quad
%%
%1) Si \instanceetR\ alors il existe des formules $A$ et $B$ et un multiensemble $\Dt$ tels que $\D = A \land B, \Dt$ et $\s_{1} = \Th\, ;\G \To A,\Dt$ et $\s_{2} = \Th\, ;\G \To B,\Dt$.
% Posons $\Dt' = \D' - n:A \land B$ le multiensemble obtenu en retirant une seule occurrence de $n:A\land B$ à $\D'$ (qui contient cet élément parce que $\D$ contient $A\land B$ et par définition de $\surj$),
% et $\s'_{1} = \G' \To_{n} n:A,\Dt'$ et $\s'_{2} = \G' \To_{n} n:B,\Dt'$.
% Alors on a bien $\s_{1}=\surj(\s'_{1})$ et $\s_{2}=\surj(\s'_{2})$ (en remarquant que 
% %$\Dt = \{ C \:|\: n:C \in \Dt'\}$
%$\Dt = \forget (\Dt'_{n})$
%), et \instanceetRp (en remarquant que $\s' = \G' \To_{n} n:A \land B,\Dt'$).
%%
%\quad2)~
%Si \instanceetRp\ alors il existe $A$, $B$ et $\Dt'$ tels que $\D' = n:A \land B, \Dt'$ et $\s'_{1} = \G' \To_{n} n:A,\Dt'$ et $\s'_{2} = \G' \To_{n} n:B,\Dt'$ ; 
% on pose $\Dt = \D - A \land B$ le multiensemble obtenu en retirant une seule occurrence de $A\land B$ à $\D$,
% et $\s_{1}=\surj(\s'_{1})$ et $\s_{2}=\surj(\s'_{2})$ ; on obtient $\s = \Th\, ;\G \To A\land B,\Dt$ et $\s_{1} = \Th\, ;\G \To A,\Dt$ et $\s_{2} = \Th\, ;\G \To B,\Dt$\; d'où\instanceetR.

%\noindent 
$\boldsymbol\to \negthickspace \boldsymbol L$ :	\quad
%
1) Si \instanceimpL\ alors il existe $A$, $B$ et $\Gt$ tels que $\G=A\to B,\Gt$ et $\s_{1} = \Th\, ;B,\Gt \To \D$ et $\s_{2} = B,\Th\, ;\Gt \To A,\D$ et $\s_{3} = B \,; \Th,\Gt \To A$ ; et il existe $i\leq n$ tel que $i:A\to B\in\G'$. On pose $\Gt' = \G' - i:A\to B$ (on retire une seule occurrence de $i:A\to B$ de $\G'$) et $\s'_{1} = i:B,\Gt' \To_{n} \D'$ et $\s'_{2} = n+1:B,\Gt' \To_{n} n:A,\D'$ et $\s'_{3} = n+2:B,\Gt' \To_{n+1} n+1:A, \D'$ et on vérifie qu'on a bien
$\s_{1}=\surj(\s'_{1})$ et $\s_{2}=\surj(\s'_{2})$ et $\s_{3}=\surj(\s'_{3})$ (en remarquant que 
$\Gt = \forget (\Gt'_{\leq n})$
), et aussi\instanceimpLp).
\linebreak
%
\quad2)~
Si \instanceimpLp\ alors il existe $i$, $A$, $B$ et $\Gt'$ tels que $\G'=i:A\to B,\Gt'$ et $\s'_{1}$, $\s'_{2}$ et $\s'_{3}$ ont la forme donnée ci-dessus ; on pose $\Gt = \G - A\to B$ (on retire une seule occurrence de $A\to B$ de $\G$), alors les images $\s_{1}$, $\s_{2}$ et $\s_{3}$ par $\surj$ de $\s'_{1}$, $\s'_{2}$ et $\s'_{3}$ respectivement s'écrivent comme ci-dessus et donc ${\instanceimpL.}$
\end{proof}


\begin{theo}
Soit $\sigma\in\Sig$ et $\sigma'\in\Sig'$ tels que $\sigma=\surj(\sigma')$, alors $\vdash \sigma$ si et seulement si $\vdash' \sigma'$.
%Soit $\sigma$ un séquent de \LSJ\ et $\sigma'$ un séquent de \LSJn\ tels que $\sigma=\surj(\sigma')$, alors $\vdash \sigma$ si et seulement si $\vdash' \sigma'$.
\end{theo}

\begin{proof}
Par récurrence sur la \emph{taille} de $\s\in\Sig$, c'est-à-dire la somme des tailles des formules des trois multiensembles apparaissant dans $\s$.

\

\noindent
On initialise pour tout $\sigma = \Th\, ;\G \To \D$ tel que toutes les formules dans $\G$ et dans $\D$ sont atomiques : soit $\sigma' = \G' \To_{n} \D' \in\Sig'$ tel que $\sigma=\surj(\sigma')$. Alors toutes les formules associées à un $i \leq n$ dans $\G'$ et toutes les formules associées à $n$ dans $\D'$ sont aussi atomiques. En étudiant la forme des conclusions des règles non axiomatiques de \LSJ\ comme de \LSJn,
on remarque que si $\s$ (resp. $\s'$) est la conclusion d'une règle de \LSJ\ (resp. \LSJn), alors la règle est un axiome. L'initialisation est donc un cas particulier de ce qui suit avec $p=0$ (ce qui entraîne qu'on n'utilise en fait pas l'hypothèse de récurrence).

% on obtient que : $\vdash \s$ si et seulement si $\s$ est une conséquence directe d'un axiome de \LSJ, et $\vdash' \s'$ si et seulement si $\s'$ est une conséquence directe d'un axiome de \LSJn. Or d'après le lemme, pour $\mathcal A$ axiome de \LSJ, \instanceAx si et seulement si \instanceAxp. On en déduit $\vdash \sigma$ si et seulement si $\vdash' \sigma'$.

\

\noindent
Soit $\s = \Th\, ;\G \To \D \in\Sig$. Soit $\sigma' = \G' \To_{n} \D' \in\Sig'$ tel que $\sigma=\surj(\sigma')$.

On suppose $\vdash \s$. Alors il existe une règle $\mathcal R$ de \LSJ\ et $\s_{1}$, ... , $\s_{p} \in\Sig$ (avec éventuellement $p$ nul) tels que $\vdash \s_{k}$ pour tout $k$ et\instanceR. D'après le lemme, il existe $\s'_{1}$, ... , $\s'_{p} \in\Sig'$ tels que $\s_{k}=\surj(\s'_{k})$ pour tout $k$ et\instanceRp. Pour tout $k$, on applique l'hypothèse de récurrence à $\s_{k}$ qui a une \emph{taille} strictement inférieure à celle de $\s$, et on obtient $\vdash' \s'_{k}$. On en déduit $\vdash' \s'$.

On suppose $\vdash' \s'$. Alors il existe une règle $\mathcal R'$ de \LSJn\ et $\s'_{1}$, ... , $\s'_{p} \in\Sig'$ tels que $\vdash' \s'_{k}$ pour tout $k$ et\instanceRp. On pose $\s_{k}=\surj(\s'_{k})$ pour tout $k$. D'après le lemme on a \instanceR, en particulier on peut appliquer l'hypothèse de récurrence aux $\s_{k}$ donc $\vdash \s_{k}$ pour tout $k$, d'où $\vdash \s$.
\end{proof}








\section{\'Eléments d'implémentation}


On utilise l'algorithme dont le pseudo-code est donné dans \cite{LSJ}. Il s'agit de l'algorithme donné en \ref{algoGeneral}, en mettant à profit l'inversibilité de la plupart des règles et prémisses. Adapter l'algorithme de \LSJ\ à \LSJn\ est immédiat ; cependant, on ne garde en mémoire qu'un seul séquent qu'on modifie en place, et on utilise la localité des règles pour retrouver le séquent initial avant d'essayer une nouvelle prémisse ou une nouvelle instance. 

\subsection{Ordre d'essai des instances : choix de la formule principale}
\label{subsection:choixFormulePrincipale}

Ce qui est précisé dans \cite{LSJ}, mais pas en \ref{algoGeneral} puisque c'est propre au calcul \LSJ, est l'ordre dans lequel on s'intéresse aux différentes instances dont un séquent donné est conclusion. On privilégie naturellement celles qui offrent une possibilité de terminer rapidement la recherche de preuve, ce qui induit une priorité en fonction de la règle associée : d'abord les axiomes, puis les règles inversibles à une seule prémisse $\land L$ et $\lor R$, puis celles à deux prémisses $\land R$ et $\lor L$, et enfin les règles non inversibles $\imp L$ et $\imp R$. 

Une formule est dite \emph{composée} si elle est de la forme $A\,c\,B$ avec $c$ un connecteur, c'est-à-dire non réduite à $\bot$ ou une variable.
%
%Par ailleurs, pour une formule donnée de la conclusion, on remarque qu'
On remarque que, pour une formule composée donnée d'un séquent,
il y a exactement une instance dont ce séquent est conclusion avec cette formule comme formule principale, et la règle associée ne dépend que de la formule et de 
%son appartenance à $\G$ ou à $\D$
sa position \emph{à gauche} (dans $\G$) ou \emph{à droite} (dans $\D$) du séquent
. De plus toute instance ne correspondant pas à un axiome a une formule principale, qui est composée. Décider l'instance à considérer revient alors à choisir une formule principale. 


\begin{floatingfigure}[r]{4.5cm}
\centering
$
\begin{array}{ccc}
	\text{Forme} & \text{Côté} & \text{Priorité} \\
	A\land B & L & 1 \\
	A\lor B & R & 2 \\
	A\lor B & L & 3 \\
	A\land B & R & 4 \\
	A\imp B & L & 5 \\
	A\imp B & R & 5 \\
\end{array}
$
\caption{Priorité selon la forme de la formule et son appartenance à $\G$ (``côté $L$'') ou $\D$ (``côté $R$'')}
\label{fig:priorite}
\end{floatingfigure}


Pour cela, on associe à toute formule composée 
%(c'est-à-dire de la forme $A\,c\,B$ avec $c$ un connecteur)
de $\G$ et de $\D$ une \textbf{priorité} selon la figure~\ref{fig:priorite}. Plus l'entier est petit, plus la formule est prioritaire. On choisit alors la formule la plus prioritaire parmi les formules ``accessibles'', c'est-à-dire les formules de $\G$ auxquelles est associé un indice inférieur à l'indice $n$ du séquent, ou celles de $\D$ avec un indice égal à $n$ ; ce sont exactement les formules qui auraient figuré dans $\G$ ou $\D$ d'un séquent $\Th\,;\G\To\D$ de \LSJ. Ce choix de formule principale n'intervient qu'après avoir testé les axiomes. S'il n'y a aucune formule principale possible, le séquent est non prouvable. Le seul cas où on peut avoir plusieurs instances à tester pour un séquent donné est celui où la priorité la plus petite donc la plus forte est $5$. Dans ce cas, on teste successivement les formules ``accessibles'' de forme $A\to B$ de $\G$ comme de $\D$, jusqu'à trouver une instance dont toutes les prémisses sont prouvables donc aussi la conclusion, ou les avoir toutes testées sans succès et conclure que le séquent initial n'est pas prouvable. On a arbitrairement choisi que $\land L$ est prioritaire sur $\lor R$. Cela permet de déduire directement de la priorité la règle concernée, sauf dans le cas particulier des ``implique''.





\subsection{Indexation}

Une formule peut être considérée comme un \textbf{arbre binaire} dont les feuilles sont étiquetées par la constante $\bot$ ou une variable propositionnelle, et les n\oe uds internes sont étiquettés par un connecteur binaire. La notion de sous-formule correspond alors à celle de sous-arbre. On rappelle qu'une formule est \textbf{\emph{atomique}} si elle est réduite à $\bot$ ou à une variable, c'est-à-dire si l'arbre associé est une feuille.
%
On utilise la propriété de la sous-formule, que \LSJn\ hérite de \LSJ, pour obtenir une représentation des formules plus facile à manipuler. En effet, si l'objectif est de déterminer la prouvabilité de la formule $A$ en logique intuitionniste, on applique l'algorithme de preuve au séquent $\; \To A$, donc toutes les formules susceptibles d'apparaître sont des sous-formules de la formule $A$. On peut ainsi réaliser une phase préliminaire d'\textbf{indexation} où on associe un entier à chaque sous-formule de $A$, c'est-à-dire chaque n\oe ud (n\oe ud interne ou feuille) de l'arbre correspondant. On retient en plus un tableau qui à l'entier représentant la formule $B$, associe : la constante $\bot$ ou la variable locale correspondant à $B$ si $B$ a cette forme, ou ``$i$ $c$ $j$'' si $B=C\,c\,D$ avec $c$ un connecteur binaire et $i$, $j$ les entiers respectivement associés à $C$, $D$. Le nombre de cases de ce tableau est la taille de la formule $A$ dont on veut décider la prouvabilité. On peut alors accéder facilement aux fils de n'importe quelle formule considérée, et comme on a récursivement cette information sur les fils, on peut retrouver, à partir du numéro d'une formule, toutes les informations de l'arbre associé.

+ côté ?

La figure~\ref{fig:indexation} donne un exemple d'indexation. ``sf'' comme ``sous-formule'' est le numéro associé à une formule, ``description'' ce qui est stocké dans le tableau, est ``classe'' est expliqué dans la prochaine sous-section.



%\
%
%\noindent
%\textbf{Priorités.}
%Les priorités de la sous-section précédente peuvent être déterminées au cours de l'indexation. Car les connecteurs sont bien sûr connus, mais surtout, on peut décider de quel côté du séquent une formule donnée est susceptible d'apparaître. On se donne un ensemble à deux éléments $E=\{gauche,droite\}$. Si $\Ccal$ est un élément de $E$, on note $\bar\Ccal$ l'autre élément de $E$. On constate en observant les règles que si une formule $H=A\land B$ ou $H=A\lor B$ apparaît du côté $\Ccal$ d'un séquent, alors $A$ et $B$ ne peuvent apparaître dans une séquent que du même côté $\Ccal$ ; et si $H=A\to B$ apparaît du côté $\Ccal$, alors $B$ ne peut apparaître que du même côté $\Ccal$, et $A$ du côté opposé $\bar\Ccal$. Comme on sait que dans la recherche de preuve pour une formule $A$, cette formule apparaît à $droite$ dans le séquent initial $\;\To A$, on est capable d'associer un côté, puis une priorité à chaque sous-formule de $A$.




%\begin{center}
%\begin{tikzpicture}[xscale=1,yscale=1]
%% Styles (MODIFIABLES)
%\tikzstyle{fleche}=[->,>=latex,thick]
%\tikzstyle{noeud}=[fill=yellow,circle,draw]
%\tikzstyle{feuille}=[fill=yellow,circle,draw]
%% Dimensions (MODIFIABLES)
%\def\DistanceInterNiveaux{1}
%\def\DistanceInterFeuilles{1}
%% Dimensions calculées (NON MODIFIABLES)
%\def\NiveauA{(-0)*\DistanceInterNiveaux}
%\def\NiveauB{(-1)*\DistanceInterNiveaux}
%\def\NiveauC{(-2)*\DistanceInterNiveaux}
%\def\InterFeuilles{(1)*\DistanceInterFeuilles}
%% Noeuds (MODIFIABLES : Styles et Coefficients d'InterFeuilles)
%\node (R) at ({(0.5)*\InterFeuilles},{\NiveauA}) {$f$};
%\node (Ra) at ({(0)*\InterFeuilles},{\NiveauB}) {$g$};
%\node (Raa) at ({(0)*\InterFeuilles},{\NiveauC}) {$a$};
%\node (Rb) at ({(1)*\InterFeuilles},{\NiveauB}) {$a$};
%% Arcs (MODIFIABLES : Styles)
%\draw (R)--(Ra);
%\draw (Ra)--(Raa);
%\draw (R)--(Rb);
%\end{tikzpicture}
%\end{center}
%%:-+-+-+-+- Fin

\def\arbreIndexation{
%\begin{center}
\begin{tikzpicture}[xscale=1,yscale=1]
% Styles (MODIFIABLES)
\tikzstyle{fleche}=[->,>=latex,thick]
\tikzstyle{noeud}=[fill=yellow,circle,draw]
\tikzstyle{feuille}=[fill=yellow,circle,draw]
% Dimensions (MODIFIABLES)
%\def\DistanceInterNiveaux{1}
%\def\DistanceInterFeuilles{1.5}
\def\DistanceInterNiveaux{1}
\def\DistanceInterFeuilles{1.5}
% Dimensions calculées (NON MODIFIABLES)
\def\NiveauA{(-0)*\DistanceInterNiveaux}
\def\NiveauB{(-1)*\DistanceInterNiveaux}
\def\NiveauC{(-2)*\DistanceInterNiveaux}
\def\NiveauD{(-3)*\DistanceInterNiveaux}
\def\InterFeuilles{(1)*\DistanceInterFeuilles}
% Noeuds (MODIFIABLES : Styles et Coefficients d'InterFeuilles)
\node (R) at ({(2)*\InterFeuilles},{\NiveauA}) {$\autour{\imp}{11}{7}{D}{?}$};
\node (Ra) at ({(0.5)*\InterFeuilles},{\NiveauB}) {$\autour{\land}{3}{3}{D}{?}$};
\node (Raa) at ({(0)*\InterFeuilles},{\NiveauC}) {$\autour{A}{1}{1}{D}{?}$};
\node (Rab) at ({(1)*\InterFeuilles},{\NiveauC}) {$\autour{B}{2}{2}{D}{?}$};
\node (Rb) at ({(3.5)*\InterFeuilles},{\NiveauB}) {$\autour{\lor}{10}{6}{D}{?}$};
\node (Rba) at ({(2.5)*\InterFeuilles},{\NiveauC}) {$\autour{\imp}{6}{5}{D}{?}$};
\node (Rbaa) at ({(2)*\InterFeuilles},{\NiveauD}) {$\autour{\bot}{4}{0}{D}{?}$};
\node (Rbab) at ({(3)*\InterFeuilles},{\NiveauD}) {$\autour{C}{5}{4}{D}{?}a$};
\node (Rbb) at ({(4.5)*\InterFeuilles},{\NiveauC}) {$\autour{\land}{9}{3}{D}{?}$};
\node (Rbba) at ({(4)*\InterFeuilles},{\NiveauD}) {$\autour{A}{7}{1}{D}{?}$};
\node (Rbbb) at ({(5)*\InterFeuilles},{\NiveauD}) {$\autour{B}{8}{2}{D}{?}$};
\node (legende) at ({(4.5)*\InterFeuilles},{\NiveauA}) {$\autour{\text{n\oe ud}}{\textbf{sf}}{\textit{classe}}{D}{?}$};
% Arcs (MODIFIABLES : Styles)
\draw (R)--(Ra);
\draw (Ra)--(Raa);
\draw (Ra)--(Rab);
\draw (R)--(Rb);
\draw (Rb)--(Rba);
\draw (Rba)--(Rbaa);
\draw (Rba)--(Rbab);
\draw (Rb)--(Rbb);
\draw (Rbb)--(Rbba);
\draw (Rbb)--(Rbbb);
\end{tikzpicture}
%\end{center}
%:-+-+-+-+- Fin
}



\begin{figure}[h]
\centering
\includegraphics[width=0.3\linewidth]{indexation} %Quelques_formules.f12
\qquad
\arbreIndexation
\caption{Indexation de la formule $(a\land b)\land(\lnot c \lor (a\land b))$}
\label{fig:indexation}
\end{figure}



\subsection{Classes d'égalité structurelle pour l'axiome $id$}
\label{subsection:classes}

L'axiome\LSJLid\ $(i\leq n)$ affirme qu'un séquent est prouvable si une même formule $A$ apparaît, de fa\c con ``accessible'' (condition sur les indices), de part et d'autre du séquent. 
%
``même formule'' est à comprendre au sens de l'égalité structurelle, c'est-à-dire l'égalité des arbres associés. Tester cette égalité entre les arbres est long (de l'ordre du nombre de n\oe uds du plus petit). On préfère, au cours de l'indexation, construire un deuxième tableau, qui à chaque numéro de formule associe un numéro de \emph{classe}, à comprendre comme les classes d'équivalence de l'égalité structurelle. Ainsi, on détermine en temps constant si les formules associées à deux entiers donnés sont égales structurellement. %Ces classent apparaissent dans la figure~\ref{?}.
Voir la figure~\ref{fig:indexation}.



%



\subsection{Structure de données pour les multiensembles $\G$ et $\D$ du séquent}



Soit $\s=\G\To\D$ le séquent qu'on garde en mémoire au cours de l'algorithme. Le choix de la représentation de $\G$ et $\D$, multiensembles de couples ``\emph{ indice\,:\!formule }'', est motivé par ce qui suit. On doit souvent, et donc on voudrait pouvoir rapidement
\begin{itemize}
\item
choisir un couple principal $i:H$ le plus prioritaire ;
\item
retirer le couple principal choisi $i:H$ du séquent donc de $\G$ ou $\D$, et si $H=A\,c\,B$, ajouter $j:A$ ou $k:B$ où $j$ et $k$ sont des indices valant $n$, l'indice du séquent, ou $n+1$ ;
\item
inversement, retirer $j:A$ ou $k:B$ et rajouter $i:H$.
\end{itemize}


Nous représentons $\G$, comme $\D$, par un tableau à $6?$ cases, une par priorité. Dans la case $p$ se trouve une liste de couples (\;\emph{un indice $i$}\;,\; \emph{la liste des formules H de priorité $p$ telles que $i\!:\!H$ est dans $\G$ (resp. $\D$)}\;) ; ces couples sont triés par indices décroissants ; un tel couple n'est présent que si sa liste de formules est non vide. %Voir l'exemple de la figure~\ref{?}.

Le tableau indexé par les indices permet d'une part un choix rapide du couple principal, et d'autre part, d'ajouter rapidement n'importe quel couple $j:A$ quelle que soit sa priorité. Utiliser par exemple une liste de tous les couples triés par priorité assurerait le premier point, mais pas le second. Le tri des indices par ordre décroissant est pour l'ajout de $j:A$ ou $k:B$, car dans toutes les règles, $j$ et $k$ valent $n$ ou $n+1$, où $n$ est l'indice du séquent. Avoir un seul couple avec une liste de formules par indice permet l'ajout en temps constant d'un couple d'indice $n$ même dans $\G$, où il peut y avoir des couples d'indice $n+1$. Le retrait du couple principal $i:H$ ne pose pas de problème : par choix du couple principal, il se trouve au début de la liste. Enfin, pour assurer que retirer $j:A$ ou $k:B$ ou rajouter $i:H$ se fait aussi en temps constant, on vérifie qu'entre le moment où on passe d'une conclusion d'une instance à une prémisse, et celui où on repasse de la prémisse à la conclusion, la représentation des multiensembles de la prémisse est exactement la même, avec toutes les listes dans le même ordre. 
%
On obtient bien toutes les opérations voulues en temps constant, sauf dans un cas : lorsque les formules les plus prioritaires sont des ``implique'', il faut parfois en essayer plusieurs. On effectue des permutations circulaires pour faire varier le couple principal, choisi comme celui en tête de liste. On n'oublie pas, selon le nombre de couples principaux qui ont été essayés, de finir de permuter les formules afin de bien revenir à une représentation du séquent identique à la représentation initiale.
%Un problème se pose cependant si les formules les plus prioritaires sont les ``implique'' : il faut parfois en essayer plusieurs. On le résout en effectuant chaque fois une permutation circulaire afin de mettre un nouveau couple en tête de liste, qui sera choisi comme couple principal.

%Une structure de données similaire, avec un tableau indexé par les classes d'égalité structurelle et dans la case $cl$, des listes de couples (\;\emph{un indice $i$}\;,\;\emph{le nombre de couples $i:H$ où $H$ est de classe $cl$ dans $\G$ (resp. $\D$)}\;), est utilisée pour retenir les classes apparaissant dans le séquent afin de vérifier rapidement si l'axiome $id$ s'applique.



%



\subsection{Informations supplémentaires pour un test rapide des axiomes}

Les axiomes sont testés à chaque appel récursif sur un nouveau séquent. L'axiome $id$ notamment est long à tester naïvement : il faudrait tester, pour tout couple $(A,B)$ de formules ``accessibles'' avec $A$ dans $\G$ et $B$ dans $\D$, si $A=B$ (égalité structurelle expliquée en \ref{subsection:classes}). La complexité associée est le produit des cardinaux de $\G$ et $\D$. On préfère retenir les multiensembles obtenus à partir de $\G$ et $\D$ en rempla\c cant la formule de chaque couple par sa classe, appelés respectivement $Cl\G$ et $Cl\D$. On retient également deux variables booléennes $fauxL$ et $id$. Lorsqu'on ajoute une formule à $\D$, on met à jour $Cl\D$, et on vérifie si la classe de la formule ajoutée est présente et ``accessible'' dans $Cl\G$, auquel cas on assigne $vrai$ à $id$. De même pour un ajout à $\G$ en inversant $Cl\D$ et $Cl\G$, mais en plus, si la formule ajoutée est $\bot$ avec un indice inférieur à celui du séquent, on assigne $vrai$ à $fauxL$. Lorsqu'on transforme une prémisse d'une instance en la conclusion, on réassigne $faux$ aux deux variables : si l'instance a été testée, c'est parce qu'aucun axiome n'était applicable à la conclusion.

L'intérêt d'avoir remplacé les formules par leur classe est qu'on peut représenter $Cl\G$ et $Cl\D$ avec une structure de données similaire à celle pour $\G$ et $\D$ : un tableau indexé par les classes et dans la case $cl$, une liste de couples (\;\emph{un indice $i$}\;,\;\emph{le nombre de couples $i\!:\!cl$ dans $Cl\G$ (resp. $Cl\D$)}\;). Vérifier si une classe donnée est présente et ``accessible'' se fait alors en temps constant.



\section{Perspective de certification}

Un des objectifs du stage était de s'intéresser à la certification d'un prouveur de logique intuitionniste s'appuyant sur \LSJ. \'Ecrire la certification d'un tel programme est très long et n'a pas été abordé. 
%En revanche, plusieurs variantes d'implémentation, dont la certification devrait être plus facile mais dont l'efficacité est diminuée, on été étudiées.
En revanche, l'implémentation a été modifiée de fa\c con à faciliter la certification, au détriment de l'efficacité. Plusieurs variantes d'implémentation ont ainsi été étudiées, afin de comparer certaines méthodes en termes de facilité de certification et d'efficacité.

\subsection{Un langage simple pour faciliter la certification}

Un premier pas vers la certification est l'utilisation d'un langage relativement simple, afin de limiter le nombre de propriétés à démontrer. Le langage que nous avons employé pour cette raison, qu'on notera \T, comporte un seul type de données : des arbres binaires, qui consistent en l'arbre vide ou une feuille étiquetée par un entier naturel ou un couple d'arbres. Les expressions sont données dans la figure~\ref{fig:expr}, \emph{var} désignant une variable et \emph{nomf} un nom de fonction, les chevrons $<.,.>$ étant utilisés pour les couples d'arbres. La condition du \textbf{if} doit être une feuille d'un entier $n$, correspondant à \emph{faux} si $n=0$ et \emph{vrai} sinon ; \textbf{isnull}, \textbf{isint} et la comparaison renvoient de même une feuille contenant $0$ ou $1$. La première expression du \textbf{match} doit s'évaluer à un couple, sinon il y a une erreur à l'exécution. De même, dans la comparaison ou dans \textbf{succ} (successeur) ou \textbf{pred} (prédécesseur), les expressions doivent être des feuilles. Une déclaration de fonction est un triplet de la forme (\emph{nomf}, \emph{var}, \emph{expr}) comportant le nom de la fonction, celui de son argument, et enfin son corps dans lequel l'argument peut apparaître comme une variable libre. Un programme consiste en une liste de déclarations de fonctions considérées comme mutuellement récursives, puis une expression à évaluer.

L'intérêt d'utiliser ce langage est que mon encadrant D. Larchey-Wendling a réalisé pour celui-ci un compilateur certifié vers une machine abstraite, ainsi qu'un interpréteur certifié de cette machine abstraite. Son objectif est justement l'écriture grâce à ce langage d'un prouveur certifié.

\begin{figure}[h]
\centering	
\def\expr{\emph{expr}}
%\expr\ = \emph{vide} $\mid$ 
\def\pipe{\;\mid\;}
$
\begin{array}{ccl}
expr = & &
	var 
	\pipe vide 
	\pipe n \in \mathbb N 
	\pipe <\!expr,expr\!>
	\pipe \textbf{match } expr  \textbf{ with } <\!var,var\!>\; \Rightarrow expr
\\ & \mid &
	\textbf{let } var = expr \textbf{ in } expr
	\pipe \textbf{call } nomf \ expr
	\pipe \textbf{isnull } expr
	\pipe \textbf{isint } expr
\\ & \mid &
	expr \leq expr
	\pipe \textbf{if } expr \textbf{ then } expr \textbf{ else } expr
	\pipe \textbf{succ } expr
	\pipe \textbf{pred } expr
\end{array}
$
\caption{Les expressions du langage \T}
\label{fig:expr}
\end{figure}



%



\subsection{Compilation d'un programme spécifique à une formule donnée}

On a vu en \ref{subsection:choixFormulePrincipale} que pour une formule composée donnée d'un séquent, il y a exactement une instance dont le séquent est conclusion avec cette formule principale, et la règle associée ne dépendent que du connecteur de la formule et de sa position à gauche ou à droite du séquent. Ces informations sont connues à l'issue de l'indexation. On peut alors calculer, pour chaque formule composée, de numéro $f$, et chaque prémisse, de numéro $k$, de l'unique règle associée, des fonctions de transformation de séquent $prem_{f,k}$ et $rev_{f,k}$, qui permettent de passer de la conclusion à la $k$-ième prémisse et réciproquement. Ces fonctions prennent en arguement l'indice $i$ de la formule principale, qui n'est connu qu'à l'exécution.

On peut ainsi, pour une formule donnée, compiler un code dans lequel des fonctions pour chaque sous-formule sont écrites en dur. L'exécution de ce code doit ensuite renvoyer si cette formule est prouvable. Calculer ces fonctions n'est pas très long par rapport à la recherche de preuve elle-même, effectuée à l'exécution, au cours de laquelle chacune de ces fonctions peut être appelée à plusieurs reprises.

L'intérêt principal de cette approche est qu'elle permet de se fixer un premier objectif : certifer le programme qui a été compilé en fonction de la formule, c'est-à-dire montrer que son exécution renvoie bien la prouvabilité de la formule. Ensuite, bien sûr, il faut aussi certifier la compilation vers ce programme afin d'obtenir un prouveur certifé. Mais pour l'instant, on continue à effectuer l'indexation, puis la compilation vers \T\ des fonctions associées aux sous-formules, en OCaml. On ajoute ensuite ces fonctions à du code en \T\ ne dépendant pas de la formule, pour obtenir un code intégralement en \T\ dont l'exécution doit renvoyer la prouvabilité de la formule initiale.




%



\subsection{Comparaison de différentes implémentations}



\bibliographystyle{plain}
\bibliography{LSJn}


%\end{document}

%%%%%

\pagebreak

\section*{Efficacité de \LSJ}


L'étude qui suit porte sur le calcul \LSJ. En effet, \LSJn\ hérite de toutes les propriétés intéressantes de \LSJ, en apportant une localité des règles qui facilite une implémentation économe en mémoire.


\subsection{Propriété de la sous-formule et indexation}

$B$ est une \textbf{sous-formule} de $A$ si $B=A$ ou si $A$ est de la forme $A_{1}$`connecteur'$A_{2}$ et ($B$ est une sous-formule de $A_{1}$ ou $B$ est une sous-formules de $A_{2}$). Un calcul de séquents vérifie la \textbf{propriété de la sous-formule} si tout séquent prouvable $\s$ admet une preuve telle que toute formule apparaissant dans (un séquent de) la preuve est une sous-formule d'une formule de $\s$. En particulier, le séquent $\To A$ a une preuve dans laquelle toute formule est une sous-formule de $A$.

Le calcul \LSJ vérifie la propriété de la sous-formule : on le constate aisément en observant chaque règle.

La propriété de la sous-formule est très recherchée en calcul des séquents. D'une part, elle donne une borne sur les formules qu'il faudra manipuler au cours d'une recherche de preuve, qui sont évidemment toutes plus petites que la formule qu'on essaie de prouver. Mais surtout, elle permet de connaître à l'avance la liste exhaustive des formules qu'on pourra rencontrer. On peut donc à l'avance les numéroter : ainsi, les formules d'un séquents sont simplement représentées par un entier. Il faut quelques informations sur ces numéros : par exemple pour une formule $A\land B$, il faut savoir qu'il s'agit d'un ``et'', et pouvoir déterminer $A$ et $B$. Il faut aussi pouvoir reconnaître quand l'axiome $id$ (une même formule apparaît des deux côtés du séquent) s'applique : pour cela on associe à chaque formule une classe, qui correspond à une classe d'équivalence de la relation d'égalité structurelle. La taille de toutes ces informations réunies est linéaire en la taille de la formule de départ (c'est-à-dire le nombre de n\oe uds de l'arbre qui la représente, qui est aussi le nombre de sous-formules avec multiplicité). Un exemple est donné par la figure~\ref{fig:indexation}.

La propriété de la sous-formule est encore plus intéressante dans le cadre de la recherche de preuve compilée : connaître à l'avance les formules qui apparaîtront permet d'écrire pour chacune des fonctions agissant sur le séquent, au lieu de les calculer au cours de la recherche de preuve (voir ??).

\begin{figure}[h]
%\centering
\includegraphics[width=0.3\linewidth]{indexation} %Quelques_formules.f12
\caption{Indexation de la formule $(a\land b)\land(\lnot c \lor (a\land b))$}
\label{fig:indexationBis}
\end{figure}

%\subsection{Absence de duplication}
%
%
%\
%
%\
%\subsection{Inversibilité de certaines prémisses de $\to L$ et $\to R$}
%
%
%$((\bigwedge_{i=1}^{n}p_{i} \lor (\lnot\lnot p_{1}\to f) \lor \bigvee_{i=2}^{n}(p_{i}\to f))\to f)\to f$
%
%\
%
%$(\;[ \;(p_{1}\land p_{2} \land ... \land p_{n}) \lor (\lnot\lnot p_{1}\to f) \lor (p_{2}\to f) \lor ... \lor (p_{n}\to f)\;]\to f\;)\to f$
%
%\
%
%$1:f \quad\To_{0}\quad 0:  p1 \land ( p2 \land p3 )  \;,\; 0: \lnot\lnot p1 \to f  \;,\;  0: p2 \to f  \;,\;  0: p3 \to f  \;,\; 0: f$
%
%\
%
%$f\;;\;\emptyset \quad\To\quad p_{1} \land p_{2} \land ... \land p_{n} \;,\; \lnot\lnot p_{1}\to f \;,\; p_{2}\to f \;,\; ...  \;,\; p_{n}\to f \;,\; f$
%
%
%
%\section{Quelques explications sur l'implémentation}
%
%\subsection{Précalculs : indexation, classes, priorités}
%
%\subsection{Gestion efficace des formules du séquent : insertion et suppression, choix de la formule principale}
%
%
%
%\section{Vers une recherche de preuve compilée et certifiée}
%
%\subsection{Un langage simple pour la certification}
%
%\subsection{Compilation : des fonctions pour chaque sous-formule}
%
%











\section{Implémentation}


\subsection{Indexation}

Une formule peut être considérée comme un \textbf{arbre binaire} dont les feuilles sont étiquetées par la constante $\bot$ ou une variable propositionnelle, et les n\oe uds internes sont étiquettés par un connecteur binaire. La notion de sous-formule correspond alors à celle de sous-arbre. On rappelle qu'une formule est \textbf{\emph{atomique}} si elle est réduite à $\bot$ ou à une variable, c'est-à-dire si l'arbre associé est une feuille.
%
Considérons une formule de la forme $A\,c\,B$ où $c$ est un connecteur binaire. Au cours de l'algorithme, on peut avoir besoin d'informations dessus : par exemple, on peut être amené dans le cadre de certaines règles à l'enlever d'un séquent pour la remplacer par $A$ ou par $B$. Il faut donc connaître $A$ et $B$. Et de même récursivement, il faut connaître les fils de $A$ et ceux de $B$, donc finalement on doit retenir tous les n\oe uds de l'arbre correspondant à la formule. Mais on préfère éviter de représenter les formules manipulées dans l'algorithme sous forme d'arbres, pour des raisons qu'on verra plus loin, par exemple la complexité du test d'égalité structurelle de deux arbres. On préfère utiliser une conséquence de la propriété de la sous-formule, que \LSJn\ hérite de \LSJ : toutes les formules susceptibles d'apparaître au cours de l'algorithme de recherche de preuve appliqué au séquent $\; \To A$, sont des sous-formules de la formule $A$. Si l'objectif est de déterminer la prouvabilité de la formule $A$ en logique intuitionniste, on peut donc réaliser une phase préliminaire d'\textbf{indexation} où on associe un entier à chaque sous-formule de $A$, c'est-à-dire chaque n\oe ud (n\oe ud interne ou feuille) de l'arbre correspondant. Afin de pouvoir retrouver les informations dont on a besoin sur chaque formule, on retient en plus un tableau qui à l'entier représentant la formule $B$, associe : la constante $\bot$ ou la variable locale correspondant à $B$ si $B$ est atomique, ou ``$i$ $c$ $j$'' si $B=C\,c\,D$ avec $c$ un connecteur binaire et $i$, $j$ les entiers respectivement associés à $C$, $D$. Le nombre de cases de ce tableau, et donc sa complexité spatiale puisque le contenu d'une case est de taille constante, est la taille de la formule $A$ dont on veut décider la prouvabilité. Au cours de l'algorithme, on représente alors les formules par des entiers, et on peut accéder facilement aux fils de n'importe quelle formule considérée.

\

\noindent
\textbf{Classes d'égalité structurelle.}
Au cours de l'algorithme, on a souvent besoin de vérifier si l'axiome d'identité~$id$ s'applique, c'est-à-dire si une même formule apparaît des deux côtés du séquent, avec des indices adéquats ; ``même formule'' est à comprendre au sens de l'égalité structurelle, c'est-à-dire l'égalité des arbres associés. Tester cette égalité entre les formules représentées par deux entiers donnés est possible à partir des informations dont on dispose mais long (de l'ordre du minimum des tailles des deux formules). On préfère, au cours de l'indexation, construire un deuxième tableau, qui à chaque entier associe un numéro de \emph{classe}, à comprendre comme les classes d'équivalence de l'égalité structurelle. Ainsi, on détermine en temps constant si les formules associées à deux entiers donnés sont égales structurellement.

%Or, deux entiers distincts peuvent représenter des formules égales structurellement. Il est possible de tester cette égalité puisqu'on peut déterminer les fils des formules considérées, puis récursivement, si les connecteurs sont le mêmes tester les égalités respectives des fils jusqu'à arriver à des formules atomiques. Mais la complexité est au moins le minimum des tailles des deux formules considérées.

\

\noindent
\textbf{Priorités.}
Les priorités de la sous-section précédente peuvent être déterminées au cours de l'indexation. Car les connecteurs sont bien sûr connus, mais surtout, on peut décider de quel côté du séquent une formule donnée est susceptible d'apparaître. On se donne un ensemble à deux éléments $E=\{gauche,droite\}$. Si $\Ccal$ est un élément de $E$, on note $\bar\Ccal$ l'autre élément de $E$. On constate en observant les règles que si une formule $H=A\land B$ ou $H=A\lor B$ apparaît du côté $\Ccal$ d'un séquent, alors $A$ et $B$ ne peuvent apparaître dans une séquent que du même côté $\Ccal$ ; et si $H=A\to B$ apparaît du côté $\Ccal$, alors $B$ ne peut apparaître que du même côté $\Ccal$, et $A$ du côté opposé $\bar\Ccal$. Comme on sait que dans la recherche de preuve pour une formule $A$, cette formule apparaît à $droite$ dans le séquent initial $\;\To A$, on est capable d'associer un côté, puis une priorité à chaque sous-formule de $A$.


\

%Retenir une formule demande donc une complexité spatiale de l'ordre du nombre de n\oe uds de l'arbre correspondant, qu'on appellera la \emph{taille} de la formule. En effet, considérons une formule de la forme $A\,c\,B$ où $c$ est un connecteur binaire. On a besoin de conserver des informations dessus : par exemple, on peut être amené dans le cadre de certaines règles à l'enlever d'un séquent pour la remplacer par $A$ ou par $B$. Il faut donc connaître $A$ et $B$. Et de même récursivement, il faut connaître les fils de $A$ et ceux de $B$, donc finalement on doit retenir tous les n\oe uds de l'arbre correspondant à la formule. Pour une seule formule, on a ainsi vraiment besoin d'un espace de l'ordre de sa taille. En revanche, on peut retenir les multiensembles de formules qui apparaissent au cours de l'algorithme en utilisant beaucoup moins d'espace que la somme des tailles des formules, tout en conservant toutes les informations dont on peut avoir besoin sur ces formules. 
%%
%La propriété essentielle pour cela est la propriété de la sous-formule, que \LSJn\ hérite de \LSJ. Elle a pour conséquence que toutes les formules susceptibles d'apparaître au cours de l'algorithme de recherche de preuve appliqué au séquent $\; \To A$, sont des sous-formules de la formule $A$. Si l'objectif est de déterminer si la formule $A$ est prouvable en logique intuitionniste, on peut donc réaliser une phase préliminaire d'\emph{indexation} où on associe un entier à chaque sous-formule de $A$, c'est-à-dire chaque n\oe ud (n\oe ud interne ou feuille) de l'arbre correspondant. Afin de pouvoir retrouver les informations dont on a besoin sur chaque formule, on retient en plus un tableau qui à l'entier représentant la formule $B$, associe : la constante $\bot$ ou une variable locale si $B$ a cette forme, ou ``$i$ $c$ $j$'' si $B=C\,c\,D$ avec $c$ un connecteur binaire et $i$, $j$ les entiers respectivement associés à $C$, $D$. Le nombre de cases de ce tableau est la taille de la formule $A$ dont on veut décider la prouvabilité. La complexité spatiale pour un multiensemble de formules qui pourraient apparaître en exécutant l'algorithme est alors la taille de $A$ plus le cardinal du multiensemble, ce qui est bien mieux que la somme des tailles des formules du multiensemble dans le pire cas
%
%
%\
%
%On a vu que \LSJn, comme \LSJ, possède la propriété de la sous-formule. Une conséquence est que toutes les formules susceptibles d'apparaître au cours de l'algorithme de recherche de preuve appliqué au séquent $\; \To A$, sont des sous-formules de la formule $A$. Si l'objectif est de déterminer si la formule $A$ est prouvable en logique intuitionniste, on peut donc réaliser une phase préliminaire d'\emph{indexation} où on associe un entier à chaque sous-formule de $A$. Ensuite, lorsqu'on effectue la recherche de preuve sur $\; \To A$, les formules contenues dans les multiensembles d'un séquent sont représentées par des entiers et occupent donc une mémoire constante. Il faut cependant faire attention à garder suffisamment d'information : remplacer tout un arbre par un entier n'est jamais anodin. Si on travaille sur une formule de la forme $A\land B$, on peut avoir besoin

%Une formule peut être considérée comme un arbre binaire dont les feuilles sont étiquetées par la constante $\bot$ ou une variable propositionnelle, et les n\oe uds internes sont étiquettés par un connecteur binaire. La notion de sous-formule correspond alors à celle de sous-arbre. Retenir une formule demande donc une complexité spatiale de l'ordre du nombre de n\oe uds de l'arbre correspondant, qu'on appellera la \emph{taille} de la formule. Cependant, on peut retenir certains multiensembles de formules en utilisant beaucoup moins d'espace que la somme des tailles de ses formules.
%
%On a vu que \LSJn, comme \LSJ, possède la propriété de la sous-formule. Une conséquence est que toutes les formules susceptibles d'apparaître au cours de l'algorithme de recherche de preuve appliqué au séquent $\; \To A$, sont des sous-formules de la formule $A$. Si l'objectif est de déterminer si la formule $A$ est prouvable en logique intuitionniste, on peut donc réaliser une phase préliminaire d'\emph{indexation} où on associe un entier à chaque sous-formule de $A$. Ensuite, lorsqu'on effectue la recherche de preuve sur $\; \To A$, les formules contenues dans les multiensembles d'un séquent sont représentées par des entiers et occupent donc une mémoire constante. Il faut cependant faire attention à garder suffisamment d'information : remplacer tout un arbre par un entier n'est jamais anodin. Si on travaille sur une formule de la forme $A\land B$, on peut avoir besoin








\subsection{Structure de données pour le séquent}




Comme toutes les règles de \LSJn\ sont locales, on peut n'avoir à tout moment qu'un seul séquent en mémoire. Un séquent de \LSJn\ consiste en deux multiensembles $\G$ et $\D$ de couples ``\emph{ indice\!:\,formule }'' et %un entier $n$ : l'\emph{indice} du séquent. L'indice 
un \emph{indice} du séquent $n$. Les indices sont des entiers, et grâce à l'indexation, les formules sont aussi des entiers. La question qui se pose est le choix de structure de données pour $\G$ et $\D$.

Considérons une des règles les plus simples : \LSJLetL. Au cours de l'algorithme de recherche de preuve, on peut être amené à vouloir transformer notre séquent courant, alors égal à la conclusion, en la prémisse. On veut pour cela retirer $i:A\land B$ de $\G$ et y ajouter $i:A$ et $i:B$. On peut aussi avoir besoin de faire la transformations inverse, c'est-à-dire retirer les deux derniers couples et rajouter le premier. Un des objectifs est donc que ces opérations soient rapides.



On définit la complexité d'une étape comme la somme des complexités dans le pire cas de l'ajout d'un couple, du retrait d'un couple, et du choix d'un couple principal.
%
De simples listes entraînent bien sûr une complexité de l'ordre du cardinal des multiensembles. On peut obtenir un choix de couple principal en temps constant avec des listes triées, et


\


Au cours de l'algorithme, on manipule un ``séquent'', censé représenter un séquent du calcul \LSJn, contenant les informations suivantes :

\noindent-\;
des informations de taille constante : l'indice $n$ du séquent, et des booléens $id$ et $fauxL$, indiquant si les axiomes de même nom sont applicables au séquent ;

\noindent-\;
les couples \emph{indice}: \emph{formule} contenus dans les champs $\G$ et $\D$ du séquent.

Comme nous l'avons expliqué en introduisant le calcul \LSJn, le but de celui-ci est de pouvoir effectuer la recherche de preuve en ne gardant à chaque instant qu'un seul séquent en mémoire.

\


Intéressons-nous maintenant à la complexité temporelle.

Celle-ci dépend du nombre de règles qu'on essaie d'appliquer, c'est-à-dire le nombre d'appels récursifs à la fonction \emph{prouvable} (?) dont le pseudo-code est donné en figure ? page ?. Ce nombre dépend de la taille de la formule et des connecteurs présents dedans (et selon l'ordre dans lequel on choisit les formules principales cela peut beaucoup varier pour une même formule, mais on s'intéresse à la complexité dans le pire cas). Mais il ne dépend pas de notre choix d'implémentation (sauf pour l'ordre des ``implique'', mais encore une fois pas si on regarde le pire cas).










\bibliographystyle{plain}
\bibliography{LSJn}

\end{document}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
.
\pagebreak

\section{Le calcul \LSJ}

L'article \cite{LSJ} définit un calcul de séquents \LSJ. Une sémantique naturelle des séquents est définie à l'aide des modèles de Kripke, mais nous ne la présentons pas. En effet, ce qui nous intéresse est l'existence, pour toute formule, d'un séquent qui est prouvable dans le calcul \LSJ\ si, et seulement si, la formule est prouvable en logique intuitionniste. Nous renvoyons à l'article pour les démonstrations, notamment celle de la complétude du calcul.

\subsection{Les séquents}

On s'intéresse à des \emph{multiensembles}, c'est-à-dire des collections où le nombre d'occurrences est pris en compte, mais non l'ordre des éléments. Cela permettra de ne pas avoir besoin de règles explicites d'échange.

Un \textbf{séquent} est la donnée de trois multiensembles $\Th$, $\G$ et $\D$ de formules ; on écrit alors $\Th\;;\;\G\;\To\;\D$.

Une définition d'un séquent \textbf{réfutable} est donnée dans l'article à l'aide des modèles de Kripke. Nous ne la détaillons pas ici, car ce qui nous intéresse surtout est la propriété suivante qui en découle, démontrée dans l'article. La définition de \textbf{prouvable} sera donnée plus tard car elle est liée aux règles du calcul, mais ceci illustre son intérêt.
\begin{prop}\label{propSignificationSequent}
%Soit $\G$, $\D$ des multiensembles de formules. Le séquent $\emptyset\;;\;\G\;\To\;\D$ est \textbf{prouvable} dans \LSJ, c'est-à-dire non réfutable, si et seulement si la formule $\bigwedge_{A\in\G}A\,\to\,\bigvee_{B\in\D}B$ est valide en logique intuitionniste.
Un séquent $\emptyset\;;\;\G\;\To\;\D$ est \textbf{réfutable} si, et seulement si, la formule $\bigwedge_{A\in\G}A\,\to\,\bigvee_{B\in\D}B$ n'est pas valide en logique intuitionniste. Un séquent est \textbf{prouvable} dans \LSJ\ si, et seulement si, il n'est pas réfutable.

\end{prop}
\begin{cor}
Soit $A$ une formule, elle est valide en logique intuitionniste si et seulement si le séquent $\emptyset;\emptyset\To A$ est  prouvable dans \LSJ.
\end{cor}

Les multiensembles $\G$ et $\D$, et leur signification dans la propriété \ref{propSignificationSequent} sont des éléments habituels en calcul des séquents. En revanche, $\Th$ est propre à \LSJ, et est difficile à interpréter car contrairement au cas où $\Th$ est vide, un séquent avec $\Th$ quelconque ne peut pas être représenté par une formule. On peut dire est que $\Th$ contient des formules gardées en réserve, non visibles directement dans le séquent (une formule de $\Th$ ne peut pas être \emph{formule principale}), mais qui peuvent être transférées dans $\G$ et ainsi devenir visibles. On verra que les seules règles qui agissent sur $\Th$ sont celles qui concernent le connecteur $\to$.

Pour un séquent $\Th\;;\;\G\;\To\;\D$, on appellera les formules de $\G$ les \textbf{formules de gauche}, celles de $\D$ les \textbf{formules de droite}, et celles de $\Th$ les \textbf{formules de réserve} du séquent (appellations non conventionnelles).

%

\subsection{Les règles}

%Une règle est de la forme\regle où $\mathcal R$ est le nom de la règle, et $prem_{1}$, ... , $prem_{p}$, $concl$ décrivent des séquents d'une certaine forme. Par exemple $\Th\;;\;A\lor B,\G\;\To\;\D$ représente n'importe quel séquent où au moins une des formules de gauche est une disjonction, et si $\Th\;;\;A,\G\;\To\;\D$ se trouve dans la même règle, cela représente un séquent obtenu à partir du précédent en rempla\c cant une disjonction de gauche $A\lor B$ par son premier terme $A$.



Les règles du calcul \LSJ\ sont données dans la figure~\ref{fig:reglesLSJ}. La notation $A,\G$ représente le multiensemble obtenu à partir de $\G$ en ajoutant une occurrence de $A$. Pour une règle \regle, $\mathcal R$ est le nom de la règle, $prem_{1}$, ... , $prem_{p}$ sont les (resp. première, ... , $p$-ième) \textbf{prémisses}, et $concl$ la \textbf{conclusion}. Les \textbf{axiomes} sont les règles sans prémisse. Pour toutes les autres règles, une unique formule apparaît de manière explicite dans la conclusion : c'est la \textbf{formule principale}. Les règles dites de gauche, ou d'introduction à gauche, contenant un $L$ dans leur nom, sont celles où la formule principale se trouve à gauche dans la conclusion, de même pour les règles de droite.

\begin{figure}
\centering

$$\begin{array}{cc}
	\LSJfauxL & \LSJid \\\\
	\LSJetL & \LSJetR \\\\
	\LSJouL & \LSJouR \\\\
	\multicolumn{2}{c}{\LSJimpL}\\\\
	\multicolumn{2}{c}{\LSJimpR}
\end{array}$$

\caption{Les règles du calcul \LSJ}
\label{fig:reglesLSJ}
\end{figure}


Une \textbf{instance} d'une règle $\mathcal R$ a la même forme que la règle : \instance, mais ici les $\s_{i}$ et $\s$ sont des séquents connus explicitement ; bien entendu il faut qu'il s'agisse de séquents qui ont bien la forme donnée par la définition de la règle. Par exemple \LSJetL\ devient une instance de la règle $\land L$ (qui a la même écriture que la règle) lorsqu'on connaît les formules $A$ et $B$ et toutes les formules de $\Th$, $\G$, $\D$.

Une \textbf{preuve} est un arbre dont les n\oe uds sont étiquetés par un séquent et une règle et ont la même arité que le nombre de prémisses de la règle, et tel que : pour tout n\oe ud de séquent $\s$ et règle $\mathcal R$, si $\s_{1}$, ... , $\s_{p}$ sont les séquents associés à chacun de ses fils respectivement, alors \instance\ est une instance de $\mathcal R$. Les feuilles d'un tel arbre sont les n\oe uds auxquels est associé un axiome.

Un séquent est \textbf{prouvable} s'il existe une preuve à la racine de laquelle il est associé.

De manière équivalente, on peut définir l'ensemble des formules prouvables comme le plus petit ensemble vérifiant : pour toute instance \instance\ d'une règle de \LSJ, si pour tout $i$, $\s_{i}$ est prouvable, alors $\s$ est prouvable (en particulier pour toute instance \instanceAx\ d'un axiome $\mathcal A$, $\s$ est prouvable).



\subsection{Conditions de non-prouvabilité}

Pour montrer qu'un séquent est prouvable, il suffit d'en exhiber une preuve. Comment montrer le contraire ? D'après la définition précédente, un séquent n'est pas prouvable s'il n'existe aucune instance de règle\instance telle que tous les $\s_{i}$ sont prouvables. Or les $\s_{i}$ ne dépendent que de $\s$, $\mathcal R$ et du choix de la formule principale : il est donc possible de tester toutes les instances possibles. Cela fournit un premier algorithme de recherche de preuve : récursivement, pour chercher si un séquent $\s$ est prouvable, on considère toutes les instances de règles dont $\s$ est la conclusion et pour chacune on détermine récursivement si chaque prémisse est prouvable. Si on trouve une instance telle que toutes les prémisses sont prouvables, alors $\s$ est prouvable (et on obtient une preuve de $\s$ si on connaît une preuve de chacune de ces prémisses), sinon $\s$ n'est pas prouvable. Cet algorithme est très long. En fait, c'est à peu près ce qu'on se retrouve à faire dans les cas extrêmement défavorables. Mais heureusement, on a un procédé bien plus économe en moyenne grâce à la notion de règle ou prémisse inversible.

Une prémisse $prem_{i}$ d'une règle\regle(aussi appelée $i$-ème prémisse de $\mathcal R$) est \textbf{inversible} si on a : si $prem_{i}$ est non prouvable, alors $concl$ est non prouvable. Une règle est \textbf{inversible} si toutes ses prémisses sont inversibles.

On admet, une démonstration se trouvant dans l'article \cite{LSJ} :

\noindent- les règles $\land L$, $\land R$, $\lor L$ et $\lor R$ sont inversibles~;

\noindent- les deux premières prémisses de $\to L$ et la première prémisse de $\to R$ sont inversibles~;

\noindent- la troisième prémisse de $\to L$ et la deuxième prémisse de $\to R$ ne sont pas inversibles.



\subsection{Algorithme}


On en déduit le procédé suivant pour essayer d'appliquer une règle à un séquent avec un formule principale donnée : on essaie de prouver les prémisses inversibles, puis l'éventuelle prémisse non inversible (dans \LSJ\ il y en a au plus une). Dès qu'on trouve qu'une prémisse inversible est non prouvable, on s'arrête : le séquent initial n'est pas prouvable non plus. Si toutes les prémisses sont prouvables, le séquent initial est également prouvable. Dans le dernier cas (seule la prémisse non inversible est non prouvable), on essaie une application de règle avec une autre formule principale.

Il ne reste plus qu'à décider dans quel ordre les formules qui peuvent l'être sont choisies comme formule principale pour essayer d'appliquer une règle. On choisit de traiter en premier les règles inversibles, car on sait alors qu'il n'y aura pas besoin d'essayer d'autre application de règle sur le même séquent. 
% : après avoir examiné au pire toutes les prémisses, on sait si le séquent est prouvable.
Parmi celles-ci, on privilégie celles qui n'ont qu'une prémisse ($\land L$ et $\lor R$) sur les autres, qui en ont deux ($\lor L$ et $\land R$).

%L'algorithme est le suivant.

\begin{figure}[!h]
%\centering
\def\true{\emph{vrai}}
\def\false{\emph{faux}}
\def\lett{\textbf{soit }}
\def\if{\textbf{si} }
\def\then{\textbf{alors} }
\def\return{\textbf{retourner} }
\def\select{\textbf{sélectionner} }
\def\from{\textbf{dans} }

\textbf{fonction} estProuvable ($\s$)

\quad \lett $\s=\Th;\G\To\D$

\quad \if ($\bot\in\G$) \then \return \true

\quad \if ($\G\cap\D\neq\emptyset$) \then \return \true

\quad \if ($\G$ et $\D$ ne contiennent que des formules \emph{atomiques}) \then \return \false


\quad \if (il existe $A\land B\in\G$) \then $\{$

\quad \quad \select $H=A\land B$ \from $\G$

\quad \quad \return estProuvable($prem(\land L, \s, H)$)

\quad $\}$


\quad \if (il existe $A\lor B\in\D$) \then $\{$

\quad \quad \select $H=A\lor B$ \from $\D$

\quad \quad \return estProuvable($prem(\lor R, \s, H)$)

\quad $\}$

\quad ...


\caption{Algorithme}
\label{fig:algo}
\end{figure}



\subsection{?}




On voit immédiatement que l'algorithme nécessite de pouvoir déduire d'un séquent, d'une règle et d'une formule principale contenue dans le séquent et sur laquelle la règle peut agir, les séquents correspondant aux différentes prémisses. Ce n'est pas difficile : pour les axiomes il n'y a rien à faire ; pour les autres règles, la formule principale $H$ étant de la forme $A \text{ 'connecteur' } B$, il suffit d'enlever $H$ du séquent et, selon le connecteur et le côté où se trouvait $H$, d'ajouter $A$ ou $B$ à $\Th$, $\G$, $\D$ ou nulle part.

Mais ce n'est pas tout. Lorsqu'on essaie d'appliquer une règle\instancedeux\ au séquent $\s$, on lance une recherche de preuve sur $\s_{1}$ qu'on a obtenu comme décrit ci-dessus. Si on obtient que $\s_{1}$ est prouvable, on lance alors la recherche de preuve sur $\s_{2}$. On doit donc déterminer $\s_{2}$. On a vu qu'on sait le faire à partir de $\s$. Une solution consiste donc à retenir $\s$ pendant qu'on effectue la recherche de preuve sur $\s_{1}$, mais cela peut être coûteux en mémoire. Une autre solution, que nous avons privilégiée, consiste à être capable de retrouver $\s$ à partir de $\s_{1}$ ainsi que de la formule principale, de la règle et du numéro de la prémisse (ici $1$). On a dans ce cas besoin de pouvoir retrouver la conclusion à partir de n'importe laquelle des prémisses, pas seulement par exemple de la première prémisse pour une règle qui n'en a que deux. En effet, utiliser $\s_{1}$ pour retrouver $\s$ suppose qu'à la fin de la recherche de preuve pour $\s_{1}$, on connaît $\s_{1}$. Or, l'idée ici est de n'avoir vraiment qu'un seul séquent en mémoire à tout moment. Ainsi, à la fin de la recherche de preuve pour $\s$, on doit connaître $\s$, donc on doit aussi pouvoir déduire $\s$ de $\s_{2}$ en connaissant la formule principale et le fait qu'on est en train de s'intéresser à la deuxième prémisse.

En résumé, on aimerait (bien que ce ne soit pas nécessaire) que toutes les règles soient \textbf{locales}, avec la définition suivante.

\begin{df}
Une règle est \textbf{locale} si pour toute instance\instance\ de cette règle et pour tout $i$ entre $1$ et $p$, on peut déduire $\s$ à partir de $\s_{i}$ et de la formule principale et de $i$.
\end{df}

On remarque que $\land L$, $\land R$, $\lor L$ et $\lor R$ sont locales. Les axiomes sont également locaux, la définition n'ayant pas grand intérêt pour eux. En revanche, les règles $\to L$ et $\to R$ ne sont pas locales : pour chacune, les formules représentées par $\D$ dans la conclusion n'apparaissent nulle part dans la dernière prémisse, il n'est donc pas possible de retrouver la conclusion en connaissant uniquement cette prémisse, la formule principale et le numéro de la prémisse, puisqu'il n'y a aucun moyen d'en déduire ce qui se trouve dans $\D$.

C'est pour cette raison qu'on introduit le calcul \LSJn, dans lequel toutes les règles sont locales.

\section{Le calcul \LSJn}


%On utilise les définitions et notations de l'article~\cite{LSJ}.
%.
%
%\
%
%Le système \LSJn\ a pour objectif de faire les mêmes calculs que \LSJ, mais en manipulant des séquents qui contiennent un peu plus d'information, afin de pouvoir faire le ``back-tracking'' nécessaire à l'algorithme de \LSJ\ en n'ayant à tout moment en mémoire qu'un seul séquent.
%
%Pour cela, on veut que les séquents de \LSJn\ représentent de manière exhaustive et pertinente ceux de \LSJ\ : on montre qu'il existe une surjection de l'ensemble des séquents de \LSJn\ dans l'ensemble des séquents de \LSJ, telle qu'un séquent de \LSJn\ est prouvable dans \LSJn\ si, et seulement si, son image est prouvable dans \LSJ.
%
%\
%
%Le calcul \LSJn, très proche du calcul \LSJ, manipule des séquents contenant un peu plus d'information afin de n'avoir que des règles locales. 
%Plus précisément, chaque séquent de \LSJn\ a un indice (un entier naturel), et chaque formule du séquent a également un indice.
%Plus précisément, chaque séquent a un indice $n$, qui détermine lesquelles de ses formules, qui ont aussi chacune un indice $i$, sont \emph{actives}, c'est-à-dire peuvent être la formule principale lors d'une application de règle : pour les formules de gauche, la condition est $i\leq n$, et pour celles de droite $i=n$. Ainsi, pour la dernière prémisse des deux règles liées à $\to$ par exemple, les formules de droite de la conclusion peuvent être conservée dans le séquent sans être actives. Il suffit de modifier l'indice du séquent pour changer les formules actives.

Le calcul \LSJn\ est très proche du calcul \LSJ\ : chaque règle de \LSJn\ correspond à une règle de \LSJ, et des arbres de preuve dans les deux systèmes pour la même formule sont fortement liés. Mais contrairement à \LSJ, les règles de \LSJn\ sont toutes locales. Pour cela, les séquents de \LSJn\ représentent chacun un séquent de \LSJ, avec un peu plus d'informations : celles qui sont parfois nécessaire pour retrouver la conclusion à partir d'une prémisse. Cette représentation est exhaustive et correcte. On montre en effet qu'il existe une surjection de l'ensemble des séquents de \LSJn\ dans l'ensemble des séquents de \LSJ, telle qu'un séquent de \LSJn\ est prouvable dans \LSJn\ si, et seulement si, son image est prouvable dans \LSJ.


\subsection{Formalisme de \LSJn}


Un séquent de \LSJn\ est la donnée de deux multiensembles $\Gp$ et $\Dp$ de couples $entier~:~formule$, et d'un entier naturel $n$, tels que tous les entiers présents dans $\Gp$ sont $\leq n+1$ et tous ceux présents dans $\Dp$ sont $\leq n$ ; on écrit $\Gp \Rightarrow_{n} \Dp$.

\

Les règles du calcul \LSJn\ sont décrite dans la figure~\ref{fig:reglesLSJn}. Chacune correspond à une règle de \LSJ.


\begin{figure}[h]
\centering

\emph{$n$ et parfois $i$ désignent toujours des entiers naturels, avec $i\leq n$}
$$\begin{array}{cc}
	\LSJLfauxL & \LSJLid \\\\
	\LSJLetL & \LSJLetR \\\\
	\LSJLouL & \LSJLouR \\\\
	\multicolumn{2}{c}{\LSJLimpL}\\\\
	\multicolumn{2}{c}{\LSJLimpR}
\end{array}$$

\caption{Les règles du calcul \LSJn}
\label{fig:reglesLSJn}
\end{figure}




\subsection{\'Equivalence avec \LSJ}


On note $\Sig$ l'ensemble des séquents de \LSJ, et $\Sig'$ l'ensemble des séquents de \LSJn.

Soit $\sigma\in\Sig$, on note $\vdash\sigma$ si $\sigma$ est prouvable dans \LSJ\ ; soit $\sigma'\in\Sig'$, on note $\vdash'\sigma'$ si $\sigma'$ est prouvable dans \LSJn.

\

Soit $M$ un multiensemble de couples $entier:formule$, l'entier d'un couple étant appelé son indice. On note $M_{k}$ le multiensemble obtenu à partir de $M$ en ne gardant que les couples d'indice $k$, et $M_{\leq k}$ celui obtenu en ne gardant que les couples d'indice inférieur à $k$. On note $\forget(M)$ le multiensemble de formules obtenu en oubliant l'indice et ne gardant que la formule de chaque couple de $M$.

On définit l'application $\surj$ de %l'ensemble des séquents de \LSJn\ dans l'ensemble des séquents de \LSJ,
$\Sig'$ dans $\Sig$, qui à $\G' \To_{n} \D'$ associe $\Th\, ;\G \To \D$ %\quad 

\noindent
où :\;
$\left\{
\begin{array}{l}
%	\Th = \{ A \:|\: n+1:A \in \G'\} \\
%	\G = \{ A \:|\: \exists i\leq n,\ i:A \in \G'\} \\
%	\D = \{ A \:|\: n:A \in \D'\}
	\Th = \forget (\G'_{n+1}) \\
	\G = \forget (\G'_{\leq n}) \\
	\D = \forget (\D'_{n})
\end{array}
\right.$.

C'est une application surjective : en effet tout séquent $\Th \,;\G\To\D$ de \LSJ\ a au moins pour antécédent le séquent $\G' \To_{0} \D'$, 
%avec $\G' = \{ 0:A \:|\: A \in \G\} \cup \{ 1:A \:|\: A \in \Th\}$ et $\D' = \{ 0:A \:|\: A \in \D\}$.
où $\G'$ est l'union de $0 : \G$ (le multiensemble de couples obtenu à partir de $\G$ en rempla\c cant chaque occurrence d'une formule $A$ par une occurrence du couple $0:A$) avec $1:\Th$, et où $\D'=0:\D$.

\




Soit $\mathcal R$ une règle de \LSJ. On note $\mathcal R'$ la règle de \LSJn\ qui lui correspond. On écrit \instanceR\ et \instanceRp\ des instances de ces règles.


\begin{lm}
Soit $\sigma\in\Sig$ et $\sigma'\in\Sig'$ tels que $\sigma=\surj(\sigma')$ et soit $\mathcal R$ une règle de \LSJ.

1) Si \instanceR alors il existe $\s'_{1}$, ... , $\s'_{p}$ tels que pour tout $k$, $\s_{k} = \surj (\s'_{k})$, et \instanceRp.

2) Si \instanceRp, posons pour tout $k$, $\s_{k} = \surj (\s'_{k})$, alors \instanceR.

\noindent
Pour un axiome $\mathcal A$, cela signifie simplement : \instanceAx si et seulement si \instanceAxp.
\end{lm}

\begin{proof}
On le montre pour chaque règle ; c'est une conséquence assez directe de la définition de $\surj$. Faisons-le par exemple pour $id$, $\land R$ et $\to L$. \`A chaque fois, on se donne $\s = \Th\, ;\G \To \D$ et $\s' = \G' \To_{n} \D' \in\Sig'$ tels que $\s=\surj(\s')$.

\

%\noindent-\quad 
\noindent $id$ :\quad On a\instanceid\ si et seulement s'il existe une formule $A$ appartenant à la fois à $\G$ et $\D$, ce qui équivaut, par définition de $\surj$, à : il existe $A$ et $i\leq n$ tels que $n:A\in\D'$ et $i:A\in\G'$, c'est-à-dire \instanceidp.

\

\noindent $\land R$ :	\quad

1) Si \instanceetR\ alors il existe des formules $A$ et $B$ et un multiensemble $\Dt$ tels que $\D = A \land B, \Dt$ et $\s_{1} = \Th\, ;\G \To A,\Dt$ et $\s_{2} = \Th\, ;\G \To B,\Dt$.
 Posons $\Dt' = \D' - n:A \land B$ le multiensemble obtenu en retirant une seule occurrence de $n:A\land B$ à $\D'$ (qui contient cet élément parce que $\D$ contient $A\land B$ et par définition de $\surj$),
 et $\s'_{1} = \G' \To_{n} n:A,\Dt'$ et $\s'_{2} = \G' \To_{n} n:B,\Dt'$.
 Alors on a bien $\s_{1}=\surj(\s'_{1})$ et $\s_{2}=\surj(\s'_{2})$ (en remarquant que 
 %$\Dt = \{ C \:|\: n:C \in \Dt'\}$
$\Dt = \forget (\Dt'_{n})$
), et \instanceetRp (en remarquant que $\s' = \G' \To_{n} n:A \land B,\Dt'$).

2) Si \instanceetRp\ alors il existe $A$, $B$ et $\Dt'$ tels que $\D' = n:A \land B, \Dt'$ et $\s'_{1} = \G' \To_{n} n:A,\Dt'$ et $\s'_{2} = \G' \To_{n} n:B,\Dt'$ ; 
 on pose $\Dt = \D - A \land B$ le multiensemble obtenu en retirant une seule occurrence de $A\land B$ à $\D$,
 et $\s_{1}=\surj(\s'_{1})$ et $\s_{2}=\surj(\s'_{2})$ ; on obtient $\s = \Th\, ;\G \To A\land B,\Dt$ et $\s_{1} = \Th\, ;\G \To A,\Dt$ et $\s_{2} = \Th\, ;\G \To B,\Dt$\; d'où\instanceetR.

\

\noindent $\to L$ :	\quad

1) Si \instanceimpL\ alors il existe $A$, $B$ et $\Gt$ tels que $\G=A\to B,\Gt$ et $\s_{1} = \Th\, ;B,\Gt \To \D$ et $\s_{2} = B,\Th\, ;\Gt \To A,\D$ et $\s_{3} = B \,; \Th,\Gt \To A$ ; et il existe $i\leq n$ tel que $i:A\to B\in\G'$ ;
 on pose $\Gt' = \G' - i:A\to B$ (on retire une seule occurrence de $i:A\to B$ de $\G'$) et $\s'_{1} = i:B,\Gt' \To_{n} \D'$ et $\s'_{2} = n+1:B,\Gt' \To_{n} n:A,\D'$ et $\s'_{3} = n+2:B,\Gt' \To_{n+1} n+1:A, \D'$ et on vérifie que cela convient.

2) Si \instanceimpLp\ alors il existe $i$, $A$, $B$ et $\Gt'$ tels que $\G'=i:A\to B,\Gt'$ et $\s'_{1}$, $\s'_{2}$ et $\s'_{3}$ ont la forme donnée ci-dessus ; on pose $\Gt = \G - A\to B$ (on retire une seule occurrence de $A\to B$ de $\G$), alors les images $\s_{1}$, $\s_{2}$ et $\s_{3}$ par $\surj$ de $\s'_{1}$, $\s'_{2}$ et $\s'_{3}$ respectivement s'écrivent comme ci-dessus et donc \instanceimpL.
\end{proof}



\begin{theo}
Soit $\sigma\in\Sig$ et $\sigma'\in\Sig'$ tels que $\sigma=\surj(\sigma')$, alors $\vdash \sigma$ si et seulement si $\vdash' \sigma'$.
%Soit $\sigma$ un séquent de \LSJ\ et $\sigma'$ un séquent de \LSJn\ tels que $\sigma=\surj(\sigma')$, alors $\vdash \sigma$ si et seulement si $\vdash' \sigma'$.
\end{theo}

\begin{proof}
Par récurrence sur la \emph{taille} de $\s\in\Sig$, c'est-à-dire la somme des tailles des formules des trois multiensembles apparaissant dans $\s$.

\

\noindent
On initialise pour tout $\sigma = \Th\, ;\G \To \D$ tel que toutes les formules dans $\G$ et dans $\D$ sont atomiques : soit $\sigma' = \G' \To_{n} \D' \in\Sig'$ tel que $\sigma=\surj(\sigma')$. Alors toutes les formules associées à un $i \leq n$ dans $\G'$ et toutes les formules associées à $n$ dans $\D'$ sont aussi atomiques. En étudiant la forme des conclusions des règles non axiomatiques de \LSJ\ comme de \LSJn,
on remarque que si $\s$ (resp. $\s'$) est la conclusion d'une règle de \LSJ\ (resp. \LSJn), alors la règle est un axiome. L'initialisation est donc un cas particulier de ce qui suit avec $p=0$ (ce qui entraîne qu'on n'utilise en fait pas l'hypothèse de récurrence).

% on obtient que : $\vdash \s$ si et seulement si $\s$ est une conséquence directe d'un axiome de \LSJ, et $\vdash' \s'$ si et seulement si $\s'$ est une conséquence directe d'un axiome de \LSJn. Or d'après le lemme, pour $\mathcal A$ axiome de \LSJ, \instanceAx si et seulement si \instanceAxp. On en déduit $\vdash \sigma$ si et seulement si $\vdash' \sigma'$.

\

\noindent
Soit $\s = \Th\, ;\G \To \D \in\Sig$. Soit $\sigma' = \G' \To_{n} \D' \in\Sig'$ tel que $\sigma=\surj(\sigma')$.

On suppose $\vdash \s$. Alors il existe une règle $\mathcal R$ de \LSJ\ et $\s_{1}$, ... , $\s_{p} \in\Sig$ (avec éventuellement $p$ nul) tels que $\vdash \s_{k}$ pour tout $k$ et\instanceR. D'après le lemme, il existe $\s'_{1}$, ... , $\s'_{p} \in\Sig'$ tels que $\s_{k}=\surj(\s'_{k})$ pour tout $k$ et\instanceRp. Pour tout $k$, on applique l'hypothèse de récurrence à $\s_{k}$ qui a une \emph{taille} strictement inférieure à celle de $\s$, et on obtient $\vdash' \s'_{k}$. On en déduit $\vdash' \s'$.

On suppose $\vdash' \s'$. Alors il existe une règle $\mathcal R'$ de \LSJn\ et $\s'_{1}$, ... , $\s'_{p} \in\Sig'$ tels que $\vdash' \s'_{k}$ pour tout $k$ et\instanceRp. On pose $\s_{k}=\surj(\s'_{k})$ pour tout $k$. D'après le lemme on a \instanceR, en particulier on peut appliquer l'hypothèse de récurrence aux $\s_{k}$ donc $\vdash \s_{k}$ pour tout $k$, d'où $\vdash \s$.

\end{proof}






\section{Efficacité de \LSJ}


L'étude qui suit porte sur le calcul \LSJ. En effet, \LSJn\ hérite de toutes les propriétés intéressantes de \LSJ, en apportant une localité des règles qui facilite une implémentation économe en mémoire.


\subsection{Propriété de la sous-formule et indexation}

$B$ est une \textbf{sous-formule} de $A$ si $B=A$ ou si $A$ est de la forme $A_{1}$`connecteur'$A_{2}$ et ($B$ est une sous-formule de $A_{1}$ ou $B$ est une sous-formules de $A_{2}$). Un calcul de séquents vérifie la \textbf{propriété de la sous-formule} si tout séquent prouvable $\s$ admet une preuve telle que toute formule apparaissant dans (un séquent de) la preuve est une sous-formule d'une formule de $\s$. En particulier, le séquent $\To A$ a une preuve dans laquelle toute formule est une sous-formule de $A$.

Le calcul \LSJ vérifie la propriété de la sous-formule : on le constate aisément en observant chaque règle.

La propriété de la sous-formule est très recherchée en calcul des séquents. D'une part, elle donne une borne sur les formules qu'il faudra manipuler au cours d'une recherche de preuve, qui sont évidemment toutes plus petites que la formule qu'on essaie de prouver. Mais surtout, elle permet de connaître à l'avance la liste exhaustive des formules qu'on pourra rencontrer. On peut donc à l'avance les numéroter : ainsi, les formules d'un séquents sont simplement représentées par un entier. Il faut quelques informations sur ces numéros : par exemple pour une formule $A\land B$, il faut savoir qu'il s'agit d'un ``et'', et pouvoir déterminer $A$ et $B$. Il faut aussi pouvoir reconnaître quand l'axiome $id$ (une même formule apparaît des deux côtés du séquent) s'applique : pour cela on associe à chaque formule une classe, qui correspond à une classe d'équivalence de la relation d'égalité structurelle. La taille de toutes ces informations réunies est linéaire en la taille de la formule de départ (c'est-à-dire le nombre de n\oe uds de l'arbre qui la représente, qui est aussi le nombre de sous-formules avec multiplicité). Un exemple est donné par la figure~\ref{fig:indexation}.

La propriété de la sous-formule est encore plus intéressante dans le cadre de la recherche de preuve compilée : connaître à l'avance les formules qui apparaîtront permet d'écrire pour chacune des fonctions agissant sur le séquent, au lieu de les calculer au cours de la recherche de preuve (voir ??).

\begin{figure}
%\centering
\includegraphics[width=0.3\linewidth]{indexation} %Quelques_formules.f12
\caption{Indexation de la formule $(a\land b)\land(\lnot c \lor (a\land b))$}
\label{fig:indexation}
\end{figure}

%\subsection{Absence de duplication}
%
%
%\
%
%\
%\subsection{Inversibilité de certaines prémisses de $\to L$ et $\to R$}
%
%
%$((\bigwedge_{i=1}^{n}p_{i} \lor (\lnot\lnot p_{1}\to f) \lor \bigvee_{i=2}^{n}(p_{i}\to f))\to f)\to f$
%
%\
%
%$(\;[ \;(p_{1}\land p_{2} \land ... \land p_{n}) \lor (\lnot\lnot p_{1}\to f) \lor (p_{2}\to f) \lor ... \lor (p_{n}\to f)\;]\to f\;)\to f$
%
%\
%
%$1:f \quad\To_{0}\quad 0:  p1 \land ( p2 \land p3 )  \;,\; 0: \lnot\lnot p1 \to f  \;,\;  0: p2 \to f  \;,\;  0: p3 \to f  \;,\; 0: f$
%
%\
%
%$f\;;\;\emptyset \quad\To\quad p_{1} \land p_{2} \land ... \land p_{n} \;,\; \lnot\lnot p_{1}\to f \;,\; p_{2}\to f \;,\; ...  \;,\; p_{n}\to f \;,\; f$
%
%
%
%\section{Quelques explications sur l'implémentation}
%
%\subsection{Précalculs : indexation, classes, priorités}
%
%\subsection{Gestion efficace des formules du séquent : insertion et suppression, choix de la formule principale}
%
%
%
%\section{Vers une recherche de preuve compilée et certifiée}
%
%\subsection{Un langage simple pour la certification}
%
%\subsection{Compilation : des fonctions pour chaque sous-formule}
%
%











\section{Implémentation}
\subsection{Indexation}

cf ``Propriété de la sous-formule et indexation'' + explication sur les classes (et priorités) et les champs axiomes du séquent



\subsection{Structure de données pour le séquent}

Au cours de l'algorithme, on manipule un ``séquent'', censé représenter un séquent du calcul \LSJn, contenant les informations suivantes :

\noindent-\;
des informations de taille constante : l'indice $n$ du séquent, et des booléens $id$ et $fauxL$, indiquant si les axiomes de même nom sont applicables au séquent ;

\noindent-\;
les couples \emph{indice}: \emph{formule} contenus dans les champs $\G$ et $\D$ du séquent.

Comme nous l'avons expliqué en introduisant le calcul \LSJn, le but de celui-ci est de pouvoir effectuer la recherche de preuve en ne gardant à chaque instant qu'un seul séquent en mémoire.

\


Intéressons-nous maintenant à la complexité temporelle.

Celle-ci dépend du nombre de règles qu'on essaie d'appliquer, c'est-à-dire le nombre d'appels récursifs à la fonction \emph{prouvable} (?) dont le pseudo-code est donné en figure ? page ?. Ce nombre dépend de la taille de la formule et des connecteurs présents dedans (et selon l'ordre dans lequel on choisit les formules principales cela peut beaucoup varier pour une même formule, mais on s'intéresse à la complexité dans le pire cas). Mais il ne dépend pas de notre choix d'implémentation (sauf pour l'ordre des ``implique'', mais encore une fois pas si on regarde le pire cas).










\bibliographystyle{plain}
\bibliography{LSJn}

\end{document}












